{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=600,\n",
    "                 img_height=200,\n",
    "                 batch_size=32):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.obstacle_images = []\n",
    "        self.no_obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_obstacles = 0\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen(self.batch_size)\n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self, batch_size):\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen, batch_size=batch_size)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    "\n",
    "    # Special generator to generate the 3 parts of the input image as 3 separate input images\n",
    "    def three_im_generator(self, gen, dataset, target_size, batch_size, class_mode):\n",
    "\n",
    "        im_gen = gen.flow_from_directory(dataset, \n",
    "                                         target_size=target_size, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         color_mode='grayscale',\n",
    "                                         class_mode=class_mode)\n",
    "        self.filenames = im_gen.filenames\n",
    "\n",
    "        while True:\n",
    "            im1_s, im2_s, im3_s = [], [], []\n",
    "            images, labels = im_gen.next()\n",
    "\n",
    "            for im in images:\n",
    "                w = im.shape[1]\n",
    "                im1 = im[:, :w//3]\n",
    "                im2 = im[:, w//3:(w*2)//3] \n",
    "                im3 = im[:, (w*2)//3:] \n",
    "                im1_s.append(im1)\n",
    "                im2_s.append(im2)\n",
    "                im3_s.append(im3)\n",
    "\n",
    "            im1_s = np.array(im1_s)\n",
    "            im2_s = np.array(im2_s)\n",
    "            im3_s = np.array(im3_s)\n",
    "            yield [im1_s, im2_s, im3_s], labels\n",
    "                        \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "\n",
    "    # Compute and plot multi-class confusion-matrix with normalization\n",
    "    def plot_cm_normalized(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold)\n",
    "        # Normalise\n",
    "        cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        sns.heatmap(cmn, annot=True, fmt='.3f')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show(block=False)  \n",
    "                \n",
    "    def display_false_positives(self, predictions, threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        if 500 > len(false_positives) > 1:\n",
    "            num_images = len(false_positives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_positives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                print(f'FP prediction: {preds[i]}, imname: {imname}')\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_positives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show()\n",
    "            \n",
    "    def display_false_negatives(self, predictions, threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "\n",
    "        if 500 > len(false_negatives) > 1:\n",
    "            num_images = len(false_negatives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_negatives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_negatives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show()   \n",
    "            \n",
    "    def save_false_positives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'false_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "    def save_true_positives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        true_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'true_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "\n",
    "    def save_false_negatives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'false_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "    def save_true_negatives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        true_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'true_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 1492 images belonging to 2 classes.\n",
      "Found 1492 images belonging to 2 classes.\n",
      "47/47 [==============================] - 7s 143ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Variables --\n",
    "model_path = '/home/drevital/cs_video_processor/models/humid_jan22_ggm'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/humid_jan22_ggm/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'rgb'\n",
    "thresholds = [0.3, 0.5, 0.7]\n",
    "batch_size = 32\n",
    "save_base_path = '/home/drevital/obstacles_classification_datasets/model_eval'\n",
    "save_name = dataset.split('/')[-2] + '_' + str(threshold)\n",
    "save_path = os.path.join(save_base_path, save_name)\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, dataset, batch_size=batch_size)\n",
    "\n",
    "# -- Define Labels\n",
    "labels = np.array([0]*handler.num_no_obstacles\\\n",
    "                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "# -- Print confision-matrix\n",
    "handler.plot_cm_normalized(model_path, labels, predictions, threshold=threshold)\n",
    "\n",
    "# -- Save Images\n",
    "handler.save_false_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "handler.save_false_positives(predictions, threshold=threshold, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
