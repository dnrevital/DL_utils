{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = '/home/drevital/obstacles_classification_datasets/obstacle_classification_RGB_data'\n",
    "annotated_folder = '/home/drevital/obstacles_classification_datasets/rgb_6/annotated'\n",
    "in_folder = '/home/drevital/obstacles_classification_datasets/rgb_6'\n",
    "out_folder = '/home/drevital/obstacles_classification_datasets/humid_jan22'\n",
    "sites = ['_'.join(s.split('_')[:-2]) for s in os.listdir(src_folder)]\n",
    "\n",
    "# Parameters used in the diff_metric to diff_coef assignent function\n",
    "alfa = 3\n",
    "beta = 1.5\n",
    "gamma = 8\n",
    "swc = 1.0 # sample weight coefficient\n",
    "diff_threshold = 50\n",
    "std_threshold_dist = 1.5 # Distance from std to apply sample_weight correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_thresholds = {'israel': 55, 'new_factory': 50, 'new_factory_humid': 50, 'musashi_office': 40, 'koki_factory': 40}\n",
    "default_threshold = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dictionary for the image names of each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_images = defaultdict(list)\n",
    "\n",
    "for site in sites:\n",
    "    site_folder = os.path.join(src_folder, site + '_rgb_data','all_data')\n",
    "    class_folders = os.listdir(site_folder)\n",
    "    for cls in class_folders:\n",
    "        site_images[site] += [f for f in os.listdir(os.path.join(site_folder,cls))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List images not found in any site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_folders = ['no_obstacle', 'obstacle']\n",
    "\n",
    "for class_folder in class_folders:\n",
    "    annotated = os.listdir(os.path.join(annotated_folder, class_folder))\n",
    "    for a in annotated:\n",
    "        # alt_name takes into account the same name with ignoring one _ at the end\n",
    "        alt_name = '.'.join(a.split('.')[:-1])[:-1] + '.jpg'\n",
    "        found_states = [a in site_images[site] for site in sites]\n",
    "        found = any(found_states)\n",
    "        alt_found = any([alt_name in site_images[site] for site in sites])\n",
    "        found = found or alt_found\n",
    "        if not found:\n",
    "            print(f'{class_folder}: {a}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A funciton to find the source site of a given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_site_and_threshold(im_name):\n",
    "    found_states = [im_name in site_images[site] for site in sites]\n",
    "    \n",
    "    if any(found_states):\n",
    "        site = sites[np.argmax(found_states)]\n",
    "        threshold = site_thresholds[site]\n",
    "    else:\n",
    "        site = 'unknown'\n",
    "        threshold = default_threshold\n",
    "        \n",
    "    return site, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define curve to assign diff_coef according to diff_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_metric_to_diff_coef(sigma_dist):\n",
    "    \n",
    "    # Based on Sigmoid\n",
    "    # adding alpha, beta and gamma controls, as explained at the\n",
    "    # beginning of this notebook\n",
    "    \n",
    "    return 1/(1 + np.exp(-(sigma_dist*alfa-beta)*gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {'in_name': [],\n",
    "              'out_name': [],\n",
    "              'class_name': [],\n",
    "              'diff_metric': [],\n",
    "              'diff_coef': [],\n",
    "              'sample_weight': []\n",
    "             }\n",
    "diff_metrics = {'no_obstacle': [], 'obstacle': []}\n",
    "class_names = ['no_obstacle', 'obstacle']\n",
    "subset_name = 'train'\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(in_folder, subset_name, class_name)\n",
    "    im_names = os.listdir(class_path)\n",
    "    for im_name in tqdm(im_names):\n",
    "        im_path = os.path.join(class_path, im_name)\n",
    "        pair = cv2.imread(im_path)\n",
    "\n",
    "        # Generate diff mask            \n",
    "        w = pair.shape[1]\n",
    "        ref = pair[:, :w//2]\n",
    "        current = pair[:, w//2:]\n",
    "        diff = cv2.subtract(ref, current)\n",
    "        agg_rgb = np.stack((diff[:, :, 0], diff[:, :, 1], diff[:, :, 2])).max(0)\n",
    "        _, mask = cv2.threshold(agg_rgb, diff_threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Calculate diff_coeff\n",
    "        h = mask.shape[0]\n",
    "        w = mask.shape[1]\n",
    "        area = h * w\n",
    "\n",
    "        # Update train dictionary\n",
    "        train_dict['in_name'].append(im_name)\n",
    "        train_dict['class_name'].append(class_name)\n",
    "        diff_metric = (np.sum(mask)/255)/area\n",
    "        if class_name == 'obstacle':\n",
    "            diff_metric = 1.0 - diff_metric\n",
    "        train_dict['diff_metric'].append(diff_metric)    \n",
    "        diff_metrics[class_name].append(diff_metric)\n",
    "            \n",
    "mean = {'no_obstacle': np.mean(diff_metrics['no_obstacle']),\n",
    "        'obstacle': np.mean(diff_metrics['obstacle'])}\n",
    "std = {'no_obstacle': np.std(diff_metrics['no_obstacle']),\n",
    "       'obstacle': np.std(diff_metrics['obstacle']) }\n",
    "\n",
    "for i, diff_metric in enumerate(train_dict['diff_metric']):\n",
    "    class_name = train_dict['class_name'][i]\n",
    "    diff_threshold = mean[class_name] + std_threshold_dist * std['obstacle']\n",
    "    sigma_dist = abs(diff_metric - diff_threshold)/std[class_name]\n",
    "    diff_coef = 0.0 # By default, if this image isn't an \"outlier\" for its class\n",
    "    if class_name == 'obstacle' and diff_metric < diff_threshold  or\\\n",
    "       class_name == 'no_obstacle' and diff_metric > diff_threshold:\n",
    "        diff_coef = diff_metric_to_diff_coef(sigma_dist)\n",
    "    sample_weight = 1.0 + swc * diff_coef\n",
    "    train_dict['diff_coef'].append(diff_coef)\n",
    "    train_dict['sample_weight'].append(sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function to generate <ref, current, mask> triplet from <ref, current> pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_image(pair, threshold):\n",
    "    w = pair.shape[1]\n",
    "    ref = pair[:, :w//2]\n",
    "    current = pair[:, w//2:]\n",
    "    diff = cv2.absdiff(current, ref)\n",
    "    agg_rgb = np.stack((diff[:, :, 0], diff[:, :, 1], diff[:, :, 2])).max(0)\n",
    "    _, mask = cv2.threshold(agg_rgb, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # old morphological operations\n",
    "    copyImg = cv2.erode(mask, np.ones((3, 3), np.uint8), iterations=1)  # reduce noise\n",
    "    copyImg = cv2.dilate(copyImg, np.ones((7, 7), np.uint8), iterations=1)\n",
    "    copyImg = cv2.erode(copyImg, np.ones((5, 5), np.uint8), iterations=1)\n",
    "    copyImg = cv2.dilate(copyImg, np.ones((9, 9), np.uint8), iterations=1)\n",
    "    kernel = np.ones((11, 11), np.uint8)  # kernel for dilation\n",
    "\n",
    "    # increase area to an object\n",
    "    copyImg = cv2.dilate(copyImg, kernel, iterations=2)\n",
    "    copyImg = cv2.dilate(copyImg, np.ones((13, 13), np.uint8), iterations=1)\n",
    "    copyImg = cv2.erode(copyImg, np.ones((11, 11), np.uint8), iterations=1)\n",
    "    copyImg = cv2.erode(copyImg, np.ones((5, 5), np.uint8), iterations=1)\n",
    "\n",
    "    mask = copyImg \n",
    "    \n",
    "    return cv2.hconcat([ref[:, :, 1], current[:, :, 1], mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate triplet images <ref, current, mask>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_names = ['train', 'eval']\n",
    "class_names = ['no_obstacle', 'obstacle']\n",
    "class_extensions = {'no_obstacle': 'noobs', 'obstacle': 'obs'}\n",
    "\n",
    "for subset_name in subset_names:\n",
    "    cur_out_folder = os.path.join(out_folder, subset_name)\n",
    "    Path(cur_out_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prepare indices for shuffling the images in dictionary, so onstacle/no_obstacle are mixed\n",
    "# This is necessary for the training/validation from corresponding dataframe to work properly\n",
    "\n",
    "keys = list(train_dict.keys())\n",
    "shuffled_train_dict = {}\n",
    "inds = [i for i in range(len(train_dict['in_name']))]\n",
    "shuffled = inds.copy()\n",
    "random.shuffle(shuffled)\n",
    "for k in keys:\n",
    "    if len(train_dict[k]) > 0:\n",
    "        shuffled_train_dict[k] = [train_dict[k][shuffled[i]] for i in range(len(train_dict['in_name']))]\n",
    "    else:\n",
    "        shuffled_train_dict[k] = []\n",
    "    \n",
    "subset_name = 'train'\n",
    "i = 0\n",
    "for im_name in tqdm(shuffled_train_dict['in_name']):\n",
    "    class_name = shuffled_train_dict['class_name'][i]\n",
    "    class_path = os.path.join(in_folder, subset_name, class_name)\n",
    "    im_path = os.path.join(class_path, im_name)\n",
    "    pair = cv2.imread(im_path)\n",
    "    site, threshold = find_site_and_threshold(im_name)\n",
    "    triplet = triplet_image(pair, threshold)\n",
    "    class_extension = class_extensions[class_name]\n",
    "    sample_weight = shuffled_train_dict['sample_weight'][i]\n",
    "    out_im_name = '.'.join(im_name.split('.')[:-1])\\\n",
    "         + f'_{site}_{class_extension}_{sample_weight:.4f}_.jpg'\n",
    "    shuffled_train_dict['out_name'].append(out_im_name)\n",
    "    cur_out_folder = os.path.join(out_folder, subset_name)\n",
    "    out_path = os.path.join(cur_out_folder, out_im_name)\n",
    "    cv2.imwrite(out_path, triplet)\n",
    "    i += 1\n",
    "    \n",
    "subset_name = 'eval'\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(in_folder, subset_name, class_name)\n",
    "    im_names = os.listdir(class_path)\n",
    "    cur_out_folder = os.path.join(out_folder, subset_name, class_name)\n",
    "    Path(cur_out_folder).mkdir(parents=True, exist_ok=True)\n",
    "    for im_name in tqdm(im_names):\n",
    "        im_path = os.path.join(class_path, im_name)\n",
    "        pair = cv2.imread(im_path)\n",
    "        site, threshold = find_site_and_threshold(im_name)\n",
    "        triplet = triplet_image(pair, threshold)\n",
    "        out_im_name = '.'.join(im_name.split('.')[:-1]) + f'_{site}_.jpg'\n",
    "        out_path = os.path.join(cur_out_folder, out_im_name)\n",
    "        cv2.imwrite(out_path, triplet)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe from sample_weights Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(shuffled_train_dict[k]) for k in shuffled_train_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame.from_dict(shuffled_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the Dataframe in a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = out_folder.split('/')[-1] + '.csv'\n",
    "csv_path = os.path.join(out_folder, csv_name)\n",
    "train_df.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean['obstacle'], std['obstacle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
