{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = '/home/drevital/obstacles_classification_datasets/obstacle_classification_RGB_data'\n",
    "annotated_folder = '/home/drevital/obstacles_classification_datasets/rgb_6/annotated'\n",
    "in_folder = '/home/drevital/obstacles_classification_datasets/test_rgb_6'\n",
    "out_folder = '/home/drevital/obstacles_classification_datasets/test_compare_boosts'\n",
    "sites = ['_'.join(s.split('_')[:-2]) for s in os.listdir(src_folder)]\n",
    "\n",
    "# Parameters used in the diff_metric to diff_coef assignent function\n",
    "alfa = -3.5\n",
    "beta = 2.0\n",
    "gamma = 8\n",
    "swc = 1.0 # sample weight coefficient\n",
    "diff_threshold = 50\n",
    "std_threshold_dist = 1.5 # Distance from std to apply sample_weight correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['musashi_office',\n",
       " 'koki_factory',\n",
       " 'israel',\n",
       " 'new_factory',\n",
       " 'new_factory_humid']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_thresholds = {'israel': 55, 'new_factory': 50, 'new_factory_humid': 50, 'musashi_office': 40, 'koki_factory': 40}\n",
    "default_threshold = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dictionary for the image names of each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_images = defaultdict(list)\n",
    "\n",
    "for site in sites:\n",
    "    site_folder = os.path.join(src_folder, site + '_rgb_data','all_data')\n",
    "    class_folders = os.listdir(site_folder)\n",
    "    for cls in class_folders:\n",
    "        site_images[site] += [f for f in os.listdir(os.path.join(site_folder,cls))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List images not found in any site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obstacle: 43_1561__reversed.jpg\n",
      "obstacle: 43_1697__reversed.jpg\n",
      "obstacle: 1_1235_1_reversed.jpg\n",
      "obstacle: 43_1589__reversed.jpg\n",
      "obstacle: 1_1195_1_reversed.jpg\n",
      "obstacle: 43_1665__reversed.jpg\n",
      "obstacle: 1_1031_1_reversed.jpg\n",
      "obstacle: 43_1625__reversed.jpg\n",
      "obstacle: 43_1525__reversed.jpg\n",
      "obstacle: 1_725__reversed.jpg\n",
      "obstacle: 1_1131_1_reversed.jpg\n",
      "obstacle: 1_1027_1_reversed.jpg\n",
      "obstacle: 43_1689__reversed.jpg\n",
      "obstacle: 1_1035_1_reversed.jpg\n",
      "obstacle: 43_1485__reversed.jpg\n",
      "obstacle: 1_1111_1_reversed.jpg\n",
      "obstacle: 1_1135_1_reversed.jpg\n",
      "obstacle: 1_1159_1_reversed.jpg\n",
      "obstacle: 43_1645__reversed.jpg\n",
      "obstacle: 43_1509__reversed.jpg\n",
      "obstacle: 1_1071_1_reversed.jpg\n",
      "obstacle: 1_1147_1_reversed.jpg\n",
      "obstacle: 43_1541__reversed.jpg\n",
      "obstacle: 43_1661__reversed.jpg\n",
      "obstacle: 43_1669__reversed.jpg\n",
      "obstacle: 43_1677__reversed.jpg\n",
      "obstacle: 1_1175_1_reversed.jpg\n",
      "obstacle: 43_1569__reversed.jpg\n",
      "obstacle: 43_1649__reversed.jpg\n",
      "obstacle: 1_745__reversed.jpg\n",
      "obstacle: 1_1263_1_reversed.jpg\n",
      "obstacle: 1_1067_1_reversed.jpg\n",
      "obstacle: 1_1079_1_reversed.jpg\n",
      "obstacle: 1_1171_1_reversed.jpg\n",
      "obstacle: 1_987__reversed.jpg\n",
      "obstacle: 43_1493__reversed.jpg\n",
      "obstacle: 1_1047_1_reversed.jpg\n",
      "obstacle: 1_737__reversed.jpg\n",
      "obstacle: 1_1127__reversed.jpg\n",
      "obstacle: 43_1613__reversed.jpg\n",
      "obstacle: 1_1059_1_reversed.jpg\n",
      "obstacle: 1_1167_1_reversed.jpg\n",
      "obstacle: 1_1179_1_reversed.jpg\n",
      "obstacle: 43_1681__reversed.jpg\n",
      "obstacle: 1_1267__reversed.jpg\n",
      "obstacle: 30_468__reversed.jpg\n",
      "obstacle: 1_1255_1_reversed.jpg\n",
      "obstacle: 43_1693__reversed.jpg\n",
      "obstacle: 1_1103_1_reversed.jpg\n",
      "obstacle: 1_1227_1_reversed.jpg\n",
      "obstacle: 1_1223_1_reversed.jpg\n",
      "obstacle: 43_1585__reversed.jpg\n",
      "obstacle: 1_749__reversed.jpg\n",
      "obstacle: 43_1637__reversed.jpg\n",
      "obstacle: 1_1199_1_reversed.jpg\n",
      "obstacle: 1_733__reversed.jpg\n",
      "obstacle: 1_991__reversed.jpg\n",
      "obstacle: 11_306__reversed.jpg\n",
      "obstacle: 43_1729__reversed.jpg\n",
      "obstacle: 1_1231_1_reversed.jpg\n",
      "obstacle: 1_1139_1_reversed.jpg\n",
      "obstacle: 43_1653__reversed.jpg\n",
      "obstacle: 1_999__reversed.jpg\n",
      "obstacle: 1_1055_1_reversed.jpg\n",
      "obstacle: 33_521__reversed.jpg\n",
      "obstacle: 43_1605__reversed.jpg\n",
      "obstacle: 33_517__reversed.jpg\n",
      "obstacle: 1_1163_1_reversed.jpg\n",
      "obstacle: 43_1513__reversed.jpg\n",
      "obstacle: 43_1577__reversed.jpg\n",
      "obstacle: 43_1721__reversed.jpg\n",
      "obstacle: 43_1633__reversed.jpg\n",
      "obstacle: 43_1581__reversed.jpg\n",
      "obstacle: 43_1601__reversed.jpg\n",
      "obstacle: 43_1537__reversed.jpg\n",
      "obstacle: 1_717__reversed.jpg\n",
      "obstacle: 11_302__reversed.jpg\n",
      "obstacle: 43_1557__reversed.jpg\n",
      "obstacle: 43_1505__reversed.jpg\n",
      "obstacle: 1_1043_1_reversed.jpg\n",
      "obstacle: 43_1501__reversed.jpg\n",
      "obstacle: 30_460__reversed.jpg\n",
      "obstacle: 1_1091_1_reversed.jpg\n",
      "obstacle: 43_1521__reversed.jpg\n",
      "obstacle: 1_1187_1_reversed.jpg\n",
      "obstacle: 1_1075_1_reversed.jpg\n",
      "obstacle: 43_1641__reversed.jpg\n",
      "obstacle: 1_1215_1_reversed.jpg\n",
      "obstacle: 43_1565__reversed.jpg\n",
      "obstacle: 1_1259_1_reversed.jpg\n",
      "obstacle: 1_1039_1_reversed.jpg\n",
      "obstacle: 43_1741__reversed.jpg\n",
      "obstacle: 11_310__reversed.jpg\n",
      "obstacle: 43_1593__reversed.jpg\n",
      "obstacle: 1_1151_1_reversed.jpg\n",
      "obstacle: 43_1657__reversed.jpg\n",
      "obstacle: 1_1115_1_reversed.jpg\n",
      "obstacle: 1_1095_1_reversed.jpg\n",
      "obstacle: 43_1553__reversed.jpg\n",
      "obstacle: 1_995__reversed.jpg\n",
      "obstacle: 1_1143_1_reversed.jpg\n",
      "obstacle: 43_1597__reversed.jpg\n",
      "obstacle: 1_753__reversed.jpg\n",
      "obstacle: 43_1621__reversed.jpg\n",
      "obstacle: 1_1051_1_reversed.jpg\n",
      "obstacle: 43_1673__reversed.jpg\n",
      "obstacle: 1_1243_1_reversed.jpg\n",
      "obstacle: 1_757__reversed.jpg\n",
      "obstacle: 1_1099_1_reversed.jpg\n",
      "obstacle: 43_1609__reversed.jpg\n",
      "obstacle: 43_1629__reversed.jpg\n",
      "obstacle: 1_1155_1_reversed.jpg\n",
      "obstacle: 43_1489__reversed.jpg\n",
      "obstacle: 43_1529__reversed.jpg\n",
      "obstacle: 43_1517__reversed.jpg\n",
      "obstacle: 1_1251_1_reversed.jpg\n",
      "obstacle: 1_1183_1_reversed.jpg\n",
      "obstacle: 43_1617__reversed.jpg\n",
      "obstacle: 1_1123_1_reversed.jpg\n",
      "obstacle: 1_1083_1_reversed.jpg\n",
      "obstacle: 1_1239_1_reversed.jpg\n",
      "obstacle: 30_464__reversed.jpg\n",
      "obstacle: 1_1191_1_reversed.jpg\n",
      "obstacle: 1_721__reversed.jpg\n",
      "obstacle: 1_1219_1_reversed.jpg\n",
      "obstacle: 1_1211_1_reversed.jpg\n",
      "obstacle: 1_1271__reversed.jpg\n",
      "obstacle: 1_1087_1_reversed.jpg\n",
      "obstacle: 43_1725__reversed.jpg\n",
      "obstacle: 43_1685__reversed.jpg\n",
      "obstacle: 1_1119_1_reversed.jpg\n",
      "obstacle: 1_729__reversed.jpg\n",
      "obstacle: 1_1203_1_reversed.jpg\n",
      "obstacle: 43_1545__reversed.jpg\n",
      "obstacle: 43_1533__reversed.jpg\n",
      "obstacle: 1_1063_1_reversed.jpg\n",
      "obstacle: 1_1207_1_reversed.jpg\n",
      "obstacle: 43_1573__reversed.jpg\n",
      "obstacle: 43_1497__reversed.jpg\n",
      "obstacle: 43_1733__reversed.jpg\n",
      "obstacle: 43_1549__reversed.jpg\n"
     ]
    }
   ],
   "source": [
    "class_folders = ['no_obstacle', 'obstacle']\n",
    "\n",
    "for class_folder in class_folders:\n",
    "    annotated = os.listdir(os.path.join(annotated_folder, class_folder))\n",
    "    for a in annotated:\n",
    "        # alt_name takes into account the same name with ignoring one _ at the end\n",
    "        alt_name = '.'.join(a.split('.')[:-1])[:-1] + '.jpg'\n",
    "        found_states = [a in site_images[site] for site in sites]\n",
    "        found = any(found_states)\n",
    "        alt_found = any([alt_name in site_images[site] for site in sites])\n",
    "        found = found or alt_found\n",
    "        if not found:\n",
    "            print(f'{class_folder}: {a}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A funciton to find the source site of a given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_site_and_threshold(im_name):\n",
    "    found_states = [im_name in site_images[site] for site in sites]\n",
    "    \n",
    "    if any(found_states):\n",
    "        site = sites[np.argmax(found_states)]\n",
    "        threshold = site_thresholds[site]\n",
    "    else:\n",
    "        site = 'unknown'\n",
    "        threshold = default_threshold\n",
    "        \n",
    "    return site, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define curve to assign diff_coef according to diff_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_metric_to_diff_coef(sigma_dist):\n",
    "    \n",
    "    # Correction curve for assigning coefficients\n",
    "    # Based on Sigmoid\n",
    "    # adding alpha, beta and gamma controls, as explained at the\n",
    "    # beginning of this notebook\n",
    "    \n",
    "    return 1/(1 + np.exp(-(sigma_dist*alfa-beta)*gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.2) /tmp/pip-req-build-vrhoqk3o/opencv/modules/core/src/arithm.cpp:647: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-fc01aa896e6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0magg_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.2) /tmp/pip-req-build-vrhoqk3o/opencv/modules/core/src/arithm.cpp:647: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'arithm_op'\n"
     ]
    }
   ],
   "source": [
    "train_dict = {'in_name': [],\n",
    "              'out_name': [],\n",
    "              'class_name': [],\n",
    "              'diff_metric': [],\n",
    "              'diff_coef': [],\n",
    "              'sample_weight': []\n",
    "             }\n",
    "diff_metrics = {'no_obstacle': [], 'obstacle': []}\n",
    "class_names = ['no_obstacle', 'obstacle']\n",
    "subset_name = 'train'\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(in_folder, subset_name, class_name)\n",
    "    im_names = os.listdir(class_path)\n",
    "    for im_name in tqdm(im_names):\n",
    "        im_path = os.path.join(class_path, im_name)\n",
    "        pair = cv2.imread(im_path)\n",
    "\n",
    "        # Generate diff mask            \n",
    "        w = pair.shape[1]\n",
    "        ref = pair[:, :w//2]\n",
    "        current = pair[:, w//2:w//2+w//2]\n",
    "        diff = cv2.subtract(ref, current)\n",
    "        agg_rgb = np.stack((diff[:, :, 0], diff[:, :, 1], diff[:, :, 2])).max(0)\n",
    "        _, mask = cv2.threshold(agg_rgb, diff_threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Calculate diff_coeff\n",
    "        h = mask.shape[0]\n",
    "        w = mask.shape[1]\n",
    "        area = h * w\n",
    "\n",
    "        # Update train dictionary\n",
    "        train_dict['in_name'].append(im_name)\n",
    "        train_dict['class_name'].append(class_name)\n",
    "        diff_metric = (np.sum(mask)/255)/area\n",
    "        train_dict['diff_metric'].append(diff_metric)    \n",
    "        diff_metrics[class_name].append(diff_metric)\n",
    "            \n",
    "mean = {'no_obstacle': np.mean(diff_metrics['no_obstacle']),\n",
    "        'obstacle': np.mean(diff_metrics['obstacle'])}\n",
    "std = {'no_obstacle': np.std(diff_metrics['no_obstacle']),\n",
    "       'obstacle': np.std(diff_metrics['obstacle']) }\n",
    "\n",
    "for i, diff_metric in enumerate(train_dict['diff_metric']):\n",
    "    class_name = train_dict['class_name'][i]\n",
    "    # Following is to adjust the direction of distance from std and correction accordingly\n",
    "    # For obstacle - a negative sigma means we are lower than threshold and need correction\n",
    "    # For no obstacle a positive sigma means we are higher than threshold and need correction\n",
    "    sigma_dist_sign = 1.0 if class_name == 'obstacle' else -1.0 \n",
    "    diff_threshold = mean[class_name] + sigma_dist_sign * std_threshold_dist * std['obstacle']\n",
    "    sigma_dist = sigma_dist_sign * (diff_metric - diff_threshold)/std[class_name]\n",
    "    diff_coef = diff_metric_to_diff_coef(sigma_dist)\n",
    "    sample_weight = 1.0 + swc * diff_coef\n",
    "    train_dict['diff_coef'].append(diff_coef)\n",
    "    train_dict['sample_weight'].append(sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function to generate <ref, current, mask> triplet from <ref, current> pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_image(pair, threshold):\n",
    "    w = pair.shape[1]\n",
    "    ref = pair[:, :w//2]\n",
    "    current = pair[:, w//2:w//2+w//2]\n",
    "    diff = cv2.subtract(ref, current)\n",
    "    agg_rgb = np.stack((diff[:, :, 0], diff[:, :, 1], diff[:, :, 2])).max(0)\n",
    "    _, mask = cv2.threshold(agg_rgb, diff_threshold, 255, cv2.THRESH_BINARY)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)  \n",
    "    \n",
    "    return cv2.hconcat([ref, current, mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate triplet images <ref, current, mask>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_names = ['train', 'eval']\n",
    "class_names = ['no_obstacle', 'obstacle']\n",
    "class_extensions = {'no_obstacle': 'noobs', 'obstacle': 'obs'}\n",
    "\n",
    "for subset_name in subset_names:\n",
    "    cur_out_folder = os.path.join(out_folder, subset_name)\n",
    "    Path(cur_out_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prepare indices for shuffling the images in dictionary, so onstacle/no_obstacle are mixed\n",
    "# This is necessary for the training/validation from corresponding dataframe to work properly\n",
    "\n",
    "keys = list(train_dict.keys())\n",
    "shuffled_train_dict = {}\n",
    "inds = [i for i in range(len(train_dict['in_name']))]\n",
    "shuffled = inds.copy()\n",
    "random.shuffle(shuffled)\n",
    "for k in keys:\n",
    "    if len(train_dict[k]) > 0:\n",
    "        shuffled_train_dict[k] = [train_dict[k][shuffled[i]] for i in range(len(train_dict['in_name']))]\n",
    "    else:\n",
    "        shuffled_train_dict[k] = []\n",
    "    \n",
    "subset_name = 'train'\n",
    "i = 0\n",
    "for im_name in tqdm(shuffled_train_dict['in_name']):\n",
    "    class_name = shuffled_train_dict['class_name'][i]\n",
    "    class_path = os.path.join(in_folder, subset_name, class_name)\n",
    "    im_path = os.path.join(class_path, im_name)\n",
    "    pair = cv2.imread(im_path)\n",
    "    site, threshold = find_site_and_threshold(im_name)\n",
    "    triplet = triplet_image(pair, threshold)\n",
    "    class_extension = class_extensions[class_name]\n",
    "    sample_weight = shuffled_train_dict['sample_weight'][i]\n",
    "    out_im_name = '.'.join(im_name.split('.')[:-1])\\\n",
    "         + f'_{site}_{class_extension}_{sample_weight:.4f}_.jpg'\n",
    "    shuffled_train_dict['out_name'].append(out_im_name)\n",
    "    cur_out_folder = os.path.join(out_folder, subset_name)\n",
    "    out_path = os.path.join(cur_out_folder, out_im_name)\n",
    "    cv2.imwrite(out_path, triplet)\n",
    "    i += 1\n",
    "    \n",
    "subset_name = 'eval'\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(in_folder, subset_name, class_name)\n",
    "    im_names = os.listdir(class_path)\n",
    "    cur_out_folder = os.path.join(out_folder, subset_name, class_name)\n",
    "    Path(cur_out_folder).mkdir(parents=True, exist_ok=True)\n",
    "    for im_name in tqdm(im_names):\n",
    "        im_path = os.path.join(class_path, im_name)\n",
    "        pair = cv2.imread(im_path)\n",
    "        site, threshold = find_site_and_threshold(im_name)\n",
    "        triplet = triplet_image(pair, threshold)\n",
    "        out_im_name = '.'.join(im_name.split('.')[:-1]) + f'_{site}_.jpg'\n",
    "        out_path = os.path.join(cur_out_folder, out_im_name)\n",
    "        cv2.imwrite(out_path, triplet)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe from sample_weights Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(shuffled_train_dict[k]) for k in shuffled_train_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame.from_dict(shuffled_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the Dataframe in a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = out_folder.split('/')[-1] + '.csv'\n",
    "csv_path = os.path.join(out_folder, csv_name)\n",
    "train_df.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean['obstacle'], std['obstacle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean['no_obstacle'], std['no_obstacle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
