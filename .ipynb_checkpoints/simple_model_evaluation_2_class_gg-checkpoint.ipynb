{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=400,\n",
    "                 img_height=200,\n",
    "                 batch_size=32):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.obstacle_images = []\n",
    "        self.no_obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_obstacles = 0\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen(self.batch_size)\n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self, batch_size):\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen, batch_size=batch_size)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    "\n",
    "    # Special generator to generate the 3 parts of the input image as 3 separate input images\n",
    "    def two_im_generator(self, gen, dataset, target_size, batch_size, class_mode):\n",
    "\n",
    "        im_gen = gen.flow_from_directory(dataset, \n",
    "                                         target_size=target_size, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         color_mode='grayscale',\n",
    "                                         class_mode=class_mode)\n",
    "        self.filenames = im_gen.filenames\n",
    "\n",
    "        while True:\n",
    "            im1_s, im2_s = [], []\n",
    "            images, labels = im_gen.next()\n",
    "\n",
    "            for im in images:\n",
    "                w = im.shape[1]\n",
    "                im1 = im[:, :w//2]\n",
    "                im2 = im[:, w//2:] \n",
    "                im1_s.append(im1)\n",
    "                im2_s.append(im2)\n",
    "\n",
    "            im1_s = np.array(im1_s)\n",
    "            im2_s = np.array(im2_s)\n",
    "            yield [im1_s, im2_s], labels\n",
    "                        \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.two_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = self.two_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        \n",
    "    # Compute and plot multi-class confusion-matrix with normalization\n",
    "    def plot_cm_normalized(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold)\n",
    "        # Normalise\n",
    "        cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        sns.heatmap(cmn, annot=True, fmt='.3f')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show(block=False)  \n",
    "        \n",
    "    def display_false_positives(self, predictions, threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        if 500 > len(false_positives) > 1:\n",
    "            num_images = len(false_positives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_positives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                print(f'FP prediction: {preds[i]}, imname: {imname}')\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_positives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show()\n",
    "            \n",
    "    def display_false_negatives(self, predictions, threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "\n",
    "        if 500 > len(false_negatives) > 1:\n",
    "            num_images = len(false_negatives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_negatives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_negatives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show()   \n",
    "            \n",
    "    def save_false_positives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'false_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "    def save_false_negatives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'false_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 1432 images belonging to 2 classes.\n",
      "Found 1432 images belonging to 2 classes.\n",
      "45/45 [==============================] - 12s 260ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Variables --\n",
    "model_path = '/home/drevital/cs_video_processor/models/gg_16_256'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/gg/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'rgb'\n",
    "threshold = 0.70\n",
    "batch_size = 32\n",
    "save_base_path = '/home/drevital/obstacles_classification_datasets/model_eval'\n",
    "save_name = dataset.split('/')[-2] + '_' + str(threshold)\n",
    "save_path = os.path.join(save_base_path, save_name)\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, dataset, batch_size=batch_size)\n",
    "\n",
    "# -- Define Labels\n",
    "labels = np.array([0]*handler.num_no_obstacles\\\n",
    "                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "# -- Print confision-matrix\n",
    "handler.plot_cm_normalized(model_path, labels, predictions, threshold=threshold)\n",
    "\n",
    "# -- Save False Negatives\n",
    "handler.save_false_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "handler.save_false_positives(predictions, threshold=threshold, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
