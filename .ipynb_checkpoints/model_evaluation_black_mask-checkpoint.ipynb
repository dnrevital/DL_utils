{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=600,\n",
    "                 img_height=200,\n",
    "                 batch_size=32):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.obstacle_images = []\n",
    "        self.no_obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_obstacles = 0\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen(self.batch_size)\n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self, batch_size):\n",
    "        datagen = ImageDataGenerator()\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen, batch_size=batch_size)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    "\n",
    "    # Special generator to generate the 3 parts of the input image as 3 separate input images\n",
    "    def three_im_generator(self,\n",
    "                           gen,\n",
    "                           dataset,\n",
    "                           target_size,\n",
    "                           comp_target_size,\n",
    "                           batch_size,\n",
    "                           class_mode):\n",
    "\n",
    "        im_gen = gen.flow_from_directory(dataset, \n",
    "                                         target_size=target_size, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         class_mode=class_mode)\n",
    "        self.filenames = im_gen.filenames\n",
    "\n",
    "        while True:\n",
    "            im1_s, im2_s, im3_s = [], [], []\n",
    "            images, labels = im_gen.next()\n",
    "\n",
    "            for im in images:\n",
    "                imarr = np.array(im, dtype='float32')\n",
    "                w = imarr.shape[1]\n",
    "                im2 = imarr[:, w//3:(w*2)//3] \n",
    "                im3 = imarr[:, (w*2)//3:] \n",
    "                im1 = np.array(im2)\n",
    "                im3 = cv2.cvtColor(im3, cv2.COLOR_RGB2GRAY)\n",
    "                im1 /= 255.0\n",
    "                im2 /= 255.0\n",
    "                im3 /= 255.0\n",
    "                \n",
    "                im1_s.append(im1)\n",
    "                im2_s.append(im2)\n",
    "                im3_s.append(im3)\n",
    "                \n",
    "            im1_s = np.array(im1_s)\n",
    "            im2_s = np.array(im2_s)\n",
    "            im3_s = np.array(im3_s)\n",
    "            \n",
    "            yield [im1_s, im2_s, im3_s], labels\n",
    "                        \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            comp_target_size=(self.img_height, self.img_height),\n",
    "            batch_size=self.batch_size,\n",
    "            #class_mode='binary'\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            comp_target_size=(self.img_height, self.img_height),\n",
    "            batch_size=self.batch_size,\n",
    "            #class_mode='binary'\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        \n",
    "    # Compute and plot multi-class confusion-matrix with normalization\n",
    "    def plot_cm_normalized(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold)\n",
    "        print(f'cm: {cm}')\n",
    "        # Normalise\n",
    "        cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        sns.heatmap(cmn, annot=True, fmt='.3f')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show(block=False)  \n",
    "                \n",
    "    def save_false_positives(self, predictions, threshold, save_path):\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'false_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fp_preds = [p[0] for p in preds]\n",
    "        return fp_preds\n",
    "            \n",
    "    def save_true_positives(self, predictions, threshold, save_path):\n",
    "        true_positives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'true_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "\n",
    "    def save_false_negatives(self, predictions, threshold, save_path):\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'false_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fn_preds = [p[0] for p in preds]\n",
    "        return fn_preds\n",
    "            \n",
    "    def save_true_negatives(self, predictions, threshold, save_path):\n",
    "        true_negatives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'true_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "    def calc_recall(self, predictions, threshold=0.5):\n",
    "        true_positives = sum([predictions[self.num_no_obstacles+i] >= threshold\\\n",
    "                            for i in range(self.num_obstacles)])\n",
    "        false_negatives = sum([predictions[self.num_no_obstacles+i] < threshold\\\n",
    "                            for i in range(self.num_obstacles)])\n",
    "        \n",
    "        return true_positives / (true_positives + false_negatives)\n",
    "                           \n",
    "    def calc_specifity(self, predictions, threshold=0.5):\n",
    "        true_negatives = sum([predictions[i] <= threshold\\\n",
    "                            for i in range(self.num_no_obstacles)])\n",
    "        false_positives = sum([predictions[i] > threshold\\\n",
    "                            for i in range(self.num_no_obstacles)])\n",
    "        \n",
    "        return true_negatives / (true_negatives + false_positives)\n",
    "        \n",
    "    def calc_accuracy(self, predictions, threshold=0.5):\n",
    "        true_positives = sum([predictions[self.num_no_obstacles+i] >= threshold\\\n",
    "                            for i in range(self.num_obstacles)])\n",
    "        true_negatives = sum([predictions[i] <= threshold\\\n",
    "                            for i in range(self.num_no_obstacles)])\n",
    "        \n",
    "        return (true_positives + true_negatives) / len(predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 1493 images belonging to 2 classes.\n",
      "Found 1493 images belonging to 2 classes.\n",
      "47/47 [==============================] - 17s 349ms/step\n",
      "cm: [[732  14]\n",
      " [ 28 719]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Variables --\n",
    "model_path = '/home/drevital/cs_video_processor/models/jan23_d_22_15'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/jan23_d_22_15/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'rgb'\n",
    "thresholds = [0.28]\n",
    "batch_size = 32\n",
    "save_base_path = '/home/drevital/obstacles_classification_datasets/model_eval'\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, dataset, batch_size=batch_size)\n",
    "\n",
    "# -- Define Labels\n",
    "labels = np.array([0]*handler.num_no_obstacles\\\n",
    "                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # -- Print confision-matrix\n",
    "    handler.plot_cm_normalized(model_path, labels, predictions, threshold=threshold)\n",
    "\n",
    "    # -- Save Images\n",
    "    #save_name = dataset.split('/')[-2] + '_' + str(threshold)\n",
    "    save_name = model_name + '_' + str(threshold) + '_ref_as_current'\n",
    "    save_path = os.path.join(save_base_path, save_name)\n",
    "    fn_preds = handler.save_false_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    fp_preds = handler.save_false_positives(predictions, threshold=threshold, save_path=save_path)\n",
    "    #handler.save_true_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    #handler.save_true_positives(predictions, threshold=threshold, save_path=save_path)\n",
    "    #print(f'Recall: {handler.calc_recall(predictions)}')\n",
    "    #print(f'Specifity: {handler.calc_specifity(predictions)}')\n",
    "    #print(f'Accuracy: {handler.calc_accuracy(predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
