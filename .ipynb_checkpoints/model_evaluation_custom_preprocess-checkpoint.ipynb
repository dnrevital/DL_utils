{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Custom Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self,\n",
    "                 obs_dir,\n",
    "                 no_obs_dir,\n",
    "                 batch_size=32,\n",
    "                 input_size=(200, 200),\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        obs_imnames = os.listdir(obs_dir)\n",
    "        no_obs_imnames = os.listdir(no_obs_dir)\n",
    "        self.obs = [[os.path.join(obs_dir, name), 1] for name in obs_imnames]\n",
    "        self.no_obs = [[os.path.join(no_obs_dir, name), 0] for name in no_obs_imnames]\n",
    "        self.items = self.obs + self.no_obs\n",
    "        self.n = len(self.items)\n",
    "        self.steps = math.ceil(self.n/self.batch_size)\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.items)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = min((index+1) * self.batch_size, self.n)\n",
    "        items = self.items[start:end]\n",
    "        im1_s, im2_s, im3_s, labels = [], [], [], []\n",
    "\n",
    "        for item in items:\n",
    "            im = cv2.imread(item[0])\n",
    "            imarr = np.array(im, dtype='float32')\n",
    "            w = imarr.shape[1]\n",
    "\n",
    "            im1 = imarr[:, :w//3]\n",
    "            im2 = imarr[:, w//3:(w*2)//3] \n",
    "            im3 = imarr[:, (w*2)//3:] \n",
    "\n",
    "            im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "            im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "            im3 = cv2.cvtColor(im3, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            im1 = cv2.resize(im1, dsize=self.input_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "            im2 = cv2.resize(im2, dsize=self.input_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "            im3 = cv2.resize(im3, dsize=self.input_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            im1 /= 255.0\n",
    "            im2 /= 255.0\n",
    "            im3 /= 255.0\n",
    "\n",
    "            im1_s.append(im1)\n",
    "            im2_s.append(im2)\n",
    "            im3_s.append(im3)\n",
    "            labels.append(item[1])\n",
    "\n",
    "        im1_s = np.array(im1_s)\n",
    "        im2_s = np.array(im2_s)\n",
    "        im3_s = np.array(im3_s)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        return [im1_s, im2_s, im3_s], labels \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=600,\n",
    "                 img_height=200,\n",
    "                 batch_size=32):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.obstacle_images = []\n",
    "        self.no_obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_obstacles = 0\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen(self.batch_size)\n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self, batch_size):\n",
    "        datagen = ImageDataGenerator(rescale=1./255.)\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen, batch_size=batch_size)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    "\n",
    "    def three_im_generator(self, x, y, gen, batch_size=32):\n",
    "        im_gen = gen.flow(x, y, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        while True:\n",
    "            im1_s, im2_s, im3_s = [], [], []\n",
    "            im1, im2, im3 = [], [], []\n",
    "            images, labels = im_gen.next()\n",
    "\n",
    "            for im in images:\n",
    "                w = im.shape[1]\n",
    "                im1 = im[:, :w//3]\n",
    "                im2 = im[:, w//3:(w*2)//3] \n",
    "                im3 = im[:, (w*2)//3:] \n",
    "                im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "                im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "                im3 = cv2.cvtColor(im3, cv2.COLOR_BGR2GRAY)\n",
    "                im1 = cv2.resize(im1, dsize=(200, 200), interpolation=cv2.INTER_LANCZOS4)\n",
    "                im2 = cv2.resize(im2, dsize=(200, 200), interpolation=cv2.INTER_LANCZOS4)\n",
    "                im3 = cv2.resize(im3, dsize=(200, 200), interpolation=cv2.INTER_NEAREST)\n",
    "                im1_s.append(im1)\n",
    "                im2_s.append(im2)\n",
    "                im3_s.append(im3)\n",
    "\n",
    "            im1_s = np.array(im1_s)\n",
    "            im2_s = np.array(im2_s)\n",
    "            im3_s = np.array(im3_s)\n",
    "\n",
    "            yield [im1_s, im2_s, im3_s], labels\n",
    "\n",
    "    # Special generator to generate the 3 parts of the input image as 3 separate input images\n",
    "    def three_im_generator_common_resize(self,\n",
    "                                         gen,\n",
    "                                         dataset,\n",
    "                                         target_size,\n",
    "                                         batch_size,\n",
    "                                         class_mode):\n",
    "\n",
    "        im_gen = gen.flow_from_directory(dataset, \n",
    "                                         target_size=target_size, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         class_mode=class_mode)\n",
    "        self.filenames = im_gen.filenames\n",
    "\n",
    "        while True:\n",
    "            im1_s, im2_s, im3_s = [], [], []\n",
    "            images, labels = im_gen.next()\n",
    "\n",
    "            for im in images:\n",
    "                w = im.shape[1]\n",
    "                im1 = im[:, :w//3]\n",
    "                im2 = im[:, w//3:(w*2)//3] \n",
    "                im3 = im[:, (w*2)//3:] \n",
    "                im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "                im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "                im3 = cv2.cvtColor(im3, cv2.COLOR_BGR2GRAY)\n",
    "                im1_s.append(im1)\n",
    "                im2_s.append(im2)\n",
    "                im3_s.append(im3)\n",
    "\n",
    "            im1_s = np.array(im1_s)\n",
    "            im2_s = np.array(im2_s)\n",
    "            im3_s = np.array(im3_s)\n",
    "            \n",
    "            yield [im1_s, im2_s, im3_s], labels\n",
    " \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.three_im_generator_common_size(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            #class_mode='binary'\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = CustomDataGen(self.obstacle_dataset, self.no_obstacle_dataset)\n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        \n",
    "    # Compute and plot multi-class confusion-matrix with normalization\n",
    "    def plot_cm_normalized(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold)\n",
    "        print(f'cm: {cm}')\n",
    "        # Normalise\n",
    "        cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        sns.heatmap(cmn, annot=True, fmt='.3f')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show(block=False)  \n",
    "                \n",
    "    def save_false_positives(self, predictions, threshold, save_path):\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'false_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fp_preds = [p[0] for p in preds]\n",
    "        return fp_preds\n",
    "            \n",
    "    def save_true_positives(self, predictions, threshold, save_path):\n",
    "        true_positives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'true_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "\n",
    "    def save_false_negatives(self, predictions, threshold, save_path):\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'false_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fn_preds = [p[0] for p in preds]\n",
    "        return fn_preds\n",
    "            \n",
    "    def save_true_negatives(self, predictions, threshold, save_path):\n",
    "        true_negatives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'true_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 2430 images belonging to 2 classes.\n",
      "0:32\n",
      "0:32\n",
      "32:64\n",
      " 1/76 [..............................] - ETA: 47s64:96\n",
      " 2/76 [..............................] - ETA: 28s96:128\n",
      " 3/76 [>.............................] - ETA: 26s128:160\n",
      " 4/76 [>.............................] - ETA: 28s160:192\n",
      " 5/76 [>.............................] - ETA: 27s192:224\n",
      " 6/76 [=>............................] - ETA: 27s224:256\n",
      " 7/76 [=>............................] - ETA: 26s256:288\n",
      " 8/76 [==>...........................] - ETA: 25s288:320\n",
      " 9/76 [==>...........................] - ETA: 26s320:352\n",
      "10/76 [==>...........................] - ETA: 27s352:384\n",
      "11/76 [===>..........................] - ETA: 28s384:416\n",
      "12/76 [===>..........................] - ETA: 28s416:448\n",
      "13/76 [====>.........................] - ETA: 28s448:480\n",
      "14/76 [====>.........................] - ETA: 29s480:512\n",
      "15/76 [====>.........................] - ETA: 28s512:544\n",
      "16/76 [=====>........................] - ETA: 28s544:576\n",
      "17/76 [=====>........................] - ETA: 28s576:608\n",
      "18/76 [======>.......................] - ETA: 28s608:640\n",
      "19/76 [======>.......................] - ETA: 28s640:672\n",
      "20/76 [======>.......................] - ETA: 28s672:704\n",
      "21/76 [=======>......................] - ETA: 28s704:736\n",
      "22/76 [=======>......................] - ETA: 27s736:768\n",
      "23/76 [========>.....................] - ETA: 27s768:800\n",
      "24/76 [========>.....................] - ETA: 26s800:832\n",
      "25/76 [========>.....................] - ETA: 26s832:864\n",
      "26/76 [=========>....................] - ETA: 25s864:896\n",
      "27/76 [=========>....................] - ETA: 25s896:928\n",
      "28/76 [==========>...................] - ETA: 24s928:960\n",
      "29/76 [==========>...................] - ETA: 24s960:992\n",
      "30/76 [==========>...................] - ETA: 23s992:1024\n",
      "31/76 [===========>..................] - ETA: 23s1024:1056\n",
      "32/76 [===========>..................] - ETA: 22s1056:1088\n",
      "33/76 [============>.................] - ETA: 22s1088:1120\n",
      "34/76 [============>.................] - ETA: 21s1120:1152\n",
      "35/76 [============>.................] - ETA: 21s1152:1184\n",
      "36/76 [=============>................] - ETA: 20s1184:1216\n",
      "37/76 [=============>................] - ETA: 20s1216:1248\n",
      "38/76 [==============>...............] - ETA: 19s1248:1280\n",
      "39/76 [==============>...............] - ETA: 19s1280:1312\n",
      "40/76 [==============>...............] - ETA: 18s1312:1344\n",
      "41/76 [===============>..............] - ETA: 18s1344:1376\n",
      "42/76 [===============>..............] - ETA: 17s1376:1408\n",
      "43/76 [===============>..............] - ETA: 17s1408:1440\n",
      "44/76 [================>.............] - ETA: 17s1440:1472\n",
      "45/76 [================>.............] - ETA: 16s1472:1504\n",
      "46/76 [=================>............] - ETA: 15s1504:1536\n",
      "47/76 [=================>............] - ETA: 15s1536:1568\n",
      "48/76 [=================>............] - ETA: 14s1568:1600\n",
      "49/76 [==================>...........] - ETA: 14s1600:1632\n",
      "50/76 [==================>...........] - ETA: 13s1632:1664\n",
      "51/76 [===================>..........] - ETA: 13s1664:1696\n",
      "52/76 [===================>..........] - ETA: 12s1696:1728\n",
      "53/76 [===================>..........] - ETA: 12s1728:1760\n",
      "54/76 [====================>.........] - ETA: 11s1760:1792\n",
      "55/76 [====================>.........] - ETA: 11s1792:1824\n",
      "56/76 [=====================>........] - ETA: 10s1824:1856\n",
      "57/76 [=====================>........] - ETA: 10s1856:1888\n",
      "58/76 [=====================>........] - ETA: 9s 1888:1920\n",
      "59/76 [======================>.......] - ETA: 9s1920:1952\n",
      "60/76 [======================>.......] - ETA: 8s1952:1984\n",
      "61/76 [=======================>......] - ETA: 8s1984:2016\n",
      "62/76 [=======================>......] - ETA: 7s2016:2048\n",
      "63/76 [=======================>......] - ETA: 6s2048:2080\n",
      "64/76 [========================>.....] - ETA: 6s2080:2112\n",
      "65/76 [========================>.....] - ETA: 5s2112:2144\n",
      "66/76 [=========================>....] - ETA: 5s2144:2176\n",
      "67/76 [=========================>....] - ETA: 4s2176:2208\n",
      "68/76 [=========================>....] - ETA: 4s2208:2240\n",
      "69/76 [==========================>...] - ETA: 3s2240:2272\n",
      "70/76 [==========================>...] - ETA: 3s2272:2304\n",
      "71/76 [===========================>..] - ETA: 2s2304:2336\n",
      "72/76 [===========================>..] - ETA: 2s2336:2368\n",
      "73/76 [===========================>..] - ETA: 1s2368:2400\n",
      "74/76 [============================>.] - ETA: 1s2400:2430\n",
      "76/76 [==============================] - 41s 536ms/step\n",
      "cm: [[577 627]\n",
      " [604 622]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DatasetHandler' object has no attribute 'filenames'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-a125b616c520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0msave_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_base_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mfn_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_false_negatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mfp_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_false_positives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_true_negatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-eac49576e7c8>\u001b[0m in \u001b[0;36msave_false_negatives\u001b[0;34m(self, predictions, threshold, save_path)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_false_negatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         false_negatives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n\u001b[0m\u001b[1;32m    203\u001b[0m                            if predictions[self.num_no_obstacles+i] <= threshold]\n\u001b[1;32m    204\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_no_obstacles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatasetHandler' object has no attribute 'filenames'"
     ]
    }
   ],
   "source": [
    "# -- Variables --\n",
    "model_path = '/home/drevital/cs_video_processor/models/jun22_f'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/jun22_f/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'rgb'\n",
    "thresholds = [0.65, 0.70, 0.75]\n",
    "batch_size = 32\n",
    "save_base_path = '/home/drevital/obstacles_classification_datasets/model_eval'\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, dataset, batch_size=batch_size)\n",
    "\n",
    "# -- Define Labels\n",
    "labels = np.array([0]*handler.num_no_obstacles\\\n",
    "                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # -- Print confision-matrix\n",
    "    handler.plot_cm_normalized(model_path, labels, predictions, threshold=threshold)\n",
    "\n",
    "    # -- Save Images\n",
    "    save_name = dataset.split('/')[-2] + '_' + str(threshold)\n",
    "    save_path = os.path.join(save_base_path, save_name)\n",
    "    fn_preds = handler.save_false_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    fp_preds = handler.save_false_positives(predictions, threshold=threshold, save_path=save_path)\n",
    "    handler.save_true_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    handler.save_true_positives(predictions, threshold=threshold, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
