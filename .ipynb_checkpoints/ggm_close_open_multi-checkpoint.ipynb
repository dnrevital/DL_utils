{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = '/home/drevital/obstacles_classification_datasets/obstacle_classification_RGB_data'\n",
    "annotated_folder = '/home/drevital/obstacles_classification_datasets/rgb_6/annotated'\n",
    "in_folders = ['/home/drevital/obstacles_classification_datasets/rgb_6/train']\n",
    "out_folders = ['/home/drevital/obstacles_classification_datasets/ggm_close_open_11/train']\n",
    "sites = ['_'.join(s.split('_')[:-2]) for s in os.listdir(src_folder)]\n",
    "threshold_decrement = 1\n",
    "min_white_percent = .05\n",
    "kernel_size = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_thresholds = {'israel': 55,\n",
    "                   'new_factory': 50,\n",
    "                   'new_factory_humid': 50,\n",
    "                   'musashi_office': 40,\n",
    "                   'koki_factory': 40}\n",
    "default_threshold = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dictionary for the image names of each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_images = defaultdict(list)\n",
    "\n",
    "for site in sites:\n",
    "    site_folder = os.path.join(src_folder, site + '_rgb_data','all_data')\n",
    "    class_folders = os.listdir(site_folder)\n",
    "    for cls in class_folders:\n",
    "        site_images[site] += [f for f in os.listdir(os.path.join(site_folder,cls))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List images not found in any site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_folders = ['no_obstacle', 'obstacle']\n",
    "\n",
    "for class_folder in class_folders:\n",
    "    annotated = os.listdir(os.path.join(annotated_folder, class_folder))\n",
    "    for a in annotated:\n",
    "        # alt_name takes into account the same name with ignoring one _ at the end\n",
    "        alt_name = '.'.join(a.split('.')[:-1])[:-1] + '.jpg'\n",
    "        found_states = [a in site_images[site] for site in sites]\n",
    "        found = any(found_states)\n",
    "        alt_found = any([alt_name in site_images[site] for site in sites])\n",
    "        found = found or alt_found\n",
    "        if not found:\n",
    "            print(f'{class_folder}: {a}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A funciton to find the source site of a given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_site_and_threshold(im_name):\n",
    "    found_states = [im_name in site_images[site] for site in sites]\n",
    "    \n",
    "    if any(found_states):\n",
    "        site = sites[np.argmax(found_states)]\n",
    "        threshold = site_thresholds[site]\n",
    "    else:\n",
    "        site = 'unknown'\n",
    "        threshold = default_threshold\n",
    "        \n",
    "    return site, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function to generate <ref, current, mask> triplet from <ref, current> pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_image(pair, threshold):\n",
    "    h = pair.shape[0]\n",
    "    w = pair.shape[1]\n",
    "    ref = pair[:, :w//2, 1]\n",
    "    current = pair[:, w//2:, 1]\n",
    "    pixels = h * w\n",
    "    \n",
    "    diff = cv2.absdiff(current, ref)\n",
    "\n",
    "    # Loop to generate mask, with threshold decrements, until receving a non-zero mask\n",
    "    while True and threshold > 0:\n",
    "        _, mask = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Pad the contoured image with zeros, to enable the kernel be applied on edges\n",
    "        mask_pad = np.zeros((mask.shape[0]+100, mask.shape[1]+100), np.uint8)\n",
    "        x1 = (mask_pad.shape[0] - mask.shape[0]) // 2\n",
    "        x2 = x1 + mask.shape[0]\n",
    "        y1 = (mask_pad.shape[1] - mask.shape[1]) // 2\n",
    "        y2 = y1 + mask.shape[1]\n",
    "        mask_pad[x1:x2, y1:y2] = mask\n",
    "\n",
    "        # morphological operations\n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        copyImg = cv2.morphologyEx(mask_pad, cv2.MORPH_CLOSE, kernel)\n",
    "        copyImg = cv2.morphologyEx(copyImg, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Return to original countoured image dimensions\n",
    "        mask = copyImg[x1:x2, y1:y2]\n",
    "\n",
    "        if (np.sum(mask)//255) / pixels > min_white_percent:\n",
    "            break\n",
    "\n",
    "        threshold -= threshold_decrement\n",
    "    \n",
    "    return cv2.hconcat([ref, current, mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over in_folders, create <ref, current, mask> images and write the to corresponding out_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['no_obstacle', 'obstacle']\n",
    "\n",
    "for i, in_folder in enumerate(in_folders):\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(in_folder, class_name)\n",
    "        im_names = os.listdir(class_path)\n",
    "        for im_name in tqdm(im_names):\n",
    "            im_path = os.path.join(class_path, im_name)\n",
    "            pair = cv2.imread(im_path)\n",
    "            site, threshold = find_site_and_threshold(im_name)\n",
    "            triplet = triplet_image(pair, threshold)\n",
    "            out_im_name = '.'.join(im_name.split('.')[:-1]) + f'_{site}_.jpg'\n",
    "            out_path = os.path.join(out_folders[i], class_name, out_im_name)\n",
    "            print(out_path)\n",
    "            cv2.imwrite(out_path, triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
