{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=400,\n",
    "                 img_height=200,\n",
    "                 batch_size=32):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.obstacle_images = []\n",
    "        self.no_obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_obstacles = 0\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen(self.batch_size)\n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self, batch_size):\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen, batch_size=batch_size)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    "\n",
    "    # Special generator to generate the 2 halves of the input image as 2 separate input images\n",
    "    def two_im_generator(self, gen, dataset, target_size, batch_size, class_mode):\n",
    "        im_gen = gen.flow_from_directory(dataset, \n",
    "                                         target_size=target_size, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         class_mode=class_mode)\n",
    "        self.filenames = im_gen.filenames\n",
    "\n",
    "        while True:\n",
    "            im1_s, im2_s = [], []\n",
    "            images, labels = im_gen.next()\n",
    "\n",
    "            for im in images:\n",
    "                w = im.shape[1]\n",
    "                im1 = im[:,:w//2]\n",
    "                im2 = im[:,w//2:] \n",
    "                im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "                im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "                im1_s.append(im1)\n",
    "                im2_s.append(im2)\n",
    "\n",
    "            im1_s = np.array(im1_s)\n",
    "            im2_s = np.array(im2_s)\n",
    "            yield [im1_s, im2_s], labels\n",
    "            \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.two_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = self.two_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        \n",
    "    # Compute and plot multi-class confusion-matrix with normalization\n",
    "    def plot_cm_normalized(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold)\n",
    "        # Normalise\n",
    "        cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        sns.heatmap(cmn, annot=True, fmt='.3f')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show(block=False)  \n",
    "                \n",
    "    def display_false_positives(self, predictions, threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        if 500 > len(false_positives) > 1:\n",
    "            num_images = len(false_positives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_positives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                print(f'FP prediction: {preds[i]}, imname: {imname}')\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_positives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show()\n",
    "            \n",
    "    def display_false_negatives(self, predictions, threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "\n",
    "        if 500 > len(false_negatives) > 1:\n",
    "            num_images = len(false_negatives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_negatives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_negatives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show()\n",
    "\n",
    "    def save_false_positives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'false_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "    def save_true_positives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        true_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'true_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "\n",
    "    def save_false_negatives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'false_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "    def save_true_negatives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        true_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'true_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 1432 images belonging to 2 classes.\n",
      "Found 1432 images belonging to 2 classes.\n",
      "45/45 [==============================] - 8s 183ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ebe803cb3b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# -- Save Images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_false_negatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_false_positives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_true_negatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-326672ff0532>\u001b[0m in \u001b[0;36msave_false_negatives\u001b[0;34m(self, predictions, threshold, save_path)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfn_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'false_negatives'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_negatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mimname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# -- Variables --\n",
    "model_path = '/home/drevital/cs_video_processor/models/rgb_6'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/rgb_6/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'rgb'\n",
    "threshold = 0.3\n",
    "batch_size = 32\n",
    "save_base_path = '/home/drevital/obstacles_classification_datasets/model_eval'\n",
    "save_name = dataset.split('/')[-2] + '_' + str(threshold)\n",
    "save_path = os.path.join(save_base_path, save_name)\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, dataset, batch_size=batch_size)\n",
    "\n",
    "# -- Define Labels\n",
    "labels = np.array([0]*handler.num_no_obstacles\\\n",
    "                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "# -- Print confision-matrix\n",
    "handler.plot_cm_normalized(model_path, labels, predictions, threshold=threshold)\n",
    "\n",
    "# -- Save Images\n",
    "handler.save_false_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "handler.save_false_positives(predictions, threshold=threshold, save_path=save_path)\n",
    "handler.save_true_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "handler.save_true_positives(predictions, threshold=threshold, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
