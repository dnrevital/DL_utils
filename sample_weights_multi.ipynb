{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = '/home/drevital/obstacles_classification_datasets/base_dataset'\n",
    "out_dir = '/home/drevital/obstacles_classification_datasets/feb23_c_std_15_gamma_15'\n",
    "sites_dir = '/home/drevital/obstacles_classification_datasets/base_dataset/sites'\n",
    "sites = os.listdir(sites_dir)\n",
    "\n",
    "# Parameters used in the diff_metric to diff_coef assignent function\n",
    "alfa = -3.5\n",
    "beta = 2.0\n",
    "gamma = 1.5\n",
    "swc = 2.0 # sample weight coefficient\n",
    "diff_threshold = 50\n",
    "std_threshold_dist = 1.5 # Distance from std to apply sample_weight correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kfar_saba',\n",
       " 'koki_factory',\n",
       " 'new_factory_humid',\n",
       " 'musashi_office',\n",
       " 'shufersal',\n",
       " 'new_factory',\n",
       " 'neve_ilan',\n",
       " 'unknown']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_thresholds = {'neve_ilan': 55,\n",
    "                   'kfar_saba': 55,\n",
    "                   'shufersal': 55,\n",
    "                   'new_factory': 50,\n",
    "                   'new_factory_humid': 50,\n",
    "                   'musashi_office': 40,\n",
    "                   'koki_factory': 40,\n",
    "                   'unknown': 50}\n",
    "default_threshold = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dictionary for the image names of each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_images = defaultdict(list)\n",
    "\n",
    "for site in sites:\n",
    "    site_dir = os.path.join(sites_dir, site)\n",
    "    site_images[site] = os.listdir(site_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kfar_saba', 'koki_factory', 'new_factory_humid', 'musashi_office', 'shufersal', 'new_factory', 'neve_ilan', 'unknown'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_images.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function to find the source site of a given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_site_and_threshold(im_name):\n",
    "    found_states = [im_name in site_images[site] for site in sites]\n",
    "    \n",
    "    if any(found_states):\n",
    "        site = sites[np.argmax(found_states)]\n",
    "        threshold = site_thresholds[site]\n",
    "    else:\n",
    "        site = 'unknown'\n",
    "        site_images[site].append(im_name)\n",
    "        threshold = default_threshold\n",
    "        \n",
    "    return site, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define curve to assign diff_coef according to diff_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_metric_to_diff_coef(sigma_dist):\n",
    "    \n",
    "    # Correction curve for assigning coefficients\n",
    "    # Based on Sigmoid\n",
    "    # adding alpha, beta and gamma controls, as explained at the\n",
    "    # beginning of the diff_coef_curve notebook\n",
    "    \n",
    "    return 1/(1 + np.exp(-(sigma_dist*alfa-beta)*gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6810/6810 [00:13<00:00, 513.43it/s]\n",
      "100%|██████████| 7015/7015 [00:35<00:00, 199.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dict = {'in_name': [],\n",
    "              'out_name': [],\n",
    "              'class_name': [],\n",
    "              'diff_metric': [],\n",
    "              'diff_coef': [],\n",
    "              'sample_weight': []\n",
    "             }\n",
    "diff_metrics = {'no_obstacle': [], 'obstacle': []}\n",
    "class_names = ['no_obstacle', 'obstacle']\n",
    "subset_name = 'train'\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(in_dir, subset_name, class_name)\n",
    "    im_names = os.listdir(class_path)\n",
    "    for im_name in tqdm(im_names):\n",
    "        im_path = os.path.join(class_path, im_name)\n",
    "        pair = cv2.imread(im_path)\n",
    "\n",
    "        # Generate diff mask            \n",
    "        w = pair.shape[1]\n",
    "        ref = pair[:, :w//2]\n",
    "        current = pair[:, w//2:(w//2)*2]\n",
    "        diff = cv2.subtract(ref, current)\n",
    "        agg_rgb = np.stack((diff[:, :, 0], diff[:, :, 1], diff[:, :, 2])).max(0)\n",
    "        _, mask = cv2.threshold(agg_rgb, diff_threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Calculate diff_coeff\n",
    "        h = mask.shape[0]\n",
    "        w = mask.shape[1]\n",
    "        area = h * w\n",
    "\n",
    "        # Update train dictionary\n",
    "        train_dict['in_name'].append(im_name)\n",
    "        train_dict['class_name'].append(class_name)\n",
    "        diff_metric = (np.sum(mask)/255)/area\n",
    "        train_dict['diff_metric'].append(diff_metric)    \n",
    "        diff_metrics[class_name].append(diff_metric)\n",
    "            \n",
    "mean = {'no_obstacle': np.mean(diff_metrics['no_obstacle']),\n",
    "        'obstacle': np.mean(diff_metrics['obstacle'])}\n",
    "std = {'no_obstacle': np.std(diff_metrics['no_obstacle']),\n",
    "       'obstacle': np.std(diff_metrics['obstacle']) }\n",
    "\n",
    "for i, diff_metric in enumerate(train_dict['diff_metric']):\n",
    "    class_name = train_dict['class_name'][i]\n",
    "    # Following is to adjust the direction of distance from std and correction accordingly\n",
    "    # For obstacle - a negative sigma means we are lower than threshold and need correction\n",
    "    # For no obstacle a positive sigma means we are higher than threshold and need correction\n",
    "    sigma_dist_sign = 1.0 if class_name == 'obstacle' else -1.0 \n",
    "    diff_threshold = mean[class_name] + sigma_dist_sign * std_threshold_dist * std[class_name]\n",
    "    sigma_dist = sigma_dist_sign * (diff_metric - diff_threshold)/std[class_name]\n",
    "    diff_coef = diff_metric_to_diff_coef(sigma_dist)\n",
    "    sample_weight = 1.0 + swc * diff_coef\n",
    "    train_dict['diff_coef'].append(diff_coef)\n",
    "    train_dict['sample_weight'].append(sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function to generate <ref, current, true_mask> triplet from <ref, current> pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_image_true_mask(pair, threshold):\n",
    "    w = pair.shape[1]\n",
    "    ref = pair[:, :w//2]\n",
    "    current = pair[:, w//2:(w//2)*2]\n",
    "    diff = cv2.absdiff(current, ref)\n",
    "    agg_rgb = np.stack((diff[:, :, 0], diff[:, :, 1], diff[:, :, 2])).max(0)\n",
    "    _, mask = cv2.threshold(agg_rgb, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # old morphological operations\n",
    "    copyImg = cv2.erode(mask, np.ones((3, 3), np.uint8), iterations=1)  # reduce noise\n",
    "    copyImg = cv2.dilate(copyImg, np.ones((7, 7), np.uint8), iterations=1)\n",
    "    copyImg = cv2.erode(copyImg, np.ones((5, 5), np.uint8), iterations=1)\n",
    "    copyImg = cv2.dilate(copyImg, np.ones((9, 9), np.uint8), iterations=1)\n",
    "    kernel = np.ones((11, 11), np.uint8)  # kernel for dilation\n",
    "\n",
    "    # increase area to an object\n",
    "    copyImg = cv2.dilate(copyImg, kernel, iterations=2)\n",
    "    copyImg = cv2.dilate(copyImg, np.ones((13, 13), np.uint8), iterations=1)\n",
    "    copyImg = cv2.erode(copyImg, np.ones((11, 11), np.uint8), iterations=1)\n",
    "    copyImg = cv2.erode(copyImg, np.ones((5, 5), np.uint8), iterations=1)\n",
    "\n",
    "    mask = copyImg \n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)  \n",
    "    \n",
    "    return cv2.hconcat([ref, current, mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function to generate <ref, current, black_mask> triplet from <ref, current> pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_image_black_mask(pair, threshold):\n",
    "    w = pair.shape[1]\n",
    "    ref = pair[:, :w//2]\n",
    "    current = pair[:, w//2:(w//2)*2]\n",
    "    h_mask = ref.shape[0]\n",
    "    w_mask = ref.shape[1]\n",
    "    mask = np.full((h_mask, w_mask, 3), 0, dtype=np.uint8)\n",
    "    \n",
    "    return cv2.hconcat([ref, current, mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate triplet images <ref, current, mask>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13825/13825 [01:51<00:00, 123.89it/s]\n",
      "100%|██████████| 756/756 [00:03<00:00, 218.19it/s]\n",
      "100%|██████████| 771/771 [00:07<00:00, 103.32it/s]\n"
     ]
    }
   ],
   "source": [
    "subset_names = ['train', 'eval']\n",
    "class_names = ['no_obstacle', 'obstacle']\n",
    "class_extensions = {'no_obstacle': 'noobs', 'obstacle': 'obs'}\n",
    "\n",
    "for subset_name in subset_names:\n",
    "    cur_out_dir = os.path.join(out_dir, subset_name)\n",
    "    Path(cur_out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prepare indices for shuffling the images in dictionary, so onstacle/no_obstacle are mixed\n",
    "# This is necessary for the training/validation from corresponding dataframe to work properly\n",
    "\n",
    "keys = list(train_dict.keys())\n",
    "shuffled_train_dict = {}\n",
    "inds = [i for i in range(len(train_dict['in_name']))]\n",
    "shuffled = inds.copy()\n",
    "random.shuffle(shuffled)\n",
    "for k in keys:\n",
    "    if len(train_dict[k]) > 0:\n",
    "        shuffled_train_dict[k] = [train_dict[k][shuffled[i]] for i in range(len(train_dict['in_name']))]\n",
    "    else:\n",
    "        shuffled_train_dict[k] = []\n",
    "    \n",
    "subset_name = 'train'\n",
    "i = 0\n",
    "for im_name in tqdm(shuffled_train_dict['in_name']):\n",
    "    class_name = shuffled_train_dict['class_name'][i]\n",
    "    class_path = os.path.join(in_dir, subset_name, class_name)\n",
    "    im_path = os.path.join(class_path, im_name)\n",
    "    pair = cv2.imread(im_path)\n",
    "    site, threshold = find_site_and_threshold(im_name)\n",
    "    triplet = triplet_image_true_mask(pair, threshold)\n",
    "    class_extension = class_extensions[class_name]\n",
    "    sample_weight = shuffled_train_dict['sample_weight'][i]\n",
    "    out_im_name = '.'.join(im_name.split('.')[:-1])\\\n",
    "         + f'_{site}_{class_extension}_{sample_weight:.4f}_.jpg'\n",
    "    shuffled_train_dict['out_name'].append(out_im_name)\n",
    "    cur_out_dir = os.path.join(out_dir, subset_name)\n",
    "    out_path = os.path.join(cur_out_dir, out_im_name)\n",
    "    cv2.imwrite(out_path, triplet)\n",
    "    i += 1\n",
    "    \n",
    "subset_name = 'eval'\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(in_dir, subset_name, class_name)\n",
    "    im_names = os.listdir(class_path)\n",
    "    cur_out_dir = os.path.join(out_dir, subset_name, class_name)\n",
    "    Path(cur_out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    for im_name in tqdm(im_names):\n",
    "        im_path = os.path.join(class_path, im_name)\n",
    "        pair = cv2.imread(im_path)\n",
    "        site, threshold = find_site_and_threshold(im_name)\n",
    "        triplet = triplet_image_black_mask(pair, threshold)\n",
    "        out_im_name = '.'.join(im_name.split('.')[:-1]) + f'_{site}_.jpg'\n",
    "        out_path = os.path.join(cur_out_dir, out_im_name)\n",
    "        cv2.imwrite(out_path, triplet)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe from sample_weights Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['in_name', 'out_name', 'class_name', 'diff_metric', 'diff_coef', 'sample_weight'])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_train_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13825, 13825, 13825, 13825, 13825, 13825]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(shuffled_train_dict[k]) for k in shuffled_train_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame.from_dict(shuffled_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_name</th>\n",
       "      <th>out_name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>diff_metric</th>\n",
       "      <th>diff_coef</th>\n",
       "      <th>sample_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>587_19057_0_shear_222.jpg</td>\n",
       "      <td>587_19057_0_shear_222_unknown_noobs_3.0000_.jpg</td>\n",
       "      <td>no_obstacle</td>\n",
       "      <td>0.247208</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>2.999967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115_1964_0_rotate_475.jpg</td>\n",
       "      <td>115_1964_0_rotate_475_unknown_obs_3.0000_.jpg</td>\n",
       "      <td>obstacle</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>2.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58_1752_.96_2021-08-15--11-59-26_.jpg</td>\n",
       "      <td>58_1752_.96_2021-08-15--11-59-26__new_factory_...</td>\n",
       "      <td>obstacle</td>\n",
       "      <td>0.213763</td>\n",
       "      <td>0.974624</td>\n",
       "      <td>2.949247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>458_obstacles_classification_10_2022-12-05T15-...</td>\n",
       "      <td>458_obstacles_classification_10_2022-12-05T15-...</td>\n",
       "      <td>obstacle</td>\n",
       "      <td>0.218325</td>\n",
       "      <td>0.969300</td>\n",
       "      <td>2.938600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293_obstacles_0_crop_136.jpg</td>\n",
       "      <td>293_obstacles_0_crop_136_unknown_noobs_2.9964_...</td>\n",
       "      <td>no_obstacle</td>\n",
       "      <td>0.130875</td>\n",
       "      <td>0.998219</td>\n",
       "      <td>2.996437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13820</th>\n",
       "      <td>282_obstacles_classification_10_2022-10-25T14-...</td>\n",
       "      <td>282_obstacles_classification_10_2022-10-25T14-...</td>\n",
       "      <td>obstacle</td>\n",
       "      <td>0.099875</td>\n",
       "      <td>0.999804</td>\n",
       "      <td>2.999609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13821</th>\n",
       "      <td>1_171_.79_2021-08-15--11-39-59_.jpg</td>\n",
       "      <td>1_171_.79_2021-08-15--11-39-59__new_factory_ob...</td>\n",
       "      <td>obstacle</td>\n",
       "      <td>0.292219</td>\n",
       "      <td>0.569260</td>\n",
       "      <td>2.138519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13822</th>\n",
       "      <td>1904_obstacles_0_shear_3737.jpg</td>\n",
       "      <td>1904_obstacles_0_shear_3737_unknown_noobs_3.00...</td>\n",
       "      <td>no_obstacle</td>\n",
       "      <td>0.443400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13823</th>\n",
       "      <td>1382_obstacles_0_shear_4367.jpg</td>\n",
       "      <td>1382_obstacles_0_shear_4367_unknown_noobs_2.99...</td>\n",
       "      <td>no_obstacle</td>\n",
       "      <td>0.105325</td>\n",
       "      <td>0.995044</td>\n",
       "      <td>2.990088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13824</th>\n",
       "      <td>1690_obstacles_0_crop_221.jpg</td>\n",
       "      <td>1690_obstacles_0_crop_221_unknown_noobs_2.4896...</td>\n",
       "      <td>no_obstacle</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.744799</td>\n",
       "      <td>2.489599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13825 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 in_name  \\\n",
       "0                              587_19057_0_shear_222.jpg   \n",
       "1                              115_1964_0_rotate_475.jpg   \n",
       "2                  58_1752_.96_2021-08-15--11-59-26_.jpg   \n",
       "3      458_obstacles_classification_10_2022-12-05T15-...   \n",
       "4                           293_obstacles_0_crop_136.jpg   \n",
       "...                                                  ...   \n",
       "13820  282_obstacles_classification_10_2022-10-25T14-...   \n",
       "13821                1_171_.79_2021-08-15--11-39-59_.jpg   \n",
       "13822                    1904_obstacles_0_shear_3737.jpg   \n",
       "13823                    1382_obstacles_0_shear_4367.jpg   \n",
       "13824                      1690_obstacles_0_crop_221.jpg   \n",
       "\n",
       "                                                out_name   class_name  \\\n",
       "0        587_19057_0_shear_222_unknown_noobs_3.0000_.jpg  no_obstacle   \n",
       "1          115_1964_0_rotate_475_unknown_obs_3.0000_.jpg     obstacle   \n",
       "2      58_1752_.96_2021-08-15--11-59-26__new_factory_...     obstacle   \n",
       "3      458_obstacles_classification_10_2022-12-05T15-...     obstacle   \n",
       "4      293_obstacles_0_crop_136_unknown_noobs_2.9964_...  no_obstacle   \n",
       "...                                                  ...          ...   \n",
       "13820  282_obstacles_classification_10_2022-10-25T14-...     obstacle   \n",
       "13821  1_171_.79_2021-08-15--11-39-59__new_factory_ob...     obstacle   \n",
       "13822  1904_obstacles_0_shear_3737_unknown_noobs_3.00...  no_obstacle   \n",
       "13823  1382_obstacles_0_shear_4367_unknown_noobs_2.99...  no_obstacle   \n",
       "13824  1690_obstacles_0_crop_221_unknown_noobs_2.4896...  no_obstacle   \n",
       "\n",
       "       diff_metric  diff_coef  sample_weight  \n",
       "0         0.247208   0.999983       2.999967  \n",
       "1         0.001034   0.999997       2.999994  \n",
       "2         0.213763   0.974624       2.949247  \n",
       "3         0.218325   0.969300       2.938600  \n",
       "4         0.130875   0.998219       2.996437  \n",
       "...            ...        ...            ...  \n",
       "13820     0.099875   0.999804       2.999609  \n",
       "13821     0.292219   0.569260       2.138519  \n",
       "13822     0.443400   1.000000       3.000000  \n",
       "13823     0.105325   0.995044       2.990088  \n",
       "13824     0.000000   0.744799       2.489599  \n",
       "\n",
       "[13825 rows x 6 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the Dataframe in a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = out_dir.split('/')[-1] + '.csv'\n",
    "csv_path = os.path.join(out_dir, csv_name)\n",
    "train_df.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18519772001032608, 0.12224598107311017)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean['obstacle'], std['obstacle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09469074593042251, 0.13068741788982025)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean['no_obstacle'], std['no_obstacle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfar_saba: 1539\n",
      "koki_factory: 437\n",
      "new_factory_humid: 378\n",
      "musashi_office: 3171\n",
      "shufersal: 1165\n",
      "new_factory: 7649\n",
      "neve_ilan: 3486\n",
      "unknown: 7644\n",
      "========== total: 25469\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "for site in site_images:\n",
    "    tot += len(site_images[site])\n",
    "    print(f'{site}: {len(site_images[site])}')\n",
    "print(f'========== total: {tot}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
