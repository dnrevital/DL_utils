{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Custom Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self,\n",
    "                 no_obs_dir,\n",
    "                 obs_dir,\n",
    "                 batch_size=32,\n",
    "                 input_size=(200, 200),\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        no_obs_imnames = os.listdir(no_obs_dir)\n",
    "        obs_imnames = os.listdir(obs_dir)\n",
    "        self.no_obs = [[os.path.join(no_obs_dir, name), 0] for name in no_obs_imnames]\n",
    "        self.obs = [[os.path.join(obs_dir, name), 1] for name in obs_imnames]\n",
    "        self.items = self.no_obs + self.obs\n",
    "        self.filenames = [item[0] for item in self.items]\n",
    "        self.labels = [item[1] for item in self.items]\n",
    "        self.n = len(self.items)\n",
    "        self.steps = math.ceil(self.n/self.batch_size)\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.items)\n",
    "        self.image_written = False\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = min((index+1) * self.batch_size, self.n)\n",
    "        items = self.items[start:end]\n",
    "        im1_s, im2_s, im3_s, labels = [], [], [], []\n",
    "\n",
    "        for item in items:\n",
    "            # Read image\n",
    "            im = cv2.imread(item[0])\n",
    "            im = cv2.resize(im, dsize=(600, 200), interpolation=cv2.INTER_NEAREST)\n",
    "            imarr = np.array(im, dtype='float32')\n",
    "            imarr /= 255.0\n",
    "            w = imarr.shape[1]\n",
    "\n",
    "            # Split to 3 components\n",
    "            im1 = imarr[:, :w//3]\n",
    "            im2 = imarr[:, w//3:(w*2)//3] \n",
    "            im3 = imarr[:, (w*2)//3:] \n",
    "\n",
    "            # 3rd component to grayscale\n",
    "            im3 = cv2.cvtColor(im3, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            # Add each component to its batch\n",
    "            im1_s.append(im1)\n",
    "            im2_s.append(im2)\n",
    "            im3_s.append(im3)\n",
    "            labels.append(item[1])\n",
    "\n",
    "        im1_s = np.array(im1_s)\n",
    "        im2_s = np.array(im2_s)\n",
    "        im3_s = np.array(im3_s)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        return [im1_s, im2_s, im3_s], labels \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=600,\n",
    "                 img_height=200,\n",
    "                 batch_size=32):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.no_obstacle_images = []\n",
    "        self.obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen(self.batch_size)\n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self, batch_size):\n",
    "        datagen = ImageDataGenerator(rescale=1./255.)\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen, batch_size=batch_size)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    " \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.three_im_generator_common_size(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            #class_mode='binary'\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = CustomDataGen(self.no_obstacle_dataset,\n",
    "                                          self.obstacle_dataset,\n",
    "                                          shuffle=False)\n",
    "        self.filenames = predict_generator.filenames\n",
    "        self.labels = predict_generator.labels\n",
    "        self.items = predict_generator.items\n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        \n",
    "    # Compute and plot multi-class confusion-matrix with normalization\n",
    "    def plot_cm_normalized(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold)\n",
    "        print(f'cm: {cm}')\n",
    "        # Normalise\n",
    "        cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        sns.heatmap(cmn, annot=True, fmt='.3f')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show(block=False)  \n",
    "                \n",
    "    def save_false_positives(self, predictions, threshold, save_path):\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'false_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fp_preds = [p[0] for p in preds]\n",
    "        return fp_preds\n",
    "            \n",
    "    def save_true_positives(self, predictions, threshold, save_path):\n",
    "        true_positives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p > threshold]\n",
    "\n",
    "        tp_path = os.path.join(save_path, 'true_positives')\n",
    "        Path(tp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(tp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "\n",
    "    def save_false_negatives(self, predictions, threshold, save_path):\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'false_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fn_preds = [p[0] for p in preds]\n",
    "        return fn_preds\n",
    "            \n",
    "    def save_true_negatives(self, predictions, threshold, save_path):\n",
    "        true_negatives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p <= threshold]\n",
    "        \n",
    "        tn_path = os.path.join(save_path, 'true_negatives')\n",
    "        Path(tn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(tn_path, imname)\n",
    "            cv2.imwrite(out_path, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 2430 images belonging to 2 classes.\n",
      "76/76 [==============================] - 32s 417ms/step\n",
      "cm: [[1190   14]\n",
      " [  13 1213]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Variables --\n",
    "model_path = '/home/drevital/cs_video_processor/models/jun22_f'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/jun22_f/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'rgb'\n",
    "thresholds = [0.75]\n",
    "batch_size = 32\n",
    "save_base_path = '/home/drevital/obstacles_classification_datasets/model_eval_new_method'\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, dataset, batch_size=batch_size)\n",
    "\n",
    "# -- Define Labels\n",
    "#labels = np.array([0]*handler.num_no_obstacles\\\n",
    "#                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # -- Print confision-matrix\n",
    "    handler.plot_cm_normalized(model_path, handler.labels, predictions, threshold=threshold)\n",
    "\n",
    "    # -- Save Images\n",
    "    save_name = dataset.split('/')[-2] + '_' + str(threshold)\n",
    "    save_path = os.path.join(save_base_path, save_name)\n",
    "    fn_preds = handler.save_false_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    fp_preds = handler.save_false_positives(predictions, threshold=threshold, save_path=save_path)\n",
    "    handler.save_true_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    handler.save_true_positives(predictions, threshold=threshold, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0255253 ],\n",
       "       [0.20471415],\n",
       "       [0.11698979],\n",
       "       ...,\n",
       "       [0.9985048 ],\n",
       "       [0.98502874],\n",
       "       [0.9990718 ]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
