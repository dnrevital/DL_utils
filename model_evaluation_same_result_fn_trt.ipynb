{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Custom Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self,\n",
    "                 no_obs_dir,\n",
    "                 obs_dir,\n",
    "                 batch_size=32,\n",
    "                 input_size=(200, 200),\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        no_obs_imnames = os.listdir(no_obs_dir)\n",
    "        obs_imnames = os.listdir(obs_dir)\n",
    "        self.no_obs = [[os.path.join(no_obs_dir, name), 0] for name in no_obs_imnames]\n",
    "        self.obs = [[os.path.join(obs_dir, name), 1] for name in obs_imnames]\n",
    "        self.items = self.no_obs + self.obs\n",
    "        self.filenames = [item[0] for item in self.items]\n",
    "        self.labels = [item[1] for item in self.items]\n",
    "        self.n = len(self.items)\n",
    "        self.steps = math.ceil(self.n/self.batch_size)\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.items)\n",
    "        self.image_written = False\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        start = index * self.batch_size\n",
    "        end = min((index+1) * self.batch_size, self.n)\n",
    "        items = self.items[start:end]\n",
    "        im1_s, im2_s, im3_s, labels = [], [], [], []\n",
    "\n",
    "        for item in items:\n",
    "            # Read image\n",
    "            im = cv2.imread(item[0])\n",
    "            im = cv2.resize(im, dsize=(600, 200), interpolation=cv2.INTER_NEAREST)\n",
    "            imarr = np.array(im, dtype='float32')\n",
    "            imarr /= 255.0\n",
    "            w = imarr.shape[1]\n",
    "\n",
    "            # Split to 3 components\n",
    "            im1 = imarr[:, :w//3]\n",
    "            im2 = imarr[:, w//3:(w*2)//3] \n",
    "            im3 = imarr[:, (w*2)//3:] \n",
    "\n",
    "            # 3rd component to grayscale\n",
    "            im3 = cv2.cvtColor(im3, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            # Add each component to its batch\n",
    "            im1_s.append(im1)\n",
    "            im2_s.append(im2)\n",
    "            im3_s.append(im3)\n",
    "            labels.append(item[1])\n",
    "\n",
    "        im1_s = np.array(im1_s)\n",
    "        im2_s = np.array(im2_s)\n",
    "        im3_s = np.array(im3_s)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        return [im1_s, im2_s, im3_s], labels \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=600,\n",
    "                 img_height=200,\n",
    "                 batch_size=32):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.no_obstacle_images = []\n",
    "        self.obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen(self.batch_size)\n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self, batch_size):\n",
    "        datagen = ImageDataGenerator(rescale=1./255.)\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen, batch_size=batch_size)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    " \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.three_im_generator_common_size(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            #class_mode='binary'\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = CustomDataGen(self.no_obstacle_dataset,\n",
    "                                          self.obstacle_dataset,\n",
    "                                          shuffle=False)\n",
    "        self.filenames = predict_generator.filenames\n",
    "        self.labels = predict_generator.labels\n",
    "        self.items = predict_generator.items\n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        \n",
    "    # Compute and plot multi-class confusion-matrix with normalization\n",
    "    def plot_cm_normalized(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold)\n",
    "        print(f'cm: {cm}')\n",
    "        # Normalise\n",
    "        cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        sns.heatmap(cmn, annot=True, fmt='.3f')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show(block=False)  \n",
    "                \n",
    "    def save_false_positives(self, predictions, threshold, save_path):\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'false_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fp_preds = [p[0] for p in preds]\n",
    "        return fp_preds\n",
    "            \n",
    "    def save_true_positives(self, predictions, threshold, save_path):\n",
    "        true_positives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p > threshold]\n",
    "\n",
    "        tp_path = os.path.join(save_path, 'true_positives')\n",
    "        Path(tp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(tp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "\n",
    "    def save_false_negatives(self, predictions, threshold, save_path):\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'false_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fn_preds = [p[0] for p in preds]\n",
    "        return fn_preds\n",
    "            \n",
    "    def save_true_negatives(self, predictions, threshold, save_path):\n",
    "        true_negatives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p <= threshold]\n",
    "        \n",
    "        tn_path = os.path.join(save_path, 'true_negatives')\n",
    "        Path(tn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(tn_path, imname)\n",
    "            cv2.imwrite(out_path, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 2523 images belonging to 2 classes.\n",
      "79/79 [==============================] - 36s 458ms/step\n",
      "cm: [[1217   24]\n",
      " [  27 1255]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Variables --\n",
    "model_path = '/home/drevital/cs_video_processor/models/shufersal_sep22_a'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/shufersal_sep22_a/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'rgb'\n",
    "thresholds = [0.35]\n",
    "batch_size = 32\n",
    "save_base_path = '/home/drevital/obstacles_classification_datasets/model_eval_new_method'\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, dataset, batch_size=batch_size)\n",
    "\n",
    "# -- Define Labels\n",
    "#labels = np.array([0]*handler.num_no_obstacles\\\n",
    "#                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # -- Print confision-matrix\n",
    "    handler.plot_cm_normalized(model_path, handler.labels, predictions, threshold=threshold)\n",
    "\n",
    "    # -- Save Images\n",
    "    save_name = dataset.split('/')[-2] + '_' + str(threshold)\n",
    "    save_path = os.path.join(save_base_path, save_name)\n",
    "    fn_preds = handler.save_false_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    fp_preds = handler.save_false_positives(predictions, threshold=threshold, save_path=save_path)\n",
    "    handler.save_true_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    handler.save_true_positives(predictions, threshold=threshold, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04842913],\n",
       "       [0.00383928],\n",
       "       [0.00449479],\n",
       "       ...,\n",
       "       [0.9941337 ],\n",
       "       [0.9627703 ],\n",
       "       [0.9584484 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
