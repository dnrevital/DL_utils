{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=600,\n",
    "                 img_height=200,\n",
    "                 batch_size=32):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.obstacle_images = []\n",
    "        self.no_obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_obstacles = 0\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen(self.batch_size)\n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self, batch_size):\n",
    "        datagen = ImageDataGenerator(rescale=1./255.)\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen, batch_size=batch_size)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    "\n",
    "    # Special generator to generate the 3 parts of the input image as 3 separate input images\n",
    "    def three_im_generator(self, gen, dataset, target_size, batch_size, class_mode):\n",
    "\n",
    "        im_gen = gen.flow_from_directory(dataset, \n",
    "                                         target_size=target_size, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         class_mode=class_mode)\n",
    "        self.filenames = im_gen.filenames\n",
    "\n",
    "        while True:\n",
    "            im1_s, im2_s, im3_s = [], [], []\n",
    "            images, labels = im_gen.next()\n",
    "\n",
    "            for im in images:\n",
    "                w = im.shape[1]\n",
    "                im1 = im[:, :w//3]\n",
    "                im2 = im[:, w//3:(w*2)//3] \n",
    "                im3 = im[:, (w*2)//3:] \n",
    "                im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "                im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "                im3 = cv2.cvtColor(im3, cv2.COLOR_BGR2GRAY)\n",
    "                im1_s.append(im1)\n",
    "                im2_s.append(im2)\n",
    "                im3_s.append(im3)\n",
    "\n",
    "            im1_s = np.array(im1_s)\n",
    "            im2_s = np.array(im2_s)\n",
    "            im3_s = np.array(im3_s)\n",
    "            \n",
    "            yield [im1_s, im2_s, im3_s], labels\n",
    "                        \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            #class_mode='binary'\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            #class_mode='binary'\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        \n",
    "    # Compute and plot multi-class confusion-matrix with normalization\n",
    "    def plot_cm_normalized(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold)\n",
    "        print(f'cm: {cm}')\n",
    "        # Normalise\n",
    "        cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        sns.heatmap(cmn, annot=True, fmt='.3f')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show(block=False)  \n",
    "                \n",
    "    def save_false_positives(self, predictions, threshold, save_path):\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'false_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fp_preds = [p[0] for p in preds]\n",
    "        return fp_preds\n",
    "            \n",
    "    def save_true_positives(self, predictions, threshold, save_path):\n",
    "        true_positives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'true_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "\n",
    "    def save_false_negatives(self, predictions, threshold, save_path):\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'false_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fn_preds = [p[0] for p in preds]\n",
    "        return fn_preds\n",
    "            \n",
    "    def save_true_negatives(self, predictions, threshold, save_path):\n",
    "        true_negatives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'true_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 2341 images belonging to 2 classes.\n",
      "Found 2341 images belonging to 2 classes.\n",
      "74/74 [==============================] - 29s 385ms/step\n",
      "cm: [[1147    8]\n",
      " [  12 1174]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Variables --\n",
    "model_path = '/home/drevital/cs_video_processor/models/jun22_b'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/jun22_b/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'rgb'\n",
    "thresholds = [0.30]\n",
    "batch_size = 32\n",
    "save_base_path = '/home/drevital/obstacles_classification_datasets/model_eval'\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, dataset, batch_size=batch_size)\n",
    "\n",
    "# -- Define Labels\n",
    "labels = np.array([0]*handler.num_no_obstacles\\\n",
    "                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # -- Print confision-matrix\n",
    "    handler.plot_cm_normalized(model_path, labels, predictions, threshold=threshold)\n",
    "\n",
    "    # -- Save Images\n",
    "    save_name = dataset.split('/')[-2] + '_' + str(threshold)\n",
    "    save_path = os.path.join(save_base_path, save_name)\n",
    "    fn_preds = handler.save_false_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    fp_preds = handler.save_false_positives(predictions, threshold=threshold, save_path=save_path)\n",
    "    handler.save_true_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    handler.save_true_positives(predictions, threshold=threshold, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
