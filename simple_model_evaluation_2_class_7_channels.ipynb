{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=600,\n",
    "                 img_height=200,\n",
    "                 batch_size=32):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.obstacle_images = []\n",
    "        self.no_obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_obstacles = 0\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen(self.batch_size)\n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self, batch_size):\n",
    "        datagen = ImageDataGenerator(rescale=1./255.)\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen, batch_size=batch_size)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    "\n",
    "    # Special generator to generate the 3 parts of the input image as 3 separate input images\n",
    "    def three_im_generator(self, gen, dataset, target_size, batch_size, class_mode):\n",
    "\n",
    "        im_gen = gen.flow_from_directory(dataset, \n",
    "                                         target_size=target_size, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         class_mode=class_mode)\n",
    "        self.filenames = im_gen.filenames\n",
    "\n",
    "        while True:\n",
    "            im1_s, im2_s, im3_s = [], [], []\n",
    "            images, labels = im_gen.next()\n",
    "\n",
    "            for im in images:\n",
    "                w = im.shape[1]\n",
    "                im1 = im[:, :w//3]\n",
    "                im2 = im[:, w//3:(w*2)//3] \n",
    "                im3 = im[:, (w*2)//3:] \n",
    "                im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "                im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "                im3 = cv2.cvtColor(im3, cv2.COLOR_BGR2GRAY)\n",
    "                im1_s.append(im1)\n",
    "                im2_s.append(im2)\n",
    "                im3_s.append(im3)\n",
    "\n",
    "            im1_s = np.array(im1_s)\n",
    "            im2_s = np.array(im2_s)\n",
    "            im3_s = np.array(im3_s)\n",
    "            \n",
    "            yield [im1_s, im2_s, im3_s], labels\n",
    "                        \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            #class_mode='binary'\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            #class_mode='binary'\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        \n",
    "    # Compute and plot multi-class confusion-matrix with normalization\n",
    "    def plot_cm_normalized(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold)\n",
    "        print(f'cm: {cm}')\n",
    "        # Normalise\n",
    "        cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        sns.heatmap(cmn, annot=True, fmt='.3f')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show(block=False)  \n",
    "                \n",
    "    def save_false_positives(self, predictions, threshold, save_path):\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'false_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fp_preds = [p[0] for p in preds]\n",
    "        return fp_preds\n",
    "            \n",
    "    def save_true_positives(self, predictions, threshold, save_path):\n",
    "        true_positives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'true_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "\n",
    "    def save_false_negatives(self, predictions, threshold, save_path):\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'false_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fn_preds = [p[0] for p in preds]\n",
    "        return fn_preds\n",
    "            \n",
    "    def save_true_negatives(self, predictions, threshold, save_path):\n",
    "        true_negatives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'true_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 2430 images belonging to 2 classes.\n",
      "Found 2430 images belonging to 2 classes.\n",
      "76/76 [==============================] - 55s 649ms/step\n",
      "cm: [[1195    9]\n",
      " [  16 1210]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Variables --\n",
    "model_path = '/home/drevital/cs_video_processor/models/jun22_f'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/jun22_f/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'rgb'\n",
    "thresholds = [0.75]\n",
    "batch_size = 32\n",
    "save_base_path = '/home/drevital/obstacles_classification_datasets/model_eval'\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, dataset, batch_size=batch_size)\n",
    "\n",
    "# -- Define Labels\n",
    "labels = np.array([0]*handler.num_no_obstacles\\\n",
    "                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # -- Print confision-matrix\n",
    "    handler.plot_cm_normalized(model_path, labels, predictions, threshold=threshold)\n",
    "\n",
    "    # -- Save Images\n",
    "    save_name = dataset.split('/')[-2] + '_' + str(threshold)\n",
    "    save_path = os.path.join(save_base_path, save_name)\n",
    "    fn_preds = handler.save_false_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    fp_preds = handler.save_false_positives(predictions, threshold=threshold, save_path=save_path)\n",
    "    handler.save_true_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    handler.save_true_positives(predictions, threshold=threshold, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04408726],\n",
       "       [0.1030384 ],\n",
       "       [0.5379677 ],\n",
       "       [0.4298457 ],\n",
       "       [0.5794556 ],\n",
       "       [0.56267464],\n",
       "       [0.33441687],\n",
       "       [0.8970542 ],\n",
       "       [0.0802187 ],\n",
       "       [0.00924236],\n",
       "       [0.02380756],\n",
       "       [0.0009737 ],\n",
       "       [0.24404389],\n",
       "       [0.15856794],\n",
       "       [0.24507707],\n",
       "       [0.01180562],\n",
       "       [0.00482789],\n",
       "       [0.01460081],\n",
       "       [0.0154556 ],\n",
       "       [0.04674208]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
