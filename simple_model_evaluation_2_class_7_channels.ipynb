{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=600,\n",
    "                 img_height=200,\n",
    "                 batch_size=32):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.obstacle_images = []\n",
    "        self.no_obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_obstacles = 0\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen(self.batch_size)\n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self, batch_size):\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen, batch_size=batch_size)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    "\n",
    "    # Special generator to generate the 3 parts of the input image as 3 separate input images\n",
    "    def three_im_generator(self, gen, dataset, target_size, batch_size, class_mode):\n",
    "\n",
    "        im_gen = gen.flow_from_directory(dataset, \n",
    "                                         target_size=target_size, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         class_mode=class_mode)\n",
    "        self.filenames = im_gen.filenames\n",
    "\n",
    "        while True:\n",
    "            im1_s, im2_s, im3_s = [], [], []\n",
    "            images, labels = im_gen.next()\n",
    "\n",
    "            for im in images:\n",
    "                w = im.shape[1]\n",
    "                im1 = im[:, :w//3]\n",
    "                im2 = im[:, w//3:(w*2)//3] \n",
    "                im3 = im[:, (w*2)//3:] \n",
    "                im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "                im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "                im3 = cv2.cvtColor(im3, cv2.COLOR_BGR2GRAY)\n",
    "                im1_s.append(im1)\n",
    "                im2_s.append(im2)\n",
    "                im3_s.append(im3)\n",
    "\n",
    "            im1_s = np.array(im1_s)\n",
    "            im2_s = np.array(im2_s)\n",
    "            im3_s = np.array(im3_s)\n",
    "            yield [im1_s, im2_s, im3_s], labels\n",
    "            \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        \n",
    "    # Compute and plot multi-class confusion-matrix with normalization\n",
    "    def plot_cm_normalized(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold)\n",
    "        # Normalise\n",
    "        cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        sns.heatmap(cmn, annot=True, fmt='.3f')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show(block=False)  \n",
    "                \n",
    "    def display_false_positives(self, predictions, threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        if 500 > len(false_positives) > 1:\n",
    "            num_images = len(false_positives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_positives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                print(f'FP prediction: {preds[i]}, imname: {imname}')\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_positives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show()\n",
    "            \n",
    "    def display_false_negatives(self, predictions, threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "\n",
    "        if 500 > len(false_negatives) > 1:\n",
    "            num_images = len(false_negatives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_negatives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_negatives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show()\n",
    "            \n",
    "    def save_false_positives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'false_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "    def save_true_positives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        true_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'true_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "\n",
    "    def save_false_negatives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'false_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "    def save_true_negatives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        true_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'true_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 1432 images belonging to 2 classes.\n",
      "Found 1432 images belonging to 2 classes.\n",
      "45/45 [==============================] - 15s 321ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Variables --\n",
    "model_path = '/home/drevital/cs_video_processor/models/7_channels_humid'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/7_channels_humid/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'rgb'\n",
    "threshold = 0.70\n",
    "batch_size = 32\n",
    "save_base_path = '/home/drevital/obstacles_classification_datasets/model_eval'\n",
    "save_name = dataset.split('/')[-2] + '_' + str(threshold)\n",
    "save_path = os.path.join(save_base_path, save_name)\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, dataset, batch_size=batch_size)\n",
    "\n",
    "# -- Define Labels\n",
    "labels = np.array([0]*handler.num_no_obstacles\\\n",
    "                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "# -- Print confision-matrix\n",
    "handler.plot_cm_normalized(model_path, labels, predictions, threshold=threshold)\n",
    "\n",
    "# -- Save Images\n",
    "handler.save_false_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "handler.save_false_positives(predictions, threshold=threshold, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
