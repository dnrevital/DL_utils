{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "import os\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=600,\n",
    "                 img_height=200,\n",
    "                 batch_size=32,\n",
    "                 thresh_csv_fname=None,\n",
    "                 metrics_csv_fname=None):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.obstacle_images = []\n",
    "        self.no_obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_obstacles = 0\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen()\n",
    "        \n",
    "        self.model_score = ModelScore()\n",
    "\n",
    "        if thresh_csv_fname:\n",
    "            thresh_csv_path = os.path.join(model_path, thresh_csv_fname)\n",
    "            self.f_thresh_csv = open(thresh_csv_path, 'w')\n",
    "            self.thresh_csv_writer = csv.writer(self.f_thresh_csv)\n",
    "            \n",
    "            self.thresh_csv_header = ['model',\n",
    "                                      'dataset',\n",
    "                                      'Max Lost Ratio',\n",
    "                                      'Lower Threshold',\n",
    "                                      'Upper Threshold',\n",
    "                                      'Total Predictions',\n",
    "                                      'TP',\n",
    "                                      '% TP',\n",
    "                                      'TN',\n",
    "                                      '% TN',\n",
    "                                      'FP',\n",
    "                                      '% FP',\n",
    "                                      'FN',\n",
    "                                      '% FN',\n",
    "                                      'Not Decided',\n",
    "                                      '% Not Decided',\n",
    "                                      'True Not Decided',\n",
    "                                      '% True Not Decided']\n",
    "            \n",
    "            self.thresh_csv_writer.writerow(self.thresh_csv_header)\n",
    "            \n",
    "        if metrics_csv_fname:\n",
    "            metrics_csv_path = os.path.join(model_path, metrics_csv_fname)\n",
    "            self.f_metrics_csv = open(metrics_csv_path, 'w')\n",
    "            self.metrics_csv_writer = csv.writer(self.f_metrics_csv)\n",
    "\n",
    "            metrics_prefixes = ['test', 'validation', '']\n",
    "            metrics_separators = [' ', ' ', '']\n",
    "            metrics_functions = ['auc', 'recall', 'specifity']\n",
    "            \n",
    "            self.metrics_csv_header = ['Trial Name']\n",
    "            self.metrics_csv_header.append('Model Score')\n",
    "            self.metrics_csv_header.append('Lost True Values %')\n",
    "            self.metrics_csv_header.append('Lower Threshold')\n",
    "            self.metrics_csv_header.append('Upper Threshold')\n",
    "            self.metrics_csv_header.append('% FP')\n",
    "            self.metrics_csv_header.append('% FN')\n",
    "            \n",
    "            for i, metrics_prefix in enumerate(metrics_prefixes):\n",
    "                for metrics_function in metrics_functions:\n",
    "                    metric_name = metrics_separators[i].join([metrics_prefix, metrics_function])\n",
    "                    self.metrics_csv_header.append('max ' + metric_name)\n",
    "            \n",
    "            self.metrics_csv_writer.writerow(self.metrics_csv_header)        \n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self):\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    "\n",
    "    # Special generator to generate the 3 parts of the input image as 3 separate input images\n",
    "    def three_im_generator(self, gen, dataset, target_size, batch_size, class_mode):\n",
    "\n",
    "        im_gen = gen.flow_from_directory(dataset, \n",
    "                                         target_size=target_size, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         class_mode=class_mode)\n",
    "        self.filenames = im_gen.filenames\n",
    "\n",
    "        while True:\n",
    "            im1_s, im2_s, im3_s = [], [], []\n",
    "            images, labels = im_gen.next()\n",
    "\n",
    "            for im in images:\n",
    "                w = im.shape[1]\n",
    "                im1 = im[:, :w//3]\n",
    "                im2 = im[:, w//3:(w*2)//3] \n",
    "                im3 = im[:, (w*2)//3:] \n",
    "                im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "                im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "                im3 = cv2.cvtColor(im3, cv2.COLOR_BGR2GRAY)\n",
    "                im1_s.append(im1)\n",
    "                im2_s.append(im2)\n",
    "                im3_s.append(im3)\n",
    "\n",
    "            im1_s = np.array(im1_s)\n",
    "            im2_s = np.array(im2_s)\n",
    "            im3_s = np.array(im3_s)\n",
    "            yield [im1_s, im2_s, im3_s], labels\n",
    "            \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        \n",
    "    # Compute and plot multi-class confusion-matrix, with given threshold values\n",
    "    def plot_cm_with_thresh(self,\n",
    "                            model_path,\n",
    "                            labels,\n",
    "                            predictions,\n",
    "                            predicted_classes,\n",
    "                            lower_thresh,\n",
    "                            upper_thresh):\n",
    "        \n",
    "        # Calculate number of values for each <class vs. class> considering the thresholds\n",
    "        \n",
    "        noobs_as_noobs = len([p for p in predicted_classes[:self.num_no_obstacles] if p==0])        \n",
    "        noobs_as_obs = len([p for p in predicted_classes[:self.num_no_obstacles] if p==1])\n",
    "        obs_as_noobs = len([p for p in predicted_classes[self.num_no_obstacles:] if p==0])\n",
    "        obs_as_obs = len([p for p in predicted_classes[self.num_no_obstacles:] if p==1])\n",
    "        noobs_as_undecided = len([p for p in predicted_classes[:self.num_no_obstacles] if p==2])        \n",
    "        obs_as_undecided = len([p for p in predicted_classes[self.num_no_obstacles:] if p==2])\n",
    "        \n",
    "        cm = [[noobs_as_noobs, noobs_as_obs, noobs_as_undecided],\n",
    "             [obs_as_noobs, obs_as_obs, obs_as_undecided]]\n",
    "        \n",
    "        print(f'cm: {cm}')\n",
    "        \n",
    "        # Creating a dataframe for a array-formatted Confusion matrix\n",
    "        cm_df = pd.DataFrame(cm,\n",
    "                             index = ['NO_OBSTACLE', 'OBSTACLE'], \n",
    "                             columns = ['NO_OBSTACLE', 'OBSTACLE', 'NOT_DECIDED'])\n",
    "        \n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.heatmap(cm_df, annot=True, fmt='d')\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label')        \n",
    "        \n",
    "    # Compute and plot confusion-matrix (TP, FP, TN, FN)\n",
    "    def calc_cm(self,\n",
    "                model_path,\n",
    "                labels,\n",
    "                predictions,\n",
    "                p=0.5,\n",
    "                max_lost_ratio=0,\n",
    "                not_decided=0,\n",
    "                trues=0,\n",
    "                true_not_decided=0,\n",
    "                lower_threshold=None,\n",
    "                upper_threshold=None,\n",
    "                print_params=True,\n",
    "                print_to_csv=False):\n",
    "\n",
    "        cm = confusion_matrix(labels, predictions > p)        \n",
    "\n",
    "        predicts = sum(sum(x) for x in cm)\n",
    "        tot_predicts = predicts + not_decided\n",
    "        \n",
    "        TN = cm[0][0]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "        TP = cm[1][1]\n",
    "        \n",
    "        TN_percent = (TN/tot_predicts)*100\n",
    "        FP_percent = (FP/tot_predicts)*100\n",
    "        FN_percent = (FN/tot_predicts)*100\n",
    "        TP_percent = (TP/tot_predicts)*100\n",
    "        not_decided_percent = (not_decided/tot_predicts)*100\n",
    "        true_not_decided_percent = (true_not_decided/trues)*100\n",
    "\n",
    "        if print_params:\n",
    "            print()\n",
    "            if max_lost_ratio:\n",
    "                print(f'Max Lost Ratio: {max_lost_ratio}')\n",
    "            print(f'No Obstacles Detected (True Negatives): {TN} ({TN_percent:.2f}%)')\n",
    "            print(f'No Obstacles Incorrectly Detected (False Positives): {FP} ({FP_percent:.2f}%)')\n",
    "            print(f'Obstacles Missed (False Negatives): {FN} ({FN_percent:.2f}%)')\n",
    "            print(f'Obstacles Detected (True Positives): {TP} ({TP_percent:.2f}%)')\n",
    "            if not_decided:\n",
    "                print(f'Not Decided: {not_decided} ({not_decided_percent:.2f}%)')\n",
    "            if true_not_decided:\n",
    "                print(f'True Not Decided: {true_not_decided} ({true_not_decided_percent:.2f}%)')\n",
    "            print(f'Total Obstacles: {tot_predicts}')\n",
    "        \n",
    "        self.model_score.add_model_option(true_not_decided,\n",
    "                                          true_not_decided_percent/100.0,\n",
    "                                          FP,\n",
    "                                          FP_percent/100.0,\n",
    "                                          FN,\n",
    "                                          FN_percent/100.0,\n",
    "                                          lower_threshold,\n",
    "                                          upper_threshold,\n",
    "                                          predictions=predictions)\n",
    "        \n",
    "        if print_to_csv:\n",
    "            # Prepare arguments for writing to csv\n",
    "            args = {'model': model_path,\n",
    "                    'Max Lost Ratio': max_lost_ratio,\n",
    "                    'Lower Threshold': lower_threshold,\n",
    "                    'Upper Threshold': upper_threshold,\n",
    "                    'Total Predictions': tot_predicts,\n",
    "                    'TP': TP,\n",
    "                    '% TP': TP_percent,\n",
    "                    'TN': TN,\n",
    "                    '% TN': TN_percent,\n",
    "                    'FP': FP,\n",
    "                    '% FP': FP_percent,\n",
    "                    'FN': FN,\n",
    "                    '% FN': FN_percent,\n",
    "                    'Not Decided': not_decided,\n",
    "                    '% Not Decided': not_decided_percent,\n",
    "                    'True Not Decided': true_not_decided,\n",
    "                    '% True Not Decided': true_not_decided_percent}\n",
    "            self.write_csv(**args)\n",
    "        \n",
    "        \n",
    "    # Same as above, with consideration of lower and upper threshold \n",
    "    # For values between those thresholds \"not decided\" is returned, \n",
    "    # so it lowers the no. of FP and FN\n",
    "    def calc_cm_considering_thresholds(self,\n",
    "                                       model_path,\n",
    "                                       labels,\n",
    "                                       predictions,\n",
    "                                       lower_threshold,\n",
    "                                       upper_threshold,\n",
    "                                       max_lost_ratio=0,\n",
    "                                       threshold=0.5,\n",
    "                                       print_params=True,\n",
    "                                       print_to_csv=False):\n",
    "        no_obs_preds = predictions[:self.num_no_obstacles]\n",
    "        no_obs_margin_preds = [p for p in no_obs_preds if p < lower_threshold or p > upper_threshold]\n",
    "        no_obs_margin_labels = [0]*len(no_obs_margin_preds)\n",
    "        true_no_obs_preds = [p for p in no_obs_preds if p <= 0.5]\n",
    "        true_no_obs_not_decided_preds = [p for p in no_obs_preds if lower_threshold < p <= 0.5]\n",
    "        obs_preds = predictions[self.num_no_obstacles:]\n",
    "        obs_margin_preds = [p for p in obs_preds if p < lower_threshold or p > upper_threshold]\n",
    "        obs_margin_labels = [1]*len(obs_margin_preds)\n",
    "        true_obs_preds = [p for p in obs_preds if p >= 0.5]\n",
    "        true_obs_not_decided_preds = [p for p in obs_preds if upper_threshold > p >= 0.5]\n",
    "        margin_preds = no_obs_margin_preds + obs_margin_preds\n",
    "        margin_preds = np.array(margin_preds, dtype=float)\n",
    "        true_preds = true_no_obs_preds + true_obs_preds\n",
    "        true_not_decided_preds = true_no_obs_not_decided_preds + true_obs_not_decided_preds\n",
    "        margin_labels = no_obs_margin_labels + obs_margin_labels\n",
    "        margin_labels = np.array(margin_labels, dtype=float)\n",
    "        not_decided = len(predictions) - len(margin_preds)\n",
    "        trues = len(true_preds)\n",
    "        true_not_decided = len(true_not_decided_preds)\n",
    "\n",
    "        self.calc_cm(model_path,\n",
    "                     margin_labels,\n",
    "                     margin_preds,\n",
    "                     max_lost_ratio=max_lost_ratio,\n",
    "                     not_decided=not_decided,\n",
    "                     trues=trues,\n",
    "                     true_not_decided=true_not_decided,\n",
    "                     lower_threshold=lower_threshold,\n",
    "                     upper_threshold=upper_threshold,\n",
    "                     print_params=print_params,\n",
    "                     print_to_csv=print_to_csv)\n",
    "            \n",
    "    def display_false_negatives(self, predictions, lower_threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] < lower_threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p < threshold]\n",
    "\n",
    "        if 500 > len(false_negatives) > 1:\n",
    "            num_images = len(false_negatives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_negatives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_negatives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show() \n",
    "            \n",
    "    def display_false_positives(self, predictions, upper_threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > upper_threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > upper_threshold]\n",
    "\n",
    "        if 500 > len(false_positives) > 1:\n",
    "            num_images = len(false_positives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_positives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                print(f'FP prediction: {preds[i]}, imname: {imname}')\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_positives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show()\n",
    "            \n",
    "    def display_not_decided(self, predcitions, filenames, lower_threshold, upper_threshold):\n",
    "        obstacle_image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        no_obstacle_image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        obs_title = ''\n",
    "        \n",
    "        not_decided = [fname for i, fname in enumerate(filenames)\\\n",
    "                       if ((lower_threshold < predictions[i] <= 0.5)\\\n",
    "                           and (fname.split('/')[-1] in no_obstacle_image_names))\\\n",
    "                           or ((0.5 <= predictions[i] < upper_threshold)\\\n",
    "                           and (fname.split('/')[-1] in obstacle_image_names))]\n",
    "        \n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                       if ((lower_threshold < p <= 0.5)\\\n",
    "                           and (filenames[i].split('/')[-1] in no_obstacle_image_names))\\\n",
    "                           or ((0.5 <= p < upper_threshold)\\\n",
    "                           and (filenames[i].split('/')[-1] in obstacle_image_names))]\n",
    "\n",
    "        if 500 > len(not_decided) > 1:\n",
    "            num_images = len(not_decided)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(1.5*num_images, 1.5*num_images))\n",
    "\n",
    "            for i, fname in enumerate(not_decided):\n",
    "                imname = fname.split('/')[-1]\n",
    "                if imname in obstacle_image_names:\n",
    "                    impath = os.path.join(self.obstacle_dataset, imname)\n",
    "                    obs_title = 'obs'\n",
    "                else:\n",
    "                    impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "                    obs_title = 'no_obs'\n",
    "                im = cv2.imread(impath)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(' '.join([imname, obs_title, str(preds[i]), (' '*30)]))\n",
    "            plt.show()\n",
    "        elif not_decided:\n",
    "            imname = not_decided[0].split('/')[-1]\n",
    "            if imname in obstacle_image_names:\n",
    "                impath = os.path.join(self.obstacle_dataset, imname)\n",
    "                obs_title = 'obs'\n",
    "            else:\n",
    "                impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "                obs_title = 'no_obs'\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(' '.join([imname, obs_title, str(preds[0])]))\n",
    "            plt.show()\n",
    "\n",
    "    # An algorithm for optimal threshold taken from \n",
    "    # https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
    "    # left here on case we consider re-using it.\n",
    "    # Currently we are using the 2nd algorithm below\n",
    "    def optimal_threshold_by_gmeans(self, num_no_obstacles, num_obstacles, predictions):\n",
    "        true_values = [0]*num_no_obstacles + [1]*num_obstacles \n",
    "        fpr, tpr, thresholds = roc_curve(true_values, predictions)\n",
    "        gmeans = sqrt(tpr * (1-fpr))\n",
    "        ix = argmax(gmeans)\n",
    "\n",
    "        return thresholds[ix]    \n",
    " \n",
    "    # 2nd algorithm for finding optimal threshold, own developed\n",
    "    # Currently used\n",
    "    # Params: \n",
    "    #    -- predictions - a list of predicted values for no_obstacle / obstacle\n",
    "    #    -- max_lost_ratio - a float [0.0-1.0], indicating the target maximum ratio (%/100)\n",
    "    #    of (\"not decided\" / all) true values, for TP and TN - this is to avoid putting extreme \n",
    "    #    low/high thresholds, which will lower FN/FP, but will leave too few True values returned.\n",
    "    #    This ratio (\"not_decided\" / all) is called here \"lost ratio\"\n",
    "    # Steps:\n",
    "    # 1. Set as (min_thresold / max_thresold) ==> (min(FN) / max(FP))\n",
    "    #       Using this will perform with 0 FN/FP, \n",
    "    #       as there are neither FN below lower_thresold, not FP above upper_threshold,\n",
    "    #       but --potentially-- with too many \"not decided\"\n",
    "    # 2. If the lost ratio is too high - start lowering it to the target, using binary search\n",
    "    #       to find the point where the ratio does not exceed the maximum lost-ration,\n",
    "    #       while keeping the lower/upper thresholds as close as possible to their \n",
    "    #       original values. \n",
    "    def find_thresholds(self, predictions, max_lost_ratio=0.1):\n",
    "        no_obs_preds = predictions[:handler.num_no_obstacles]\n",
    "        obs_preds = predictions[handler.num_no_obstacles:]\n",
    "        false_positives = np.array([p for p in no_obs_preds if p >= 0.5])\n",
    "        false_negatives = np.array([p for p in obs_preds if p < 0.5])\n",
    "        true_positives = np.array([p for p in obs_preds if p >= 0.5])\n",
    "        true_negatives = np.array([p for p in no_obs_preds if p < 0.5])\n",
    "        false_positives.sort(axis=0) \n",
    "        false_negatives.sort(axis=0)\n",
    "        true_positives.sort(axis=0)\n",
    "        true_negatives.sort(axis=0)\n",
    "\n",
    "        true_positives_above = np.array([p for p in true_positives if p > max(false_positives)])\n",
    "        true_negatives_below = np.array([p for p in true_negatives if p < min(false_negatives)])\n",
    "        lost_true_positives = np.array([p for p in true_positives if p <= max(false_positives)])\n",
    "        true_positives_lost_ratio = len(lost_true_positives) / len(true_positives)\n",
    "        lost_true_negatives = np.array([p for p in true_negatives if p >= min(false_negatives)])\n",
    "        true_negatives_lost_ratio = len(lost_true_negatives) / len(true_negatives)\n",
    "\n",
    "        lower_threshold = min(false_negatives)\n",
    "        lower_threshold_ind = np.where(true_negatives > lower_threshold)[0][0]\n",
    "        num_true_negatives = len(true_negatives)\n",
    "        gap = num_true_negatives - lower_threshold_ind\n",
    "        \n",
    "        # Binary search to find the point where no. of \"not decided\" satisfies the target\n",
    "\n",
    "        if true_negatives_lost_ratio > max_lost_ratio:\n",
    "            while gap:\n",
    "                lost_ratio_diff = true_negatives_lost_ratio - max_lost_ratio\n",
    "                if abs(lost_ratio_diff) < 0.01:\n",
    "                    break\n",
    "                gap //= 2\n",
    "                if lost_ratio_diff < 0.0:\n",
    "                    lower_threshold_ind -= gap\n",
    "                else:\n",
    "                    lower_threshold_ind += gap\n",
    "                lost_true_negatives = true_negatives[lower_threshold_ind:]\n",
    "                true_negatives_lost_ratio = len(lost_true_negatives) / num_true_negatives\n",
    "\n",
    "            lower_threshold = true_negatives[lower_threshold_ind] \n",
    "            \n",
    "        upper_threshold = max(false_positives)\n",
    "        upper_threshold_ind = np.where(true_positives > upper_threshold)[0][0]\n",
    "        num_true_positives = len(true_positives)\n",
    "        gap = upper_threshold_ind\n",
    "\n",
    "        # Binary search to find the point where no. of \"not decided\" satisfies the target\n",
    "        \n",
    "        if true_positives_lost_ratio > max_lost_ratio:\n",
    "            while gap:\n",
    "                lost_ratio_diff = true_positives_lost_ratio - max_lost_ratio\n",
    "                if abs(lost_ratio_diff) < 0.01:\n",
    "                    break\n",
    "                gap //= 2\n",
    "                if lost_ratio_diff < 0.0:\n",
    "                    upper_threshold_ind += gap\n",
    "                else:\n",
    "                    upper_threshold_ind -= gap\n",
    "                lost_true_positives = true_positives[:upper_threshold_ind]\n",
    "                true_positives_lost_ratio = len(lost_true_positives) / num_true_positives\n",
    "\n",
    "            upper_threshold = true_positives[upper_threshold_ind]\n",
    "            \n",
    "        return lower_threshold[0], upper_threshold[0]\n",
    "    \n",
    "    def write_metrics_to_csv(self, trial_component_display_name, print_params=True):\n",
    "        client = boto3.client('sagemaker', region_name='eu-west-1')\n",
    "        trials = client.list_trial_components()['TrialComponentSummaries']\n",
    "        trial = [t for t in trials if t['DisplayName'] == trial_component_display_name]\n",
    "        trial_description = None\n",
    "        \n",
    "        if trial:\n",
    "            trial_component_name = trial[0]['TrialComponentName']\n",
    "            trial_description = client.describe_trial_component(TrialComponentName=trial_component_name)\n",
    "\n",
    "        metrics_values = [trial_component_display_name]        \n",
    "\n",
    "        best_option = self.model_score.scored_models[self.model_score.best_option]\n",
    "        metrics_values.append(best_option['score'])\n",
    "        metrics_values.append(best_option['lost_true_values_percentage'])\n",
    "        metrics_values.append(best_option['lower_threshold'])\n",
    "        metrics_values.append(best_option['upper_threshold'])\n",
    "        metrics_values.append(best_option['false_positives_percentage'])\n",
    "        metrics_values.append(best_option['false_negatives_percentage'])\n",
    "        \n",
    "        if print_params:\n",
    "            print(f'best option: {best_option[\"lost_true_values_percentage\"]:.2f}')\n",
    "            print(f'score: {best_option[\"score\"]}')\n",
    "            print(f'lower_threshold: {best_option[\"lower_threshold\"]:.2f}')\n",
    "            print(f'upper_threshold: {best_option[\"upper_threshold\"]:.2f}')\n",
    "            print(f'%FP: {best_option[\"false_positives_percentage\"]*100:.2f}')\n",
    "            print(f'%FN: {best_option[\"false_negatives_percentage\"]*100:.2f}')\n",
    "\n",
    "        if trial_description:\n",
    "            metrics = trial_description['Metrics']\n",
    "\n",
    "            metrics_prefixes = ['test', 'validation', '']\n",
    "            metrics_separators = [' ', ' ', '']\n",
    "            metrics_functions = ['auc', 'recall', 'specifity']        \n",
    "\n",
    "            for i, metrics_prefix in enumerate(metrics_prefixes):\n",
    "                for metrics_function in metrics_functions:\n",
    "                    metric_name = metrics_separators[i].join([metrics_prefix, metrics_function])\n",
    "                    metric_value = [m for m in metrics if m['MetricName'] == metric_name]\n",
    "                    metrics_values.append(metric_value[0]['Max'])\n",
    "                                \n",
    "        self.metrics_csv_writer.writerow(metrics_values) \n",
    "\n",
    "    def write_csv(self, **args):        \n",
    "        row = []\n",
    "        keys = args.keys()\n",
    "        \n",
    "        if 'model' in keys:\n",
    "            row.append(args['model'])\n",
    "            \n",
    "        row.append(self.dataset)\n",
    "        \n",
    "        for col in self.thresh_csv_header[2:]:\n",
    "            if col in keys:\n",
    "                row.append(args[col])\n",
    "            else:\n",
    "                row.append(None)\n",
    "        \n",
    "        self.thresh_csv_writer.writerow(row)\n",
    "        \n",
    "    # Method to run when class is deleted\n",
    "    def __del__(self):\n",
    "        self.f_thresh_csv.close()\n",
    "        self.f_metrics_csv.close()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class to calculate model's score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelScore():\n",
    "    def __init__(self, alpha=0.7, beta=1.2, gamma=30):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.max_score = 0.0\n",
    "        self.scored_model_ind = 0\n",
    "        self.scored_models = []\n",
    "        \n",
    "    '''\n",
    "    Cliff shape function\n",
    "    \n",
    "    Based on the Sigmoid function:\n",
    "        1/(1 + np.exp(-x))\n",
    "\n",
    "    with:\n",
    "    1. Changing (x) to (1-x), so we flip the curve to be high near 0 and decline sharply at some point, till reaching zero\n",
    "    2. Adding alpha, beta and gamma modifiers to enable controlling the curve's attributes:\n",
    "        * alpha controls the point where the graph starts to decline sharply (= the % of lost true values which is berable and should get relatively high score for this aspect)\n",
    "        * beta controls the width of the sharply declining portion of the curve\n",
    "        * gamma controls the smoothness of the cliff-shape part of the graph. A high gamma will make the curvie less somooth, i.e. more 'cliffy'. \n",
    "\n",
    "    So our Sigmoid-modofied function is:\n",
    "\n",
    "        1/(1 + np.exp(-(1-(x+alpha)*beta)*gamma)) \n",
    "    '''\n",
    "    def cliff(self, x):\n",
    "        return 1/(1 + np.exp(-(1-(x+self.alpha)*self.beta)*self.gamma)) \n",
    "    \n",
    "    # A method to insert into overall model's scores an option, regarding \n",
    "    # the lost_true_value_percentage. \n",
    "    # The goal is that the class remembers the score attached to this option,\n",
    "    # then can compare all scores and find the best one\n",
    "    def add_model_option(self,\n",
    "                         lost_true_values,\n",
    "                         lost_true_values_percentage,\n",
    "                         false_positives,\n",
    "                         false_positives_percentage,\n",
    "                         false_negatives,\n",
    "                         false_negatives_percentage,\n",
    "                         lower_threshold,\n",
    "                         upper_threshold,\n",
    "                         predictions):\n",
    "        \n",
    "        s1 = self.cliff(lost_true_values_percentage)\n",
    "        s2 = 1.0 - (false_positives_percentage + false_negatives_percentage)\n",
    "        score = (s1 + s2) / 2\n",
    "        if score > self.max_score:\n",
    "            self.max_score = score\n",
    "            self.best_option = self.scored_model_ind\n",
    "        scored_model = {}\n",
    "        scored_model['score'] = score\n",
    "        scored_model['lost_true_values'] = lost_true_values\n",
    "        scored_model['lost_true_values_percentage'] = lost_true_values_percentage\n",
    "        scored_model['false_positives'] = false_positives\n",
    "        scored_model['false_positives_percentage'] = false_positives_percentage\n",
    "        scored_model['false_negatives'] = false_negatives\n",
    "        scored_model['false_negatives_percentage'] = false_negatives_percentage\n",
    "        scored_model['lower_threshold'] = lower_threshold\n",
    "        scored_model['upper_threshold'] = upper_threshold\n",
    "        scored_model['predictions'] = predictions\n",
    "        self.scored_models.append(scored_model)\n",
    "        self.scored_model_ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 1407 images belonging to 2 classes.\n",
      "Found 1407 images belonging to 2 classes.\n",
      "44/44 [==============================] - 22s 503ms/step\n",
      "Experimenting best max_ratio ...\n",
      "0.0050...0.0100...0.0150...0.0200...0.0250...0.0300...0.0350...0.0400...0.0450...0.0500...0.0550...0.0600...0.0650...0.0700...0.0750...0.0800...0.0850...0.0900...0.0950...0.1000...0.1050...0.1100...0.1150...0.1200...0.1250...0.1300...0.1350...0.1400...0.1450...0.1500...0.1550...0.1600...0.1650...0.1700...0.1750...0.1800...0.1850...0.1900...0.1950...0.2000...\n",
      "\n",
      "\n",
      "best option score: 0.9906524933817873\n",
      "best option lower threshold: 0.3590511083602905\n",
      "best option upper threshold: 0.7657098174095154\n",
      "best option lost true values: 16 (1.15%)\n",
      "best option false negatives: 7 (0.50%)\n",
      "best option false positives: 2 (0.14%)\n",
      "cm: [[604, 2, 10], [7, 771, 13]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Variables --\n",
    "trial_component_display_name = None\n",
    "model_path = '/home/drevital/cs_video_processor/models/7_channels_morph'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/7_channels_morph/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'rgb'\n",
    "thresh_csv_fname = f'model_thresholds.{model_name}.csv'\n",
    "#metrics_csv_fname = f'model_metrics.{model_name}.csv'\n",
    "#thresh_csv_fname = None\n",
    "print_metrics = False\n",
    "metrics_csv_fname = None\n",
    "print_cm_params=False\n",
    "display_cm_figure = False\n",
    "display_false_negatives = False\n",
    "display_false_positives = False\n",
    "display_not_decided = False\n",
    "print_best_option_params=True\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, \n",
    "                         dataset, \n",
    "                         thresh_csv_fname=thresh_csv_fname,\n",
    "                         metrics_csv_fname=metrics_csv_fname)\n",
    "\n",
    "# -- Print metrics\n",
    "if print_metrics:\n",
    "    metrics = handler.print_model_metrics(model, color_mode)\n",
    "    \n",
    "# Build labels array for prediction\n",
    "labels = np.array([0]*handler.num_no_obstacles\\\n",
    "                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "# Find optimal lower, upper thresholds per given max limit of \"not decided\" (\"lost\") predictions\n",
    "max_lost_ratios = np.arange(start=0.005, stop=0.205, step=0.005)\n",
    "\n",
    "print('Experimenting best max_ratio ...')\n",
    "for max_lost_ratio in max_lost_ratios:\n",
    "    lower_threshold, upper_threshold = handler.find_thresholds(predictions,\n",
    "                                                               max_lost_ratio=max_lost_ratio)\n",
    "    print(f'{max_lost_ratio:.4f}', end='...')\n",
    "    # Print confusion-matrix after using recommended thresholds\n",
    "    handler.calc_cm_considering_thresholds(model_path,\n",
    "                                           labels,\n",
    "                                           predictions,\n",
    "                                           lower_threshold,\n",
    "                                           upper_threshold,\n",
    "                                           max_lost_ratio=max_lost_ratio,\n",
    "                                           threshold=0.5,\n",
    "                                           print_params=print_cm_params,\n",
    "                                           print_to_csv=False)\n",
    "    \n",
    "best_option = handler.model_score.scored_models[handler.model_score.best_option]\n",
    "\n",
    "print('\\n\\n')\n",
    "print(f'best option score: {best_option[\"score\"]}')\n",
    "print(f'best option lower threshold: {best_option[\"lower_threshold\"]}')\n",
    "print(f'best option upper threshold: {best_option[\"upper_threshold\"]}')\n",
    "print(f'best option lost true values: {best_option[\"lost_true_values\"]}', end = ' ')\n",
    "print(f'({best_option[\"lost_true_values_percentage\"]*100:.2f}%)')\n",
    "print(f'best option false negatives: {best_option[\"false_negatives\"]}', end=' ')\n",
    "print(f'({best_option[\"false_negatives_percentage\"]*100:.2f}%)')\n",
    "print(f'best option false positives: {best_option[\"false_positives\"]}', end=' ')\n",
    "print(f'({best_option[\"false_positives_percentage\"]*100:.2f}%)')\n",
    "\n",
    "lower_threshold = best_option['lower_threshold']\n",
    "upper_threshold = best_option['upper_threshold']\n",
    "\n",
    "# -- Generate predictions array in the for [0,1,2] for [no_obstacle, obstacle, not_decided]\n",
    "predicted_classes= []\n",
    "for prediction in predictions:\n",
    "    classification_states = [prediction <= lower_threshold,\n",
    "                             prediction >= upper_threshold,\n",
    "                             lower_threshold < prediction < upper_threshold]\n",
    "    predicted_classes.append(np.where(classification_states)[0][0])\n",
    "    \n",
    "# -- Print confusion-matrix considering the older \"no decision\" thresholds\n",
    "handler.plot_cm_with_thresh(model_path,\n",
    "                            labels,\n",
    "                            predictions,\n",
    "                            predicted_classes,\n",
    "                            lower_threshold,\n",
    "                            upper_threshold)\n",
    "\n",
    "if display_false_negatives:\n",
    "    print('\\nFALSE NEGATIVES\\n')\n",
    "    handler.display_false_negatives(predictions, filenames, lower_threshold)\n",
    "\n",
    "if display_false_positives:\n",
    "    print('\\nFALSE POSITIVES\\n')\n",
    "    handler.display_false_positives(predictions, filenames, upper_threshold)\n",
    "\n",
    "if display_not_decided:\n",
    "    print('\\nNOT DECIDED\\n')\n",
    "    handler.display_not_decided(predictions, filenames, lower_threshold, upper_threshold)\n",
    "\n",
    "print()\n",
    "    \n",
    "# Retrieve model's metrics from SageMaker and write them to the handler's .csv file\n",
    "if trial_component_display_name:\n",
    "    handler.write_metrics_to_csv(trial_component_display_name,\n",
    "                             print_params=print_best_option_params)\n",
    "del handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
