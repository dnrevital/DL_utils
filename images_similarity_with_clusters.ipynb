{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "from os.path import exists\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_dir = '/home/drevital/pallet_detection/feb23_task_test_1'\n",
    "clusters_base_path = '/home/drevital/pallet_detection/f1'\n",
    "Path(clusters_base_path).mkdir(parents=True, exist_ok=True)\n",
    "features_path = os.path.join(clusters_base_path, 'features.csv')\n",
    "im_height = 200\n",
    "im_width = 600\n",
    "num_clusters = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(f1, f2):\n",
    "    return 1 - spatial.distance.cosine(f1, f2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_images(feature_vectors, similarity_function, num_clusters):\n",
    "    similarities = []\n",
    "    size = len(feature_vectors)\n",
    "    for i in range(size):\n",
    "        for j in range(i+1, size):\n",
    "            similarities.append(similarity_function(feature_vectors[i], feature_vectors[j]))\n",
    "\n",
    "    # Normalize the similarity values\n",
    "    min_sim = min(similarities)\n",
    "    max_sim = max(similarities)\n",
    "    rng = max_sim - min_sim\n",
    "    similarities = [(sim - min_sim) / rng for sim in similarities]\n",
    "    \n",
    "    similarities = np.array(similarities)\n",
    "    pairwise_similarities = squareform(similarities)\n",
    "    #clustering = AgglomerativeClustering(n_clusters=num_clusters, affinity='precomputed', linkage='average').fit(pairwise_similarities)\n",
    "    clustering = AgglomerativeClustering(n_clusters=num_clusters, affinity='precomputed', linkage='complete').fit(pairwise_similarities)\n",
    "    clusters = [[] for _ in range(num_clusters)]\n",
    "    for i, label in enumerate(clustering.labels_):\n",
    "        clusters[label].append(i)\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MobileNet Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_handle = 'https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4'\n",
    "module = hub.load(module_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare compared images for features_calc and similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_names = []\n",
    "sim_scores = []\n",
    "fnames = os.listdir(search_dir)\n",
    "feature_vecs = {}\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and store all compared directories's images' feature-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vecs = {}\n",
    "i=0\n",
    "\n",
    "if not exists(features_path):\n",
    "    for fname in tqdm(fnames):\n",
    "        impath = os.path.join(search_dir, fname)\n",
    "        im = tf.io.read_file(impath)\n",
    "        im = tf.io.decode_jpeg(im, channels=3)\n",
    "        im = tf.image.resize_with_pad(im, 224, 224)\n",
    "        # Convert to shape (1, 224, 224, 3) float\n",
    "        im  = tf.image.convert_image_dtype(im, tf.float32)[tf.newaxis, ...]\n",
    "        f = module(im)   \n",
    "        f_set = np.squeeze(f)  \n",
    "        feature_vecs[i] = {'path': impath, 'features': f_set}\n",
    "        i += 1\n",
    "        \n",
    "    features_df = pd.DataFrame.from_dict(feature_vecs).transpose() \n",
    "    features_df.to_csv(features_path, sep=',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Feature Vectors from the .csv File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(features_path, delimiter=',')\n",
    "feature_vectors = []\n",
    "feature_vectors_map = {}\n",
    "\n",
    "for i, fname in enumerate(fnames):\n",
    "    impath = os.path.join(search_dir, fname)\n",
    "    row = features_df[features_df['path'] == impath]\n",
    "    fvec = [float(item) for item in row['features'].tolist()[0][1:-1].split()]\n",
    "    feature_vectors.append(fvec)\n",
    "    feature_vectors_map[i] = fname"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#feature_vectors = scaler.fit_transform(feature_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Images by Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: ['12_02_23_data_08_JP_LD.png', '12_02_23_data_04_LD.png', '12_02_23_data_07_LU.png', '13_02_23_data_00_pi.png']\n",
      "Cluster 2: ['13_02_23_data_00_LU.png', '12_02_23_data_08_JP_pi.png', '12_02_23_data_04_RD.png']\n",
      "Cluster 3: ['12_02_23_data_11_pi.png']\n",
      "Cluster 4: ['12_02_23_data_11_LD.png']\n",
      "Cluster 5: ['12_02_23_data_07_LD.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drevital/.local/lib/python3.8/site-packages/sklearn/cluster/_agglomerative.py:983: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clusters = cluster_images(feature_vectors, similarity, num_clusters)\n",
    "clusters_map = defaultdict(list)\n",
    "\n",
    "for i, cluster in enumerate(clusters):\n",
    "    for j in cluster:\n",
    "        clusters_map[i].append(feature_vectors_map[j])\n",
    "    print(f'Cluster {i+1}: {clusters_map[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarities = [0.8985173650625983, 0.8296019645333045, 0.9272594625657268, 0.8360967426648496, 0.9417109002811195, 0.9021997480008199, 0.968168311484994, 0.8100581965109019, 0.8520442800021367, 0.8426173625200921, 0.9181628904513994, 0.8533018242091781, 0.9177115996433918, 0.969485436911368, 0.8651327513817553, 0.8296239509819362, 0.8400706374473954, 0.8828104774310855, 0.8108765722703809, 0.867970375426955, 0.8283588331795452, 0.8040750559482891, 0.9695689823703428, 0.794064387413589, 0.8632548409088351, 0.9680479669638304, 0.9037332641846758, 0.9046228872809501, 0.8786064176313063, 0.8557380785306958, 0.863823378278388, 0.8447001925475641, 0.821224416888748, 0.8190340136184544, 0.9472562816965735, 0.9147274162229626, 0.9259331304619225, 0.860495047662044, 0.8558728827763509, 0.8830891807821603, 0.8057699519359183, 0.8427360575327614, 0.7867955293572464, 0.8385347872216357, 0.7923104162621976]\n",
    "\n",
    "#min(similarities), max(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_sim = min(similarities)\n",
    "#max_sim = max(similarities)\n",
    "#range = max_sim - min_sim\n",
    "#similarities = [(sim - min_sim) / range for sim in similarities]\n",
    "#similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '12_02_23_data_07_LD.png',\n",
       " 1: '12_02_23_data_08_JP_LD.png',\n",
       " 2: '13_02_23_data_00_LU.png',\n",
       " 3: '12_02_23_data_11_pi.png',\n",
       " 4: '12_02_23_data_04_LD.png',\n",
       " 5: '12_02_23_data_11_LD.png',\n",
       " 6: '12_02_23_data_08_JP_pi.png',\n",
       " 7: '12_02_23_data_07_LU.png',\n",
       " 8: '13_02_23_data_00_pi.png',\n",
       " 9: '12_02_23_data_04_RD.png'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vectors_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1792"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_vectors[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
