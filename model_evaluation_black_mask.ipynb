{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=600,\n",
    "                 img_height=200,\n",
    "                 batch_size=32):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.obstacle_images = []\n",
    "        self.no_obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_obstacles = 0\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen(self.batch_size)\n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self, batch_size):\n",
    "        datagen = ImageDataGenerator()\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen, batch_size=batch_size)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    "\n",
    "    # Special generator to generate the 3 parts of the input image as 3 separate input images\n",
    "    def three_im_generator(self,\n",
    "                           gen,\n",
    "                           dataset,\n",
    "                           target_size,\n",
    "                           comp_target_size,\n",
    "                           batch_size,\n",
    "                           class_mode):\n",
    "\n",
    "        im_gen = gen.flow_from_directory(dataset, \n",
    "                                         target_size=target_size, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         class_mode=class_mode)\n",
    "        self.filenames = im_gen.filenames\n",
    "\n",
    "        while True:\n",
    "            im1_s, im2_s, mask_s = [], [], []\n",
    "            images, labels = im_gen.next()\n",
    "\n",
    "            for im in images:\n",
    "                imarr = np.array(im, dtype='float32')\n",
    "                w = imarr.shape[1]\n",
    "                im1 = imarr[:, :w//3]\n",
    "                im2 = imarr[:, w//3:(w*2)//3] \n",
    "                im3 = imarr[:, (w*2)//3:] \n",
    "                h_mask = im3.shape[0]\n",
    "                w_mask = im3.shape[1]\n",
    "                mask = np.full((h_mask, w_mask, 1), 0, dtype=np.uint8)\n",
    "                im1 /= 255.0\n",
    "                im2 /= 255.0\n",
    "                \n",
    "                im1_s.append(im1)\n",
    "                im2_s.append(im2)\n",
    "                mask_s.append(mask)\n",
    "                \n",
    "            im1_s = np.array(im1_s)\n",
    "            im2_s = np.array(im2_s)\n",
    "            mask_s = np.array(mask_s)\n",
    "            \n",
    "            yield [im1_s, im2_s, mask_s], labels\n",
    "                        \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            comp_target_size=(self.img_height, self.img_height),\n",
    "            batch_size=self.batch_size,\n",
    "            #class_mode='binary'\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            comp_target_size=(self.img_height, self.img_height),\n",
    "            batch_size=self.batch_size,\n",
    "            #class_mode='binary'\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        \n",
    "    # Compute and plot multi-class confusion-matrix with normalization\n",
    "    def plot_cm_normalized(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold)\n",
    "        print(f'cm: {cm}')\n",
    "        # Normalise\n",
    "        cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        sns.heatmap(cmn, annot=True, fmt='.3f')\n",
    "        plt.title(f'Threshold = {threshold}')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show(block=False)  \n",
    "                \n",
    "    def save_false_positives(self, predictions, threshold, save_path):\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'false_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fp_preds = [p[0] for p in preds]\n",
    "        return fp_preds\n",
    "            \n",
    "    def save_true_positives(self, predictions, threshold, save_path):\n",
    "        true_positives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'true_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "\n",
    "    def save_false_negatives(self, predictions, threshold, save_path):\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames[self.num_no_obstacles:])\\\n",
    "                           if predictions[self.num_no_obstacles+i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[self.num_no_obstacles:]) if p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'false_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "        # Return the prediction as a list for histogram plot\n",
    "        fn_preds = [p[0] for p in preds]\n",
    "        return fn_preds\n",
    "            \n",
    "    def save_true_negatives(self, predictions, threshold, save_path):\n",
    "        true_negatives = [fname for i, fname in enumerate(self.filenames[:self.num_no_obstacles])\\\n",
    "                           if predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions[:self.num_no_obstacles]) if p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'true_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            imname = imname.split('_')\n",
    "            imname.insert(2, f'{preds[i][0]:.2f}')\n",
    "            imname = '_'.join(imname)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "    def calc_recall(self, predictions, threshold=0.5):\n",
    "        true_positives = sum([predictions[self.num_no_obstacles+i] >= threshold\\\n",
    "                            for i in range(self.num_obstacles)])\n",
    "        false_negatives = sum([predictions[self.num_no_obstacles+i] < threshold\\\n",
    "                            for i in range(self.num_obstacles)])\n",
    "        \n",
    "        return true_positives / (true_positives + false_negatives)\n",
    "                           \n",
    "    def calc_specifity(self, predictions, threshold=0.5):\n",
    "        true_negatives = sum([predictions[i] <= threshold\\\n",
    "                            for i in range(self.num_no_obstacles)])\n",
    "        false_positives = sum([predictions[i] > threshold\\\n",
    "                            for i in range(self.num_no_obstacles)])\n",
    "        \n",
    "        return true_negatives / (true_negatives + false_positives)\n",
    "        \n",
    "    def calc_accuracy(self, predictions, threshold=0.5):\n",
    "        true_positives = sum([predictions[self.num_no_obstacles+i] >= threshold\\\n",
    "                            for i in range(self.num_obstacles)])\n",
    "        true_negatives = sum([predictions[i] <= threshold\\\n",
    "                            for i in range(self.num_no_obstacles)])\n",
    "        \n",
    "        return (true_positives + true_negatives) / len(predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 1493 images belonging to 2 classes.\n",
      "Found 1493 images belonging to 2 classes.\n",
      "47/47 [==============================] - 16s 329ms/step\n",
      "cm: [[742   4]\n",
      " [  8 739]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Variables --\n",
    "model_path = '/home/drevital/cs_video_processor/models/jan23_d_20_15_bm_1'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/jan23_d_20_15/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'rgb'\n",
    "thresholds = [0.32]\n",
    "batch_size = 32\n",
    "save_base_path = '/home/drevital/obstacles_classification_datasets/model_eval'\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, dataset, batch_size=batch_size)\n",
    "\n",
    "# -- Define Labels\n",
    "labels = np.array([0]*handler.num_no_obstacles\\\n",
    "                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # -- Print confision-matrix\n",
    "    handler.plot_cm_normalized(model_path, labels, predictions, threshold=threshold)\n",
    "\n",
    "    # -- Save Images\n",
    "    #save_name = dataset.split('/')[-2] + '_' + str(threshold)\n",
    "    save_name = model_name + '_' + str(threshold) + '_ref_as_current'\n",
    "    save_path = os.path.join(save_base_path, save_name)\n",
    "    #fn_preds = handler.save_false_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    #fp_preds = handler.save_false_positives(predictions, threshold=threshold, save_path=save_path)\n",
    "    handler.save_true_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "    handler.save_true_positives(predictions, threshold=threshold, save_path=save_path)\n",
    "    #print(f'Recall: {handler.calc_recall(predictions)}')\n",
    "    #print(f'Specifity: {handler.calc_specifity(predictions)}')\n",
    "    #print(f'Accuracy: {handler.calc_accuracy(predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
