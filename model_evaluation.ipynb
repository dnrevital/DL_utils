{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from time import time\n",
    "\n",
    "import os\n",
    "import io\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.318332Z",
     "iopub.status.busy": "2021-07-05T09:05:42.318028Z",
     "iopub.status.idle": "2021-07-05T09:05:44.224186Z",
     "shell.execute_reply": "2021-07-05T09:05:44.223410Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.318300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/home/drevital/cs_video_processor/models/suzuyo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:44.226149Z",
     "iopub.status.busy": "2021-07-05T09:05:44.225579Z",
     "iopub.status.idle": "2021-07-05T09:05:44.231136Z",
     "shell.execute_reply": "2021-07-05T09:05:44.230145Z",
     "shell.execute_reply.started": "2021-07-05T09:05:44.226104Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 200, 200\n",
    "BATCH_SIZE = 32\n",
    "NUM_RAND_IMAGES = 10\n",
    "batch_size = min(BATCH_SIZE, NUM_RAND_IMAGES*2)\n",
    "source_obs_images = []\n",
    "source_no_obs_images = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions for S3 Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(imname):\n",
    "    client = boto3.client('s3')\n",
    "    bucket = 'obstacles-classification'\n",
    "    key = imname\n",
    "    outfile = io.BytesIO()\n",
    "    client.download_fileobj(bucket, key, outfile)\n",
    "    outfile.seek(0)\n",
    "    im = plt.imread(outfile, format='jpg')\n",
    "    return im\n",
    "\n",
    "def preprocess_image(im):\n",
    "    im = im.reshape(im.shape[0], im.shape[1], 1)\n",
    "    arr = keras.preprocessing.image.smart_resize(im,\n",
    "                                                 (IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                 interpolation='bilinear')\n",
    "    arr /= 255.0\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define S3 Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_image_generator(obstacle_image_names, no_obstacle_image_names, batch_size):\n",
    "    s3 = boto3.resource('s3')\n",
    "    inputs = []\n",
    "    outputs = [1]*NUM_RAND_IMAGES + [0]*NUM_RAND_IMAGES\n",
    "    num_images = NUM_RAND_IMAGES*2\n",
    "    \n",
    "    for image_name in tqdm(obstacle_image_names):\n",
    "        im = get_image(image_name)\n",
    "        source_obs_images.append(im)\n",
    "        im = preprocess_image(im)\n",
    "        inputs.append(im)\n",
    "        \n",
    "    for image_name in tqdm(no_obstacle_image_names):\n",
    "        im = get_image(image_name)\n",
    "        source_no_obs_images.append(im)\n",
    "        im = preprocess_image(im)\n",
    "        inputs.append(im)\n",
    "\n",
    "    for i in range(0, num_images, batch_size):\n",
    "        x = np.array(inputs[i:i+batch_size])\n",
    "        y = np.array(outputs[i:i+batch_size])\n",
    "        yield(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to read dataset file names from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_image_names(dataset, num_images):\n",
    "    client = boto3.client('s3')\n",
    "    bucket = 'obstacles-classification'\n",
    "    image_names = []\n",
    "\n",
    "    paginator = client.get_paginator('list_objects')\n",
    "    page_iterator = paginator.paginate(Bucket=bucket, Prefix=dataset)\n",
    "\n",
    "    for page in page_iterator:\n",
    "        for image_name in page['Contents']:\n",
    "            if image_name['Key'].split('.')[-1] == 'jpg':\n",
    "                image_names.append(image_name['Key'])\n",
    "                \n",
    "    image_names = np.array(image_names)\n",
    "    np.random.shuffle(image_names)\n",
    "\n",
    "    return image_names[:num_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:06:04.389604Z",
     "iopub.status.busy": "2021-07-05T09:06:04.389296Z",
     "iopub.status.idle": "2021-07-05T09:06:04.401070Z",
     "shell.execute_reply": "2021-07-05T09:06:04.399973Z",
     "shell.execute_reply.started": "2021-07-05T09:06:04.389529Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('No Obstacles Detected (True Negatives): ', cm[0][0])\n",
    "  print('No Obstacles Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Obstacles Missed (False Negatives): ', cm[1][0])\n",
    "  print('Obstacles Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Obstacles: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch list of files in Evaluation Dataset to serve the S3 file-generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'suzuyo/eval/obstacle'\n",
    "obstacle_image_names = get_dataset_image_names(dataset, NUM_RAND_IMAGES)\n",
    "dataset = 'suzuyo/eval/no_obstacle'\n",
    "no_obstacle_image_names = get_dataset_image_names(dataset, NUM_RAND_IMAGES)\n",
    "num_obstacles = len(obstacle_image_names)\n",
    "num_no_obstacles = len(no_obstacle_image_names)\n",
    "num_images = num_obstacles + num_no_obstacles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model and print metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:06:04.402728Z",
     "iopub.status.busy": "2021-07-05T09:06:04.402381Z",
     "iopub.status.idle": "2021-07-05T09:07:19.520034Z",
     "shell.execute_reply": "2021-07-05T09:07:19.518994Z",
     "shell.execute_reply.started": "2021-07-05T09:06:04.402699Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drevital/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1973: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n",
      "100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n",
      "100%|██████████| 10/10 [00:13<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.6548 - auc: 0.8700 - recall: 0.8000 - specifity: 0.6000\n",
      "loss :  0.6548248529434204\n",
      "auc :  0.8700000047683716\n",
      "recall :  0.800000011920929\n",
      "specifity :  0.6000000238418579\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate_generator(s3_image_generator(obstacle_image_names,\n",
    "                                                      no_obstacle_image_names,\n",
    "                                                      batch_size),\n",
    "                                   verbose=1)\n",
    "\n",
    "for name, value in zip(model.metrics_names, metrics):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with the model and print prediction charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:08:25.296624Z",
     "iopub.status.busy": "2021-07-05T09:08:25.296310Z",
     "iopub.status.idle": "2021-07-05T09:08:25.952343Z",
     "shell.execute_reply": "2021-07-05T09:08:25.951103Z",
     "shell.execute_reply.started": "2021-07-05T09:08:25.296595Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.52s/it]\n",
      "100%|██████████| 10/10 [00:16<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Obstacles Detected (True Negatives):  10\n",
      "No Obstacles Incorrectly Detected (False Positives):  0\n",
      "Obstacles Missed (False Negatives):  2\n",
      "Obstacles Detected (True Positives):  8\n",
      "Total Obstacles:  10\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([1]*(NUM_RAND_IMAGES) + [0]*(NUM_RAND_IMAGES))\n",
    "num_prediction_batches = math.ceil((NUM_RAND_IMAGES*2)/batch_size)\n",
    "\n",
    "predictions = model.predict_generator(s3_image_generator(obstacle_image_names, \n",
    "                                                         no_obstacle_image_names, \n",
    "                                                         batch_size),\n",
    "                                      num_prediction_batches,\n",
    "                                      verbose=1)\n",
    "\n",
    "num_images = 2*NUM_RAND_IMAGES\n",
    "_, axarr = plt.subplots(num_images//2, 1, figsize=(15,15))\n",
    "\n",
    "for i, im in enumerate(source_obs_images[:NUM_RAND_IMAGES]):\n",
    "    axarr[i-1].imshow(im, cmap='gray', vmin=0, vmax=255)\n",
    "    \n",
    "plot_cm(labels, predictions) # Default: threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_obs_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
