{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "import boto3\n",
    "from time import time\n",
    "import os\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.318332Z",
     "iopub.status.busy": "2021-07-05T09:05:42.318028Z",
     "iopub.status.idle": "2021-07-05T09:05:44.224186Z",
     "shell.execute_reply": "2021-07-05T09:05:44.223410Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.318300Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/home/drevital/cs_video_processor/models/suzuyo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:44.226149Z",
     "iopub.status.busy": "2021-07-05T09:05:44.225579Z",
     "iopub.status.idle": "2021-07-05T09:05:44.231136Z",
     "shell.execute_reply": "2021-07-05T09:05:44.230145Z",
     "shell.execute_reply.started": "2021-07-05T09:05:44.226104Z"
    }
   },
   "outputs": [],
   "source": [
    "cloud_dataset = True\n",
    "obstacle_dataset = 'suzuyo/eval_pairs/obstacle'\n",
    "no_obstacle_dataset = 'suzuyo/eval_pairs/no_obstacle'\n",
    "IMG_HEIGHT, IMG_WIDTH = 200, 200\n",
    "BATCH_SIZE = 32\n",
    "rand_images = True\n",
    "NUM_RAND_IMAGES = 10\n",
    "batch_size = min(BATCH_SIZE, NUM_RAND_IMAGES*2)\n",
    "obstacle_pairs = []\n",
    "no_obstacle_pairs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions for S3 Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(imname):\n",
    "    client = boto3.client('s3')\n",
    "    bucket = 'obstacles-classification'\n",
    "    key = imname\n",
    "    outfile = io.BytesIO()\n",
    "    client.download_fileobj(bucket, key, outfile)\n",
    "    outfile.seek(0)\n",
    "    im = plt.imread(outfile, format='jpg')\n",
    "    return im\n",
    "\n",
    "def preprocess_image(im):\n",
    "    w = im.shape[1]\n",
    "    im1 = im[:,:w//2]\n",
    "    im2 = im[:,w//2:]\n",
    "    sub = cv2.subtract(im1, im2)\n",
    "    sub = sub.reshape(sub.shape[0], sub.shape[1], 1)\n",
    "    arr = keras.preprocessing.image.smart_resize(sub,\n",
    "                                                 (IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                 interpolation='bilinear')\n",
    "    arr /= 255.0\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define S3 Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_image_generator(obstacle_image_names,\n",
    "                       no_obstacle_image_names,\n",
    "                       num_obstale_images,\n",
    "                       num_no_obstacle_images,\n",
    "                       batch_size,\n",
    "                       eval=False):\n",
    "    s3 = boto3.resource('s3')\n",
    "    inputs = []\n",
    "    outputs = [1]*num_obstacle_images + [0]*num_no_obstacle_images\n",
    "    num_images = num_obstacle_images + num_no_obstacle_images\n",
    "    \n",
    "    for image_name in tqdm(obstacle_image_names):\n",
    "        im = get_image(image_name)\n",
    "        if eval:\n",
    "            obstacle_pairs.append(im)\n",
    "        im = preprocess_image(im)\n",
    "        inputs.append(im)\n",
    "        \n",
    "    for image_name in tqdm(no_obstacle_image_names):\n",
    "        im = get_image(image_name)\n",
    "        if eval:\n",
    "            no_obstacle_pairs.append(im)\n",
    "        im = preprocess_image(im)\n",
    "        inputs.append(im)\n",
    "\n",
    "    for i in range(0, num_images, batch_size):\n",
    "        x = np.array(inputs[i:i+batch_size])\n",
    "        y = np.array(outputs[i:i+batch_size])\n",
    "        yield(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to read dataset file names from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_image_names(dataset, num_images=None):\n",
    "    client = boto3.client('s3')\n",
    "    bucket = 'obstacles-classification'\n",
    "    image_names = []\n",
    "    actual_num_images = 0\n",
    "\n",
    "    paginator = client.get_paginator('list_objects')\n",
    "    page_iterator = paginator.paginate(Bucket=bucket, Prefix=dataset)\n",
    "\n",
    "    for page in page_iterator:\n",
    "        for image_name in page['Contents']:\n",
    "            if image_name['Key'].split('.')[-1] == 'jpg':\n",
    "                image_names.append(image_name['Key'])\n",
    "                actual_num_images += 1\n",
    "                \n",
    "    actual_image_names = np.array(image_names)\n",
    "    \n",
    "    if num_images:\n",
    "        np.random.shuffle(image_names)\n",
    "        actual_image_names = image_names[:num_images]\n",
    "        actual_num_images = num_images\n",
    "        \n",
    "    return actual_image_names, actual_num_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:06:04.389604Z",
     "iopub.status.busy": "2021-07-05T09:06:04.389296Z",
     "iopub.status.idle": "2021-07-05T09:06:04.401070Z",
     "shell.execute_reply": "2021-07-05T09:06:04.399973Z",
     "shell.execute_reply.started": "2021-07-05T09:06:04.389529Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('No Obstacles Detected (True Negatives): ', cm[0][0])\n",
    "  print('No Obstacles Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Obstacles Missed (False Negatives): ', cm[1][0])\n",
    "  print('Obstacles Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Obstacles: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch list of files in Evaluation Dataset to serve the S3 file-generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = NUM_RAND_IMAGES if rand_images else None\n",
    "obstacle_image_names, num_obstacle_images = get_dataset_image_names(obstacle_dataset,\n",
    "                                                                    num_images)\n",
    "no_obstacle_image_names, num_no_obstacle_images = get_dataset_image_names(no_obstacle_dataset,\n",
    "                                                                          num_images)\n",
    "num_obstacles = len(obstacle_image_names)\n",
    "num_no_obstacles = len(no_obstacle_image_names)\n",
    "num_images = num_obstacles + num_no_obstacles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model and print metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:06:04.402728Z",
     "iopub.status.busy": "2021-07-05T09:06:04.402381Z",
     "iopub.status.idle": "2021-07-05T09:07:19.520034Z",
     "shell.execute_reply": "2021-07-05T09:07:19.518994Z",
     "shell.execute_reply.started": "2021-07-05T09:06:04.402699Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = model.evaluate_generator(s3_image_generator(obstacle_image_names,\n",
    "                                                      no_obstacle_image_names,\n",
    "                                                      num_obstacle_images,\n",
    "                                                      num_no_obstacle_images,\n",
    "                                                      batch_size,\n",
    "                                                      eval=True),\n",
    "                                   verbose=1)\n",
    "\n",
    "for name, value in zip(model.metrics_names, metrics):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with the model and print prediction charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:08:25.296624Z",
     "iopub.status.busy": "2021-07-05T09:08:25.296310Z",
     "iopub.status.idle": "2021-07-05T09:08:25.952343Z",
     "shell.execute_reply": "2021-07-05T09:08:25.951103Z",
     "shell.execute_reply.started": "2021-07-05T09:08:25.296595Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = np.array([1]*(num_obstacle_images) + [0]*(num_no_obstacle_images))\n",
    "num_prediction_batches = math.ceil(num_images/batch_size)\n",
    "\n",
    "predictions = model.predict_generator(s3_image_generator(obstacle_image_names, \n",
    "                                                         no_obstacle_image_names, \n",
    "                                                         num_obstacle_images,\n",
    "                                                         num_no_obstacle_images,\n",
    "                                                         batch_size),\n",
    "                                      num_prediction_batches,\n",
    "                                      verbose=1)\n",
    "\n",
    "plot_cm(labels, predictions) # Default: threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives = [im for i, im in enumerate(obstacle_pairs) if predictions[i] <= 0.5]\n",
    "\n",
    "if false_negatives:\n",
    "    num_images = len(false_negatives)\n",
    "    _, axarr = plt.subplots(num_images, 1, figsize=(1.5*num_images, 1.5*num_images))\n",
    "\n",
    "    for i, im in enumerate(false_negatives):\n",
    "        axarr[i].imshow(im, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(axarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obstacles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = [im for i, im in enumerate(no_obstacle_pairs) if predictions[i+NUM_RAND_IMAGES] > 0.5]\n",
    "\n",
    "if false_positives:\n",
    "    num_images = len(false_positives)\n",
    "    _, axarr = plt.subplots(num_images, 1, figsize=(1.5*num_images, 1.5*num_images))\n",
    "\n",
    "    for i, im in enumerate(false_positives):\n",
    "        axarr[i].imshow(im, cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Optimal Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = [1]*NUM_RAND_IMAGES + [0]*NUM_RAND_IMAGES\n",
    "fpr, tpr, thresholds = roc_curve(true_values, predictions)\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "ix = argmax(gmeans)\n",
    "optimal_threshold = thresholds[ix]\n",
    "print(f'Optimal Threshold: {optimal_threshold}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Optimal Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(labels, predictions, p=optimal_threshold) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
