{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "import boto3\n",
    "from time import time\n",
    "import os\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler(ABC):\n",
    "    def __init__(self,\n",
    "                obstacle_dataset,\n",
    "                no_obstacle_dataset,\n",
    "                img_width=200,\n",
    "                img_height=200,\n",
    "                batch_size=32,\n",
    "                rand_images=True,\n",
    "                num_rand_images=10):\n",
    "        \n",
    "        self.obstacle_dataset = obstacle_dataset\n",
    "        self.no_obstacle_dataset = no_obstacle_dataset\n",
    "        self.dataset = '/'.join(self.obstacle_dataset.split('/')[:-1])\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.obstacle_images = []\n",
    "        self.no_obstacle_images = []\n",
    "        self._update_image_lists = True\n",
    "        self.rand_images = rand_images\n",
    "        \n",
    "        if rand_images:\n",
    "            self.batch_size = min(batch_size, num_rand_images*2)\n",
    "        else:\n",
    "            self.batch_size = batch_size\n",
    "            \n",
    "        if rand_images:\n",
    "            self.num_rand_images = num_rand_images\n",
    "            self.num_obstacles = num_rand_images\n",
    "            self.num_no_obstacles = num_rand_images\n",
    "            self.num_images = num_rand_images*2\n",
    "        else:\n",
    "            # Will be determined while reading all images from dataset\n",
    "            self.num_obstacles = 0\n",
    "            self.num_no_obstacles = 0\n",
    "            self.num_images = 0\n",
    "            \n",
    "        if rand_images:\n",
    "            self.obstacle_image_names = self._get_random_dataset_image_names(self.obstacle_dataset)\n",
    "            self.no_obstacle_image_names = self._get_random_dataset_image_names(self.no_obstacle_dataset)\n",
    "        else:\n",
    "            (self.obstacle_image_names,\n",
    "            self.num_obstacles) = self._get_all_dataset_image_names(self.obstacle_dataset)\n",
    "            (self.no_obstacle_image_names,\n",
    "            self.num_no_obstacles) = self._get_all_dataset_image_names(self.no_obstacle_dataset)\n",
    "            \n",
    "    @abstractmethod\n",
    "    def _get_random_dataset_image_names(self, dataset):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _get_all_dataset_image_names(self, dataset):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _get_image(self, imname):\n",
    "        pass\n",
    "    \n",
    "    def _preprocess_image(self, im):\n",
    "        w = im.shape[1]\n",
    "        im1 = im[:,:w//2]\n",
    "        im2 = im[:,w//2:]\n",
    "        sub = cv2.subtract(im1, im2)\n",
    "        sub = sub.reshape(sub.shape[0], sub.shape[1], 1)\n",
    "        arr = keras.preprocessing.image.smart_resize(sub,\n",
    "                                                     (self.img_height, self.img_width),\n",
    "                                                     interpolation='bilinear')\n",
    "        arr /= 255.0\n",
    "        return arr\n",
    "    \n",
    "    def image_generator(self):\n",
    "        inputs = []\n",
    "        outputs = [0]*self.num_no_obstacles + [1]*self.num_obstacles\n",
    "\n",
    "        for image_name in tqdm(self.no_obstacle_image_names):\n",
    "            im = self._get_image(image_name)\n",
    "            if self._update_image_lists:\n",
    "                self.no_obstacle_images.append(im)\n",
    "            im = self._preprocess_image(im)\n",
    "            inputs.append(im)\n",
    "\n",
    "        for image_name in tqdm(self.obstacle_image_names):\n",
    "            im = self._get_image(image_name)\n",
    "            if self._update_image_lists:\n",
    "                self.obstacle_images.append(im)\n",
    "            im = self._preprocess_image(im)\n",
    "            inputs.append(im)\n",
    "            \n",
    "        self._update_image_lists = False\n",
    "\n",
    "        for i in range(0, self.num_images, self.batch_size):\n",
    "            x = np.array(inputs[i:i+self.batch_size])\n",
    "            y = np.array(outputs[i:i+self.batch_size])\n",
    "            yield(x, y)\n",
    "            \n",
    "    @abstractmethod\n",
    "    def get_metrics(self, model):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_predictions(self, model):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudDatasetHandler(DatasetHandler):\n",
    "    \n",
    "    def _get_random_dataset_image_names(self, dataset):\n",
    "        client = boto3.client('s3')\n",
    "        bucket = 'obstacles-classification'\n",
    "        image_names = []\n",
    "\n",
    "        paginator = client.get_paginator('list_objects')\n",
    "        page_iterator = paginator.paginate(Bucket=bucket, Prefix=dataset)\n",
    "\n",
    "        for page in page_iterator:\n",
    "            for image_name in page['Contents']:\n",
    "                if image_name['Key'].split('.')[-1] == 'jpg':\n",
    "                    image_names.append(image_name['Key'])\n",
    "\n",
    "        image_names = np.array(image_names)\n",
    "        np.random.shuffle(image_names)\n",
    "        image_names = image_names[:self.num_rand_images]\n",
    "\n",
    "        return list(image_names)\n",
    "\n",
    "    def _get_all_dataset_image_names(self, dataset):\n",
    "        client = boto3.client('s3')\n",
    "        bucket = 'obstacles-classification'\n",
    "        image_names = []\n",
    "        num_images = 0\n",
    "\n",
    "        paginator = client.get_paginator('list_objects')\n",
    "        page_iterator = paginator.paginate(Bucket=bucket, Prefix=dataset)\n",
    "\n",
    "        for page in page_iterator:\n",
    "            for image_name in page['Contents']:\n",
    "                if image_name['Key'].split('.')[-1] == 'jpg':\n",
    "                    image_names.append(image_name['Key'])\n",
    "                    num_images += 1\n",
    "\n",
    "        return image_names, num_images\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        client = boto3.client('s3')\n",
    "        bucket = 'obstacles-classification'\n",
    "        key = imname\n",
    "        outfile = io.BytesIO()\n",
    "        client.download_fileobj(bucket, key, outfile)\n",
    "        outfile.seek(0)\n",
    "        im = plt.imread(outfile, format='jpg')\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_metrics(self, model):\n",
    "        return model.evaluate_generator(self.image_generator(), verbose=1)\n",
    "    \n",
    "    def get_predictions(self,model):\n",
    "        return model.predict_generator(self.image_generator(), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalDatasetHandler(DatasetHandler):\n",
    "        \n",
    "    def _get_random_dataset_image_names(self, dataset):\n",
    "        image_names = os.listdir(dataset)\n",
    "        image_paths = [os.path.join(dataset, image_name) for image_name in image_names]\n",
    "        image_paths = np.array(image_paths)\n",
    "        np.random.shuffle(image_paths)\n",
    "        image_paths = image_paths[:self.num_rand_images]\n",
    "\n",
    "        return list(image_paths)\n",
    "\n",
    "    def _get_all_dataset_image_names(self, dataset):\n",
    "        image_names = os.listdir(dataset)\n",
    "        image_paths = [os.path.join(dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_metrics(self, model):\n",
    "        if self.rand_images:\n",
    "            return model.evaluate_generator(self.image_generator(), verbose=1)\n",
    "        else:\n",
    "            datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "            val_generator = datagen.flow_from_directory(\n",
    "                self.dataset,\n",
    "                target_size=(self.img_width, self.img_height),\n",
    "                color_mode='grayscale',\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=False,\n",
    "                class_mode='binary'\n",
    "            )\n",
    "            \n",
    "            return model.evaluate_generator(val_generator, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model):\n",
    "        if self.rand_images:\n",
    "            return model.predict_generator(self.image_generator(), verbose=1)\n",
    "        else:\n",
    "            datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "            val_generator = datagen.flow_from_directory(\n",
    "                self.dataset,\n",
    "                target_size=(self.img_width, self.img_height),\n",
    "                color_mode='grayscale',\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=False,\n",
    "                class_mode='binary'\n",
    "            )\n",
    "            \n",
    "            return model.predict_generator(val_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:06:04.389604Z",
     "iopub.status.busy": "2021-07-05T09:06:04.389296Z",
     "iopub.status.idle": "2021-07-05T09:06:04.401070Z",
     "shell.execute_reply": "2021-07-05T09:06:04.399973Z",
     "shell.execute_reply.started": "2021-07-05T09:06:04.389529Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('No Obstacles Detected (True Negatives): ', cm[0][0])\n",
    "  print('No Obstacles Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Obstacles Missed (False Negatives): ', cm[1][0])\n",
    "  print('Obstacles Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Obstacles: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these variables per actual environment\n",
    "model_path = '/home/drevital/cs_video_processor/models/suzuyo'\n",
    "cloud_dataset = False\n",
    "obstacle_dataset = '/home/drevital/obstacles_classification_datasets/suzuyo/eval/obstacle'\n",
    "#obstacle_dataset = 'suzuyo/eval_pairs/obstacle'\n",
    "no_obstacle_dataset = '/home/drevital/obstacles_classification_datasets/suzuyo/eval/no_obstacle'\n",
    "#no_obstacle_dataset = 'suzuyo/eval_pairs/no_obstacle'\n",
    "rand_images = False\n",
    "num_rand_images = 10\n",
    "display_negatives = False\n",
    "\n",
    "#\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "dataset_handlers = [LocalDatasetHandler, CloudDatasetHandler]\n",
    "handler = dataset_handlers[cloud_dataset](obstacle_dataset,\n",
    "                                         no_obstacle_dataset,\n",
    "                                         rand_images=rand_images,\n",
    "                                         num_rand_images=num_rand_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:06:04.402728Z",
     "iopub.status.busy": "2021-07-05T09:06:04.402381Z",
     "iopub.status.idle": "2021-07-05T09:07:19.520034Z",
     "shell.execute_reply": "2021-07-05T09:07:19.518994Z",
     "shell.execute_reply.started": "2021-07-05T09:06:04.402699Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = handler.get_metrics(model)\n",
    "\n",
    "for name, value in zip(model.metrics_names, metrics):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with the model and print prediction charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:08:25.296624Z",
     "iopub.status.busy": "2021-07-05T09:08:25.296310Z",
     "iopub.status.idle": "2021-07-05T09:08:25.952343Z",
     "shell.execute_reply": "2021-07-05T09:08:25.951103Z",
     "shell.execute_reply.started": "2021-07-05T09:08:25.296595Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = np.array([0]*(handler.num_no_obstacles) + [1]*(handler.num_obstacles))\n",
    "predictions = handler.get_predictions(model)\n",
    "plot_cm(labels, predictions) # Default: threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if display_negatives:\n",
    "    false_negatives = [im for i, im in enumerate(handler.obstacle_images) if predictions[i] <= 0.5]\n",
    "\n",
    "    if 500 > len(false_negatives) > 1:\n",
    "        num_images = len(false_negatives)\n",
    "        _, axarr = plt.subplots(num_images, 1, figsize=(1.5*num_images, 1.5*num_images))\n",
    "\n",
    "        for i, im in enumerate(false_negatives):\n",
    "            axarr[i].imshow(im, cmap='gray', vmin=0, vmax=255)\n",
    "    elif false_negatives:\n",
    "        plt.imshow(false_negatives[0], cmap='gray', vmin=0, vmax=255)\n",
    "        plt.show()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if display_negatives:\n",
    "    false_positives = [im for i, im in enumerate(handler.no_obstacle_images) if predictions[i+handler.num_obstacles] > 0.5]\n",
    "\n",
    "    if 500 > len(false_positives) > 1:\n",
    "        num_images = len(false_positives)\n",
    "        _, axarr = plt.subplots(num_images, 1, figsize=(1.5*num_images, 1.5*num_images))\n",
    "\n",
    "        for i, im in enumerate(false_positives):\n",
    "            axarr[i].imshow(im, cmap='gray', vmin=0, vmax=255)\n",
    "    elif false_positives:\n",
    "        plt.imshow(false_positives[0], cmap='gray', vmin=0, vmax=255)\n",
    "        plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Optimal Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = [0]*handler.num_no_obstacles + [1]*handler.num_obstacles \n",
    "fpr, tpr, thresholds = roc_curve(true_values, predictions)\n",
    "gmeans = sqrt(tpr * (1-fpr))\n",
    "ix = argmax(gmeans)\n",
    "optimal_threshold = thresholds[ix]\n",
    "print(f'Optimal Threshold: {optimal_threshold}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Optimal Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(labels, predictions, p=optimal_threshold) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
