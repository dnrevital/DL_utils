{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from time import time\n",
    "\n",
    "import os\n",
    "import io\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.318332Z",
     "iopub.status.busy": "2021-07-05T09:05:42.318028Z",
     "iopub.status.idle": "2021-07-05T09:05:44.224186Z",
     "shell.execute_reply": "2021-07-05T09:05:44.223410Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.318300Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/home/drevital/cs_video_processor/models/suzuyo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:44.226149Z",
     "iopub.status.busy": "2021-07-05T09:05:44.225579Z",
     "iopub.status.idle": "2021-07-05T09:05:44.231136Z",
     "shell.execute_reply": "2021-07-05T09:05:44.230145Z",
     "shell.execute_reply.started": "2021-07-05T09:05:44.226104Z"
    }
   },
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 200, 200\n",
    "BATCH_SIZE = 32\n",
    "NUM_RAND_IMAGES = 10\n",
    "batch_size = min(BATCH_SIZE, NUM_RAND_IMAGES*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions for S3 Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(imname):\n",
    "    client = boto3.client('s3')\n",
    "    bucket = 'obstacles-classification'\n",
    "    key = imname\n",
    "    outfile = io.BytesIO()\n",
    "    client.download_fileobj(bucket, key, outfile)\n",
    "    outfile.seek(0)\n",
    "    im = plt.imread(outfile, format='jpg')\n",
    "    return im\n",
    "\n",
    "def preprocess_image(im):\n",
    "    im = im.reshape(im.shape[0], im.shape[1], 1)\n",
    "    arr = keras.preprocessing.image.smart_resize(im,\n",
    "                                                 (IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                 interpolation='bilinear')\n",
    "    arr /= 255.0\n",
    "    return arr\n",
    "\n",
    "def preprocess_image_1(img):\n",
    "    image = img.resize((200, 200))\n",
    "    array = img_to_array(img)\n",
    "    return(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define S3 Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_image_generator(obstacle_image_names, no_obstacle_image_names, batch_size):\n",
    "    s3 = boto3.resource('s3')\n",
    "    batch_input = []\n",
    "    batch_output = [1]*NUM_RAND_IMAGES + [0]*NUM_RAND_IMAGES\n",
    "    num_images = NUM_RAND_IMAGES*2\n",
    "    \n",
    "    batch_paths = np.array(obstacle_image_names)\n",
    "    np.random.shuffle(batch_paths)\n",
    "    \n",
    "    for input_path in tqdm(batch_paths[:NUM_RAND_IMAGES]):\n",
    "        im = get_image(input_path)\n",
    "        im = preprocess_image(im)\n",
    "        batch_input += [im]\n",
    "\n",
    "    batch_paths = np.array(no_obstacle_image_names)\n",
    "    np.random.shuffle(batch_paths)\n",
    "\n",
    "    for input_path in tqdm(batch_paths[:NUM_RAND_IMAGES]):\n",
    "        im = get_image(input_path)\n",
    "        im = preprocess_image(im)\n",
    "        batch_input += [im]\n",
    "\n",
    "    for i in range(0, num_images, batch_size):\n",
    "        x = np.array(batch_input[i:i+batch_size])\n",
    "        y = np.array(batch_output[i:i+batch_size])\n",
    "        yield(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to read dataset file names from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_image_names(dataset):\n",
    "    client = boto3.client('s3')\n",
    "    bucket = 'obstacles-classification'\n",
    "    image_names = []\n",
    "\n",
    "    paginator = client.get_paginator('list_objects')\n",
    "    page_iterator = paginator.paginate(Bucket=bucket, Prefix=dataset)\n",
    "\n",
    "    for page in page_iterator:\n",
    "        for image_name in page['Contents']:\n",
    "            if image_name['Key'].split('.')[-1] == 'jpg':\n",
    "                image_names.append(image_name['Key'])\n",
    "                \n",
    "    return image_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:06:04.389604Z",
     "iopub.status.busy": "2021-07-05T09:06:04.389296Z",
     "iopub.status.idle": "2021-07-05T09:06:04.401070Z",
     "shell.execute_reply": "2021-07-05T09:06:04.399973Z",
     "shell.execute_reply.started": "2021-07-05T09:06:04.389529Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('No Obstacles Detected (True Negatives): ', cm[0][0])\n",
    "  print('No Obstacles Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('Obstacles Missed (False Negatives): ', cm[1][0])\n",
    "  print('Obstacles Detected (True Positives): ', cm[1][1])\n",
    "  print('Total Obstacles: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch list of files in Evaluation Dataset to serve the S3 file-generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'suzuyo/eval/obstacle'\n",
    "obstacle_image_names = get_dataset_image_names(dataset)\n",
    "dataset = 'suzuyo/eval/no_obstacle'\n",
    "no_obstacle_image_names = get_dataset_image_names(dataset)\n",
    "num_obstacles = len(obstacle_image_names)\n",
    "num_no_obstacles = len(no_obstacle_image_names)\n",
    "num_images = num_obstacles + num_no_obstacles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model and print metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:06:04.402728Z",
     "iopub.status.busy": "2021-07-05T09:06:04.402381Z",
     "iopub.status.idle": "2021-07-05T09:07:19.520034Z",
     "shell.execute_reply": "2021-07-05T09:07:19.518994Z",
     "shell.execute_reply.started": "2021-07-05T09:06:04.402699Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = model.evaluate_generator(s3_image_generator(obstacle_image_names,\n",
    "                                                      no_obstacle_image_names,\n",
    "                                                      batch_size),\n",
    "                                   verbose=1)\n",
    "\n",
    "for name, value in zip(model.metrics_names, metrics):\n",
    "  print(name, ': ', value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with the model and print prediction charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T09:08:25.296624Z",
     "iopub.status.busy": "2021-07-05T09:08:25.296310Z",
     "iopub.status.idle": "2021-07-05T09:08:25.952343Z",
     "shell.execute_reply": "2021-07-05T09:08:25.951103Z",
     "shell.execute_reply.started": "2021-07-05T09:08:25.296595Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = np.array([1]*(NUM_RAND_IMAGES) + [0]*(NUM_RAND_IMAGES))\n",
    "num_prediction_batches = math.ceil((NUM_RAND_IMAGES*2)/batch_size)\n",
    "\n",
    "predictions = model.predict_generator(s3_image_generator(obstacle_image_names, \n",
    "                                                         no_obstacle_image_names, \n",
    "                                                         batch_size),\n",
    "                                      num_prediction_batches,\n",
    "                                      verbose=1)\n",
    "\n",
    "plot_cm(labels, predictions) # Default: threshold = 0.5\n",
    "plot_cm(labels, predictions, p=0.25)\n",
    "plot_cm(labels, predictions, p=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
