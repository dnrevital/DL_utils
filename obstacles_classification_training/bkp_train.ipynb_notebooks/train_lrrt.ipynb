{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "train_dataset_name = '7sw_1_5__1'\n",
    "eval_dataset_name = '7sw_1_5__1'\n",
    "dataset_hyphened_name = train_dataset_name.replace('_', '-') + '-' + f'{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())}'\n",
    "layers = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client & SM sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm   = sess.client('sagemaker')\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "\n",
    "training_experiment = Experiment.create(experiment_name = f'{dataset_hyphened_name}', \n",
    "                                        description     = f'{dataset_hyphened_name}', \n",
    "                                        sagemaker_boto_client=sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_trial = Trial.create(trial_name = f'{dataset_hyphened_name}', \n",
    "                              experiment_name = training_experiment.experiment_name,\n",
    "                              sagemaker_boto_client = sm,)\n",
    "training_trial_comp_name = f'{dataset_hyphened_name}'\n",
    "experiment_config = {\"ExperimentName\": training_experiment.experiment_name, \n",
    "                       \"TrialName\": training_trial.trial_name,\n",
    "                       \"TrialComponentDisplayName\": training_trial_comp_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training job & visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: obstacles-classification-2022-01-11-13-12-43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-11 13:12:43 Starting - Starting the training job...\n",
      "2022-01-11 13:13:08 Starting - Launching requested ML instancesProfilerReport-1641906763: InProgress\n",
      "......\n",
      "2022-01-11 13:14:10 Starting - Preparing the instances for training......\n",
      "2022-01-11 13:15:10 Downloading - Downloading input data......\n",
      "2022-01-11 13:16:11 Training - Downloading the training image..\u001b[34m2022-01-11 13:16:17.978064: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-01-11 13:16:17.986066: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2022-01-11 13:16:18.281651: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-01-11 13:16:21,627 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2022-01-11 13:16:21,634 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-11 13:16:22,048 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-11 13:16:22,063 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-11 13:16:22,078 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-01-11 13:16:22,088 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 16,\n",
      "        \"dataframe_dir\": \"s3://obstacles-classification/7sw_1_5__1\",\n",
      "        \"optimizer\": \"adam\",\n",
      "        \"model_dir\": \"s3://sagemaker-eu-west-1-947805154784/obstacles_classification/jobs/7sw_1_5__1/obstacles-classification-2022-01-11-13-12-43/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"obstacles-classification-2022-01-11-13-12-43\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-947805154784/obstacles_classification/jobs/7sw_1_5__1/obstacles-classification-2022-01-11-13-12-43/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"7_channels_weights_lrrt\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"7_channels_weights_lrrt.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":16,\"dataframe_dir\":\"s3://obstacles-classification/7sw_1_5__1\",\"model_dir\":\"s3://sagemaker-eu-west-1-947805154784/obstacles_classification/jobs/7sw_1_5__1/obstacles-classification-2022-01-11-13-12-43/model\",\"optimizer\":\"adam\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=7_channels_weights_lrrt.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=7_channels_weights_lrrt\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-1-947805154784/obstacles_classification/jobs/7sw_1_5__1/obstacles-classification-2022-01-11-13-12-43/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":16,\"dataframe_dir\":\"s3://obstacles-classification/7sw_1_5__1\",\"model_dir\":\"s3://sagemaker-eu-west-1-947805154784/obstacles_classification/jobs/7sw_1_5__1/obstacles-classification-2022-01-11-13-12-43/model\",\"optimizer\":\"adam\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"obstacles-classification-2022-01-11-13-12-43\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-947805154784/obstacles_classification/jobs/7sw_1_5__1/obstacles-classification-2022-01-11-13-12-43/source/sourcedir.tar.gz\",\"module_name\":\"7_channels_weights_lrrt\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"7_channels_weights_lrrt.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"16\",\"--dataframe_dir\",\"s3://obstacles-classification/7sw_1_5__1\",\"--model_dir\",\"s3://sagemaker-eu-west-1-947805154784/obstacles_classification/jobs/7sw_1_5__1/obstacles-classification-2022-01-11-13-12-43/model\",\"--optimizer\",\"adam\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_DATAFRAME_DIR=s3://obstacles-classification/7sw_1_5__1\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=adam\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-eu-west-1-947805154784/obstacles_classification/jobs/7sw_1_5__1/obstacles-classification-2022-01-11-13-12-43/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 7_channels_weights_lrrt.py --batch-size 16 --dataframe_dir s3://obstacles-classification/7sw_1_5__1 --model_dir s3://sagemaker-eu-west-1-947805154784/obstacles_classification/jobs/7sw_1_5__1/obstacles-classification-2022-01-11-13-12-43/model --optimizer adam\u001b[0m\n",
      "\u001b[34m[2022-01-11 13:16:24.144 ip-10-0-147-190.eu-west-1.compute.internal:28 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-01-11 13:16:24.375 ip-10-0-147-190.eu-west-1.compute.internal:28 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34mModel: \"functional_1\"\u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                    Output Shape         Param #     Connected to                     \u001b[0m\n",
      "\u001b[34m==================================================================================================\u001b[0m\n",
      "\u001b[34minput_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34minput_2 (InputLayer)            [(None, 200, 200, 3) 0                                            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34minput_3 (InputLayer)            [(None, 200, 200, 1) 0                                            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcatenate (Concatenate)       (None, 200, 200, 7)  0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d (Conv2D)                 (None, 200, 200, 16) 1024        concatenate[0][0]                \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization (BatchNorma (None, 200, 200, 16) 64          conv2d[0][0]                     \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d (MaxPooling2D)    (None, 100, 100, 16) 0           batch_normalization[0][0]        \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_1 (Conv2D)               (None, 100, 100, 32) 12832       max_pooling2d[0][0]              \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_1 (BatchNor (None, 100, 100, 32) 128         conv2d_1[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d_1 (MaxPooling2D)  (None, 50, 50, 32)   0           batch_normalization_1[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_2 (Conv2D)               (None, 50, 50, 64)   51264       max_pooling2d_1[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_2 (BatchNor (None, 50, 50, 64)   256         conv2d_2[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 64)   0           batch_normalization_2[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_3 (Conv2D)               (None, 25, 25, 128)  204928      max_pooling2d_2[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_3 (BatchNor (None, 25, 25, 128)  512         conv2d_3[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d_3 (MaxPooling2D)  (None, 13, 13, 128)  0           batch_normalization_3[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_4 (Conv2D)               (None, 13, 13, 256)  819456      max_pooling2d_3[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbatch_normalization_4 (BatchNor (None, 13, 13, 256)  1024        conv2d_4[0][0]                   \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmax_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 256)    0           batch_normalization_4[0][0]      \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mflatten (Flatten)               (None, 4096)         0           max_pooling2d_4[0][0]            \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout (Dropout)               (None, 4096)         0           flatten[0][0]                    \u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense (Dense)                   (None, 1)            4097        dropout[0][0]                    \u001b[0m\n",
      "\u001b[34m==================================================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 1,095,585\u001b[0m\n",
      "\u001b[34mTrainable params: 1,094,593\u001b[0m\n",
      "\u001b[34mNon-trainable params: 992\u001b[0m\n",
      "\u001b[34m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mFound 10468 validated image filenames belonging to 2 classes.\u001b[0m\n",
      "\n",
      "2022-01-11 13:16:31 Training - Training image download completed. Training in progress.\u001b[34mlr: 10.00000000\u001b[0m\n",
      "\u001b[34m655/655 - 303s - loss: 327108.6250 - auc: 0.6641 - recall: 0.7763 - specifity: 0.1064\u001b[0m\n",
      "\u001b[34mlr_value:1e-05           loss:161.6746826171875\u001b[0m\n",
      "\u001b[34mlr_value:1.021349338436818e-05           loss:161.84811401367188\u001b[0m\n",
      "\u001b[34mlr_value:1.043154471125328e-05           loss:161.9581298828125\u001b[0m\n",
      "\u001b[34mlr_value:1.0654251289712624e-05           loss:161.9402313232422\u001b[0m\n",
      "\u001b[34mlr_value:1.0881712506287604e-05           loss:161.94032287597656\u001b[0m\n",
      "\u001b[34mlr_value:1.1114029869356516e-05           loss:161.99461364746094\u001b[0m\n",
      "\u001b[34mlr_value:1.1351307054434312e-05           loss:161.92520141601562\u001b[0m\n",
      "\u001b[34mlr_value:1.1593649950439669e-05           loss:161.9598846435547\u001b[0m\n",
      "\u001b[34mlr_value:1.1841166706949603e-05           loss:161.96072387695312\u001b[0m\n",
      "\u001b[34mlr_value:1.2093967782463078e-05           loss:161.89186096191406\u001b[0m\n",
      "\u001b[34mlr_value:1.2352165993694855e-05           loss:161.83709716796875\u001b[0m\n",
      "\u001b[34mlr_value:1.2615876565922e-05           loss:161.81192016601562\u001b[0m\n",
      "\u001b[34mlr_value:1.2885217184405017e-05           loss:161.77418518066406\u001b[0m\n",
      "\u001b[34mlr_value:1.3160308046906782e-05           loss:161.75283813476562\u001b[0m\n",
      "\u001b[34mlr_value:1.3441271917332974e-05           loss:161.73846435546875\u001b[0m\n",
      "\u001b[34mlr_value:1.3728234180517442e-05           loss:161.70187377929688\u001b[0m\n",
      "\u001b[34mlr_value:1.40213228981772e-05           loss:161.67701721191406\u001b[0m\n",
      "\u001b[34mlr_value:1.4320668866062292e-05           loss:161.665283203125\u001b[0m\n",
      "\u001b[34mlr_value:1.4626405672325488e-05           loss:161.6324462890625\u001b[0m\n",
      "\u001b[34mlr_value:1.4938669757138159e-05           loss:161.63076782226562\u001b[0m\n",
      "\u001b[34mlr_value:1.525760047357916e-05           loss:161.60650634765625\u001b[0m\n",
      "\u001b[34mlr_value:1.5583340149823387e-05           loss:161.57833862304688\u001b[0m\n",
      "\u001b[34mlr_value:1.5916034152658022e-05           loss:161.55624389648438\u001b[0m\n",
      "\u001b[34mlr_value:1.625583095235507e-05           loss:161.5014190673828\u001b[0m\n",
      "\u001b[34mlr_value:1.6602882188928633e-05           loss:161.4852752685547\u001b[0m\n",
      "\u001b[34mlr_value:1.695734273980669e-05           loss:161.448974609375\u001b[0m\n",
      "\u001b[34mlr_value:1.731937078894794e-05           loss:161.42666625976562\u001b[0m\n",
      "\u001b[34mlr_value:1.768912789743393e-05           loss:161.4096221923828\u001b[0m\n",
      "\u001b[34mlr_value:1.806677907556844e-05           loss:161.39309692382812\u001b[0m\n",
      "\u001b[34mlr_value:1.8452492856515974e-05           loss:161.3579559326172\u001b[0m\n",
      "\u001b[34mlr_value:1.88464413715127e-05           loss:161.31539916992188\u001b[0m\n",
      "\u001b[34mlr_value:1.9248800426682813e-05           loss:161.28939819335938\u001b[0m\n",
      "\u001b[34mlr_value:1.9659749581494832e-05           loss:161.2534637451172\u001b[0m\n",
      "\u001b[34mlr_value:2.0079472228893256e-05           loss:161.22695922851562\u001b[0m\n",
      "\u001b[34mlr_value:2.0508155677140627e-05           loss:161.20510864257812\u001b[0m\n",
      "\u001b[34mlr_value:2.094599123340685e-05           loss:161.1643829345703\u001b[0m\n",
      "\u001b[34mlr_value:2.1393174289143478e-05           loss:161.14669799804688\u001b[0m\n",
      "\u001b[34mlr_value:2.184990440728028e-05           loss:161.1130828857422\u001b[0m\n",
      "\u001b[34mlr_value:2.2316385411283428e-05           loss:161.08399963378906\u001b[0m\n",
      "\u001b[34mlr_value:2.2792825476115385e-05           loss:161.03807067871094\u001b[0m\n",
      "\u001b[34mlr_value:2.3279437221136298e-05           loss:161.00071716308594\u001b[0m\n",
      "\u001b[34mlr_value:2.3776437804989043e-05           loss:160.96853637695312\u001b[0m\n",
      "\u001b[34mlr_value:2.4284049022509708e-05           loss:160.92698669433594\u001b[0m\n",
      "\u001b[34mlr_value:2.4802497403707548e-05           loss:160.90208435058594\u001b[0m\n",
      "\u001b[34mlr_value:2.5332014314857653e-05           loss:160.84815979003906\u001b[0m\n",
      "\u001b[34mlr_value:2.5872836061751866e-05           loss:160.80223083496094\u001b[0m\n",
      "\u001b[34mlr_value:2.6425203995154514e-05           loss:160.7607421875\u001b[0m\n",
      "\u001b[34mlr_value:2.698936461850908e-05           loss:160.7164764404297\u001b[0m\n",
      "\u001b[34mlr_value:2.756556969794431e-05           loss:160.6719970703125\u001b[0m\n",
      "\u001b[34mlr_value:2.8154076374629418e-05           loss:160.62876892089844\u001b[0m\n",
      "\u001b[34mlr_value:2.8755147279527463e-05           loss:160.576416015625\u001b[0m\n",
      "\u001b[34mlr_value:2.936905065059864e-05           loss:160.53256225585938\u001b[0m\n",
      "\u001b[34mlr_value:2.999606045250632e-05           loss:160.4842529296875\u001b[0m\n",
      "\u001b[34mlr_value:3.063645649887819e-05           loss:160.44354248046875\u001b[0m\n",
      "\u001b[34mlr_value:3.1290524577177595e-05           loss:160.40614318847656\u001b[0m\n",
      "\u001b[34mlr_value:3.195855657624133e-05           loss:160.3558807373047\u001b[0m\n",
      "\u001b[34mlr_value:3.264085061653977e-05           loss:160.30052185058594\u001b[0m\n",
      "\u001b[34mlr_value:3.3337711183217896e-05           loss:160.25205993652344\u001b[0m\n",
      "\u001b[34mlr_value:3.40494492619773e-05           loss:160.2029571533203\u001b[0m\n",
      "\u001b[34mlr_value:3.477638247785852e-05           loss:160.14723205566406\u001b[0m\n",
      "\u001b[34mlr_value:3.5518835236986624e-05           loss:160.09646606445312\u001b[0m\n",
      "\u001b[34mlr_value:3.6277138871342626e-05           loss:160.04505920410156\u001b[0m\n",
      "\u001b[34mlr_value:3.705163178662637e-05           loss:159.99058532714844\u001b[0m\n",
      "\u001b[34mlr_value:3.784265961327549e-05           loss:159.9366912841797\u001b[0m\n",
      "\u001b[34mlr_value:3.865057536070862e-05           loss:159.88079833984375\u001b[0m\n",
      "\u001b[34mlr_value:3.9475739574862124e-05           loss:159.83139038085938\u001b[0m\n",
      "\u001b[34mlr_value:4.0318520499089626e-05           loss:159.77667236328125\u001b[0m\n",
      "\u001b[34mlr_value:4.1179294238496476e-05           loss:159.7261199951172\u001b[0m\n",
      "\u001b[34mlr_value:4.205844492778344e-05           loss:159.66416931152344\u001b[0m\n",
      "\u001b[34mlr_value:4.295636490267305e-05           loss:159.61021423339844\u001b[0m\n",
      "\u001b[34mlr_value:4.387345487499567e-05           loss:159.5546112060547\u001b[0m\n",
      "\u001b[34mlr_value:4.4810124111514414e-05           loss:159.49600219726562\u001b[0m\n",
      "\u001b[34mlr_value:4.5766790616566954e-05           loss:159.43133544921875\u001b[0m\n",
      "\u001b[34mlr_value:4.674388131860712e-05           loss:159.3668670654297\u001b[0m\n",
      "\u001b[34mlr_value:4.774183226072852e-05           loss:159.3047332763672\u001b[0m\n",
      "\u001b[34mlr_value:4.876108879525671e-05           loss:159.24200439453125\u001b[0m\n",
      "\u001b[34mlr_value:4.980210578249438e-05           loss:159.17552185058594\u001b[0m\n",
      "\u001b[34mlr_value:5.086534779371106e-05           loss:159.1100616455078\u001b[0m\n",
      "\u001b[34mlr_value:5.195128931846545e-05           loss:159.04779052734375\u001b[0m\n",
      "\u001b[34mlr_value:5.3060414976354525e-05           loss:158.97377014160156\u001b[0m\n",
      "\u001b[34mlr_value:5.4193219733282724e-05           loss:158.897216796875\u001b[0m\n",
      "\u001b[34mlr_value:5.535020912234942e-05           loss:158.82632446289062\u001b[0m\n",
      "\u001b[34mlr_value:5.653189946945122e-05           loss:158.7529754638672\u001b[0m\n",
      "\u001b[34mlr_value:5.773881812370071e-05           loss:158.67845153808594\u001b[0m\n",
      "\u001b[34mlr_value:5.897150369276548e-05           loss:158.6039581298828\u001b[0m\n",
      "\u001b[34mlr_value:6.023050628323039e-05           loss:158.52462768554688\u001b[0m\n",
      "\u001b[34mlr_value:6.15163877460921e-05           loss:158.44273376464844\u001b[0m\n",
      "\u001b[34mlr_value:6.282972192749393e-05           loss:158.36672973632812\u001b[0m\n",
      "\u001b[34mlr_value:6.41710949248153e-05           loss:158.28915405273438\u001b[0m\n",
      "\u001b[34mlr_value:6.554110534822636e-05           loss:158.2101287841797\u001b[0m\n",
      "\u001b[34mlr_value:6.694036458782878e-05           loss:158.13446044921875\u001b[0m\n",
      "\u001b[34mlr_value:6.836949708649833e-05           loss:158.0503387451172\u001b[0m\n",
      "\u001b[34mlr_value:6.982914061855316e-05           loss:157.96229553222656\u001b[0m\n",
      "\u001b[34mlr_value:7.13199465743708e-05           loss:157.87713623046875\u001b[0m\n",
      "\u001b[34mlr_value:7.284258025108282e-05           loss:157.78753662109375\u001b[0m\n",
      "\u001b[34mlr_value:7.439772114947442e-05           loss:157.70172119140625\u001b[0m\n",
      "\u001b[34mlr_value:7.598606327722256e-05           loss:157.61770629882812\u001b[0m\n",
      "\u001b[34mlr_value:7.760831545860945e-05           loss:157.53384399414062\u001b[0m\n",
      "\u001b[34mlr_value:7.92652016508468e-05           loss:157.45144653320312\u001b[0m\n",
      "\u001b[34mlr_value:8.095746126715336e-05           loss:157.35694885253906\u001b[0m\n",
      "\u001b[34mlr_value:8.26858495067314e-05           loss:157.2617950439453\u001b[0m\n",
      "\u001b[34mlr_value:8.445113769178657e-05           loss:157.16116333007812\u001b[0m\n",
      "\u001b[34mlr_value:8.625411361174285e-05           loss:157.05990600585938\u001b[0m\n",
      "\u001b[34mlr_value:8.809558187480768e-05           loss:156.95928955078125\u001b[0m\n",
      "\u001b[34mlr_value:8.997636426704137e-05           loss:156.86004638671875\u001b[0m\n",
      "\u001b[34mlr_value:9.189730011909303e-05           loss:156.7618408203125\u001b[0m\n",
      "\u001b[34mlr_value:9.385924668076538e-05           loss:156.6564483642578\u001b[0m\n",
      "\u001b[34mlr_value:9.586307950357804e-05           loss:156.55792236328125\u001b[0m\n",
      "\u001b[34mlr_value:9.79096928314955e-05           loss:156.44949340820312\u001b[0m\n",
      "\u001b[34mlr_value:0.0001           loss:156.34190368652344\u001b[0m\n",
      "\u001b[34mlr_value:0.0001021349338436819           loss:156.23049926757812\u001b[0m\n",
      "\u001b[34mlr_value:0.0001043154471125328           loss:156.11880493164062\u001b[0m\n",
      "\u001b[34mlr_value:0.00010654251289712624           loss:156.00640869140625\u001b[0m\n",
      "\u001b[34mlr_value:0.00010881712506287603           loss:155.89654541015625\u001b[0m\n",
      "\u001b[34mlr_value:0.00011114029869356504           loss:155.77407836914062\u001b[0m\n",
      "\u001b[34mlr_value:0.00011351307054434311           loss:155.6549072265625\u001b[0m\n",
      "\u001b[34mlr_value:0.00011593649950439669           loss:155.53114318847656\u001b[0m\n",
      "\u001b[34mlr_value:0.00011841166706949616           loss:155.40476989746094\u001b[0m\n",
      "\u001b[34mlr_value:0.00012093967782463078           loss:155.28225708007812\u001b[0m\n",
      "\u001b[34mlr_value:0.00012352165993694854           loss:155.1578826904297\u001b[0m\n",
      "\u001b[34mlr_value:0.00012615876565922013           loss:155.02597045898438\u001b[0m\n",
      "\u001b[34mlr_value:0.00012885217184405016           loss:154.8909454345703\u001b[0m\n",
      "\u001b[34mlr_value:0.00013160308046906782           loss:154.7535858154297\u001b[0m\n",
      "\u001b[34mlr_value:0.00013441271917332987           loss:154.61622619628906\u001b[0m\n",
      "\u001b[34mlr_value:0.0001372823418051744           loss:154.47752380371094\u001b[0m\n",
      "\u001b[34mlr_value:0.000140213228981772           loss:154.33763122558594\u001b[0m\n",
      "\u001b[34mlr_value:0.00014320668866062307           loss:154.19500732421875\u001b[0m\n",
      "\u001b[34mlr_value:0.00014626405672325487           loss:154.0567169189453\u001b[0m\n",
      "\u001b[34mlr_value:0.0001493866975713816           loss:153.90969848632812\u001b[0m\n",
      "\u001b[34mlr_value:0.0001525760047357916           loss:153.76220703125\u001b[0m\n",
      "\u001b[34mlr_value:0.00015583340149823372           loss:153.61172485351562\u001b[0m\n",
      "\u001b[34mlr_value:0.0001591603415265802           loss:153.4547119140625\u001b[0m\n",
      "\u001b[34mlr_value:0.0001625583095235507           loss:153.3017578125\u001b[0m\n",
      "\u001b[34mlr_value:0.00016602882188928618           loss:153.1457977294922\u001b[0m\n",
      "\u001b[34mlr_value:0.0001695734273980669           loss:152.9861602783203\u001b[0m\n",
      "\u001b[34mlr_value:0.0001731937078894794           loss:152.8208465576172\u001b[0m\n",
      "\u001b[34mlr_value:0.00017689127897433946           loss:152.65260314941406\u001b[0m\n",
      "\u001b[34mlr_value:0.00018066779075568443           loss:152.48728942871094\u001b[0m\n",
      "\u001b[34mlr_value:0.00018452492856515975           loss:152.31491088867188\u001b[0m\n",
      "\u001b[34mlr_value:0.00018846441371512718           loss:152.14028930664062\u001b[0m\n",
      "\u001b[34mlr_value:0.00019248800426682812           loss:151.9610595703125\u001b[0m\n",
      "\u001b[34mlr_value:0.0001965974958149483           loss:151.78208923339844\u001b[0m\n",
      "\u001b[34mlr_value:0.00020079472228893275           loss:151.60240173339844\u001b[0m\n",
      "\u001b[34mlr_value:0.00020508155677140627           loss:151.417236328125\u001b[0m\n",
      "\u001b[34mlr_value:0.0002094599123340685           loss:151.2322235107422\u001b[0m\n",
      "\u001b[34mlr_value:0.00021393174289143478           loss:151.04608154296875\u001b[0m\n",
      "\u001b[34mlr_value:0.00021849904407280257           loss:150.85250854492188\u001b[0m\n",
      "\u001b[34mlr_value:0.00022316385411283427           loss:150.6567840576172\u001b[0m\n",
      "\u001b[34mlr_value:0.00022792825476115384           loss:150.45855712890625\u001b[0m\n",
      "\u001b[34mlr_value:0.00023279437221136322           loss:150.25927734375\u001b[0m\n",
      "\u001b[34mlr_value:0.00023776437804989045           loss:150.05648803710938\u001b[0m\n",
      "\u001b[34mlr_value:0.0002428404902250971           loss:149.84942626953125\u001b[0m\n",
      "\u001b[34mlr_value:0.0002480249740370757           loss:149.6386260986328\u001b[0m\n",
      "\u001b[34mlr_value:0.0002533201431485765           loss:149.42913818359375\u001b[0m\n",
      "\u001b[34mlr_value:0.00025872836061751866           loss:149.21495056152344\u001b[0m\n",
      "\u001b[34mlr_value:0.0002642520399515454           loss:148.99940490722656\u001b[0m\n",
      "\u001b[34mlr_value:0.0002698936461850908           loss:148.7768096923828\u001b[0m\n",
      "\u001b[34mlr_value:0.0002756556969794431           loss:148.54937744140625\u001b[0m\n",
      "\u001b[34mlr_value:0.0002815407637462945           loss:148.3197021484375\u001b[0m\n",
      "\u001b[34mlr_value:0.00028755147279527465           loss:148.08688354492188\u001b[0m\n",
      "\u001b[34mlr_value:0.0002936905065059864           loss:147.85256958007812\u001b[0m\n",
      "\u001b[34mlr_value:0.0002999606045250632           loss:147.61390686035156\u001b[0m\n",
      "\u001b[34mlr_value:0.0003063645649887816           loss:147.3717803955078\u001b[0m\n",
      "\u001b[34mlr_value:0.00031290524577177596           loss:147.12582397460938\u001b[0m\n",
      "\u001b[34mlr_value:0.0003195855657624133           loss:146.87606811523438\u001b[0m\n",
      "\u001b[34mlr_value:0.00032640850616539734           loss:146.6274871826172\u001b[0m\n",
      "\u001b[34mlr_value:0.000333377111832179           loss:146.3705291748047\u001b[0m\n",
      "\u001b[34mlr_value:0.00034049449261977304           loss:146.1107940673828\u001b[0m\n",
      "\u001b[34mlr_value:0.00034776382477858555           loss:145.8473358154297\u001b[0m\n",
      "\u001b[34mlr_value:0.00035518835236986624           loss:145.58047485351562\u001b[0m\n",
      "\u001b[34mlr_value:0.00036277138871342626           loss:145.31076049804688\u001b[0m\n",
      "\u001b[34mlr_value:0.00037051631786626406           loss:145.03578186035156\u001b[0m\n",
      "\u001b[34mlr_value:0.00037842659613275493           loss:144.7604217529297\u001b[0m\n",
      "\u001b[34mlr_value:0.00038650575360708617           loss:144.47950744628906\u001b[0m\n",
      "\u001b[34mlr_value:0.0003947573957486216           loss:144.19422912597656\u001b[0m\n",
      "\u001b[34mlr_value:0.00040318520499089624           loss:143.9092254638672\u001b[0m\n",
      "\u001b[34mlr_value:0.00041179294238496473           loss:143.61952209472656\u001b[0m\n",
      "\u001b[34mlr_value:0.00042058444927783444           loss:143.32333374023438\u001b[0m\n",
      "\u001b[34mlr_value:0.0004295636490267301           loss:143.0262908935547\u001b[0m\n",
      "\u001b[34mlr_value:0.0004387345487499567           loss:142.72267150878906\u001b[0m\n",
      "\u001b[34mlr_value:0.00044810124111514414           loss:142.4158477783203\u001b[0m\n",
      "\u001b[34mlr_value:0.00045766790616567           loss:142.1055908203125\u001b[0m\n",
      "\u001b[34mlr_value:0.00046743881318607125           loss:141.79241943359375\u001b[0m\n",
      "\u001b[34mlr_value:0.0004774183226072852           loss:141.47427368164062\u001b[0m\n",
      "\u001b[34mlr_value:0.0004876108879525666           loss:141.15408325195312\u001b[0m\n",
      "\u001b[34mlr_value:0.0004980210578249438           loss:140.82830810546875\u001b[0m\n",
      "\u001b[34mlr_value:0.0005086534779371106           loss:140.49925231933594\u001b[0m\n",
      "\u001b[34mlr_value:0.000519512893184655           loss:140.1665496826172\u001b[0m\n",
      "\u001b[34mlr_value:0.0005306041497635453           loss:139.8301239013672\u001b[0m\n",
      "\u001b[34mlr_value:0.0005419321973328272           loss:139.4908447265625\u001b[0m\n",
      "\u001b[34mlr_value:0.0005535020912234948           loss:139.1490936279297\u001b[0m\n",
      "\u001b[34mlr_value:0.0005653189946945123           loss:138.8020782470703\u001b[0m\n",
      "\u001b[34mlr_value:0.0005773881812370071           loss:138.45143127441406\u001b[0m\n",
      "\u001b[34mlr_value:0.0005897150369276547           loss:138.09800720214844\u001b[0m\n",
      "\u001b[34mlr_value:0.0006023050628323045           loss:137.74156188964844\u001b[0m\n",
      "\u001b[34mlr_value:0.0006151638774609209           loss:137.38446044921875\u001b[0m\n",
      "\u001b[34mlr_value:0.0006282972192749393           loss:137.0265350341797\u001b[0m\n",
      "\u001b[34mlr_value:0.0006417109492481523           loss:136.65806579589844\u001b[0m\n",
      "\u001b[34mlr_value:0.0006554110534822635           loss:136.2880096435547\u001b[0m\n",
      "\u001b[34mlr_value:0.0006694036458782878           loss:135.9147186279297\u001b[0m\n",
      "\u001b[34mlr_value:0.0006836949708649839           loss:135.5421600341797\u001b[0m\n",
      "\u001b[34mlr_value:0.0006982914061855316           loss:135.16390991210938\u001b[0m\n",
      "\u001b[34mlr_value:0.000713199465743708           loss:134.7830352783203\u001b[0m\n",
      "\u001b[34mlr_value:0.000728425802510829           loss:134.4015350341797\u001b[0m\n",
      "\u001b[34mlr_value:0.0007439772114947442           loss:134.0159912109375\u001b[0m\n",
      "\u001b[34mlr_value:0.0007598606327722256           loss:133.62945556640625\u001b[0m\n",
      "\u001b[34mlr_value:0.0007760831545860953           loss:133.2410888671875\u001b[0m\n",
      "\u001b[34mlr_value:0.000792652016508468           loss:132.85116577148438\u001b[0m\n",
      "\u001b[34mlr_value:0.0008095746126715335           loss:132.4597930908203\u001b[0m\n",
      "\u001b[34mlr_value:0.0008268584950673139           loss:132.06719970703125\u001b[0m\n",
      "\u001b[34mlr_value:0.0008445113769178649           loss:131.67388916015625\u001b[0m\n",
      "\u001b[34mlr_value:0.0008625411361174284           loss:131.2805938720703\u001b[0m\n",
      "\u001b[34mlr_value:0.0008809558187480769           loss:130.88490295410156\u001b[0m\n",
      "\u001b[34mlr_value:0.0008997636426704146           loss:130.49053955078125\u001b[0m\n",
      "\u001b[34mlr_value:0.0009189730011909304           loss:130.09295654296875\u001b[0m\n",
      "\u001b[34mlr_value:0.0009385924668076539           loss:129.69451904296875\u001b[0m\n",
      "\u001b[34mlr_value:0.0009586307950357793           loss:129.29661560058594\u001b[0m\n",
      "\u001b[34mlr_value:0.0009790969283149551           loss:128.8982696533203\u001b[0m\n",
      "\u001b[34mlr_value:0.001           loss:128.49876403808594\u001b[0m\n",
      "\u001b[34mlr_value:0.001021349338436819           loss:128.1035919189453\u001b[0m\n",
      "\u001b[34mlr_value:0.001043154471125328           loss:127.7044677734375\u001b[0m\n",
      "\u001b[34mlr_value:0.0010654251289712623           loss:127.30480194091797\u001b[0m\n",
      "\u001b[34mlr_value:0.0010881712506287614           loss:126.90757751464844\u001b[0m\n",
      "\u001b[34mlr_value:0.0011114029869356504           loss:126.5093994140625\u001b[0m\n",
      "\u001b[34mlr_value:0.0011351307054434311           loss:126.1135482788086\u001b[0m\n",
      "\u001b[34mlr_value:0.0011593649950439682           loss:125.71454620361328\u001b[0m\n",
      "\u001b[34mlr_value:0.0011841166706949616           loss:125.31686401367188\u001b[0m\n",
      "\u001b[34mlr_value:0.0012093967782463076           loss:124.91935729980469\u001b[0m\n",
      "\u001b[34mlr_value:0.0012352165993694854           loss:124.52066040039062\u001b[0m\n",
      "\u001b[34mlr_value:0.0012615876565922014           loss:124.1225814819336\u001b[0m\n",
      "\u001b[34mlr_value:0.0012885217184405017           loss:123.72499084472656\u001b[0m\n",
      "\u001b[34mlr_value:0.0013160308046906782           loss:123.32805633544922\u001b[0m\n",
      "\u001b[34mlr_value:0.0013441271917332988           loss:122.93223571777344\u001b[0m\n",
      "\u001b[34mlr_value:0.001372823418051744           loss:122.5364761352539\u001b[0m\n",
      "\u001b[34mlr_value:0.0014021322898177201           loss:122.14419555664062\u001b[0m\n",
      "\u001b[34mlr_value:0.0014320668866062306           loss:121.74798583984375\u001b[0m\n",
      "\u001b[34mlr_value:0.0014626405672325488           loss:121.3541488647461\u001b[0m\n",
      "\u001b[34mlr_value:0.001493866975713816           loss:120.96075439453125\u001b[0m\n",
      "\u001b[34mlr_value:0.0015257600473579174           loss:120.57073211669922\u001b[0m\n",
      "\u001b[34mlr_value:0.0015583340149823372           loss:120.1810302734375\u001b[0m\n",
      "\u001b[34mlr_value:0.001591603415265802           loss:119.791015625\u001b[0m\n",
      "\u001b[34mlr_value:0.0016255830952355086           loss:119.40211486816406\u001b[0m\n",
      "\u001b[34mlr_value:0.0016602882188928617           loss:119.0148696899414\u001b[0m\n",
      "\u001b[34mlr_value:0.0016957342739806688           loss:118.62698364257812\u001b[0m\n",
      "\u001b[34mlr_value:0.0017319370788947941           loss:118.24091339111328\u001b[0m\n",
      "\u001b[34mlr_value:0.0017689127897433947           loss:117.85714721679688\u001b[0m\n",
      "\u001b[34mlr_value:0.0018066779075568442           loss:117.47749328613281\u001b[0m\n",
      "\u001b[34mlr_value:0.0018452492856515974           loss:117.09650421142578\u001b[0m\n",
      "\u001b[34mlr_value:0.0018846441371512719           loss:116.72069549560547\u001b[0m\n",
      "\u001b[34mlr_value:0.0019248800426682811           loss:116.34564971923828\u001b[0m\n",
      "\u001b[34mlr_value:0.001965974958149483           loss:115.97364807128906\u001b[0m\n",
      "\u001b[34mlr_value:0.0020079472228893276           loss:115.60281372070312\u001b[0m\n",
      "\u001b[34mlr_value:0.0020508155677140625           loss:115.23538208007812\u001b[0m\n",
      "\u001b[34mlr_value:0.0020945991233406853           loss:114.86832427978516\u001b[0m\n",
      "\u001b[34mlr_value:0.0021393174289143497           loss:114.5047607421875\u001b[0m\n",
      "\u001b[34mlr_value:0.0021849904407280256           loss:114.14461517333984\u001b[0m\n",
      "\u001b[34mlr_value:0.002231638541128343           loss:113.78469848632812\u001b[0m\n",
      "\u001b[34mlr_value:0.002279282547611541           loss:113.42887878417969\u001b[0m\n",
      "\u001b[34mlr_value:0.002327943722113632           loss:113.0760726928711\u001b[0m\n",
      "\u001b[34mlr_value:0.0023776437804989043           loss:112.72837829589844\u001b[0m\n",
      "\u001b[34mlr_value:0.002428404902250971           loss:112.38385009765625\u001b[0m\n",
      "\u001b[34mlr_value:0.0024802497403707572           loss:112.04747772216797\u001b[0m\n",
      "\u001b[34mlr_value:0.002533201431485765           loss:111.7101821899414\u001b[0m\n",
      "\u001b[34mlr_value:0.0025872836061751866           loss:111.3791275024414\u001b[0m\n",
      "\u001b[34mlr_value:0.0026425203995154543           loss:111.04779815673828\u001b[0m\n",
      "\u001b[34mlr_value:0.002698936461850908           loss:110.72035217285156\u001b[0m\n",
      "\u001b[34mlr_value:0.0027565569697944312           loss:110.39552307128906\u001b[0m\n",
      "\u001b[34mlr_value:0.0028154076374629446           loss:110.0712661743164\u001b[0m\n",
      "\u001b[34mlr_value:0.0028755147279527463           loss:109.74871826171875\u001b[0m\n",
      "\u001b[34mlr_value:0.0029369050650598643           loss:109.42845916748047\u001b[0m\n",
      "\u001b[34mlr_value:0.002999606045250635           loss:109.11126708984375\u001b[0m\n",
      "\u001b[34mlr_value:0.003063645649887816           loss:108.79568481445312\u001b[0m\n",
      "\u001b[34mlr_value:0.0031290524577177593           loss:108.48339080810547\u001b[0m\n",
      "\u001b[34mlr_value:0.003195855657624136           loss:108.1740951538086\u001b[0m\n",
      "\u001b[34mlr_value:0.0032640850616539735           loss:107.86846923828125\u001b[0m\n",
      "\u001b[34mlr_value:0.0033337711183217896           loss:107.56413269042969\u001b[0m\n",
      "\u001b[34mlr_value:0.0034049449261977305           loss:107.26464080810547\u001b[0m\n",
      "\u001b[34mlr_value:0.003477638247785856           loss:106.96623229980469\u001b[0m\n",
      "\u001b[34mlr_value:0.003551883523698662           loss:106.66980743408203\u001b[0m\n",
      "\u001b[34mlr_value:0.0036277138871342626           loss:106.37994384765625\u001b[0m\n",
      "\u001b[34mlr_value:0.0037051631786626403           loss:106.0908203125\u001b[0m\n",
      "\u001b[34mlr_value:0.0037842659613275494           loss:105.80467224121094\u001b[0m\n",
      "\u001b[34mlr_value:0.0038650575360708616           loss:105.52070617675781\u001b[0m\n",
      "\u001b[34mlr_value:0.003947573957486216           loss:105.2375717163086\u001b[0m\n",
      "\u001b[34mlr_value:0.004031852049908962           loss:104.95631408691406\u001b[0m\n",
      "\u001b[34mlr_value:0.004117929423849647           loss:104.67695617675781\u001b[0m\n",
      "\u001b[34mlr_value:0.004205844492778349           loss:104.40304565429688\u001b[0m\n",
      "\u001b[34mlr_value:0.004295636490267301           loss:104.1341781616211\u001b[0m\n",
      "\u001b[34mlr_value:0.004387345487499567           loss:103.8727798461914\u001b[0m\n",
      "\u001b[34mlr_value:0.004481012411151446           loss:103.61222076416016\u001b[0m\n",
      "\u001b[34mlr_value:0.0045766790616567           loss:103.35871124267578\u001b[0m\n",
      "\u001b[34mlr_value:0.004674388131860712           loss:103.10894775390625\u001b[0m\n",
      "\u001b[34mlr_value:0.004774183226072852           loss:102.86040496826172\u001b[0m\n",
      "\u001b[34mlr_value:0.0048761088795256655           loss:102.6167221069336\u001b[0m\n",
      "\u001b[34mlr_value:0.004980210578249438           loss:102.37480926513672\u001b[0m\n",
      "\u001b[34mlr_value:0.005086534779371106           loss:102.1338882446289\u001b[0m\n",
      "\u001b[34mlr_value:0.005195128931846551           loss:101.89524841308594\u001b[0m\n",
      "\u001b[34mlr_value:0.005306041497635453           loss:101.6586685180664\u001b[0m\n",
      "\u001b[34mlr_value:0.0054193219733282725           loss:101.42557525634766\u001b[0m\n",
      "\u001b[34mlr_value:0.005535020912234948           loss:101.19542694091797\u001b[0m\n",
      "\u001b[34mlr_value:0.0056531899469451224           loss:100.970947265625\u001b[0m\n",
      "\u001b[34mlr_value:0.005773881812370071           loss:100.74966430664062\u001b[0m\n",
      "\u001b[34mlr_value:0.005897150369276554           loss:100.53167724609375\u001b[0m\n",
      "\u001b[34mlr_value:0.006023050628323045           loss:100.31977844238281\u001b[0m\n",
      "\u001b[34mlr_value:0.006151638774609209           loss:100.11546325683594\u001b[0m\n",
      "\u001b[34mlr_value:0.0062829721927494           loss:99.91402435302734\u001b[0m\n",
      "\u001b[34mlr_value:0.006417109492481523           loss:99.71675109863281\u001b[0m\n",
      "\u001b[34mlr_value:0.006554110534822635           loss:99.52274322509766\u001b[0m\n",
      "\u001b[34mlr_value:0.0066940364587828784           loss:99.32666015625\u001b[0m\n",
      "\u001b[34mlr_value:0.0068369497086498395           loss:99.13069915771484\u001b[0m\n",
      "\u001b[34mlr_value:0.006982914061855316           loss:98.9347915649414\u001b[0m\n",
      "\u001b[34mlr_value:0.0071319946574370805           loss:98.73872375488281\u001b[0m\n",
      "\u001b[34mlr_value:0.00728425802510829           loss:98.54324340820312\u001b[0m\n",
      "\u001b[34mlr_value:0.007439772114947442           loss:98.35572814941406\u001b[0m\n",
      "\u001b[34mlr_value:0.007598606327722256           loss:98.17276763916016\u001b[0m\n",
      "\u001b[34mlr_value:0.007760831545860953           loss:97.99258422851562\u001b[0m\n",
      "\u001b[34mlr_value:0.00792652016508468           loss:97.8218765258789\u001b[0m\n",
      "\u001b[34mlr_value:0.008095746126715335           loss:97.65508270263672\u001b[0m\n",
      "\u001b[34mlr_value:0.008268584950673149           loss:97.48795318603516\u001b[0m\n",
      "\u001b[34mlr_value:0.008445113769178648           loss:97.3240966796875\u001b[0m\n",
      "\u001b[34mlr_value:0.008625411361174284           loss:97.1587905883789\u001b[0m\n",
      "\u001b[34mlr_value:0.008809558187480778           loss:96.9944839477539\u001b[0m\n",
      "\u001b[34mlr_value:0.008997636426704146           loss:96.8332290649414\u001b[0m\n",
      "\u001b[34mlr_value:0.009189730011909304           loss:96.67852020263672\u001b[0m\n",
      "\u001b[34mlr_value:0.009385924668076539           loss:96.5268325805664\u001b[0m\n",
      "\u001b[34mlr_value:0.009586307950357793           loss:96.37967681884766\u001b[0m\n",
      "\u001b[34mlr_value:0.00979096928314955           loss:96.24675750732422\u001b[0m\n",
      "\u001b[34mlr_value:0.01           loss:96.11318969726562\u001b[0m\n",
      "\u001b[34mlr_value:0.01021349338436819           loss:95.98762512207031\u001b[0m\n",
      "\u001b[34mlr_value:0.01043154471125328           loss:95.87559509277344\u001b[0m\n",
      "\u001b[34mlr_value:0.010654251289712624           loss:95.76378631591797\u001b[0m\n",
      "\u001b[34mlr_value:0.010881712506287614           loss:95.65223693847656\u001b[0m\n",
      "\u001b[34mlr_value:0.011114029869356515           loss:95.54400634765625\u001b[0m\n",
      "\u001b[34mlr_value:0.011351307054434311           loss:95.4345474243164\u001b[0m\n",
      "\u001b[34mlr_value:0.011593649950439681           loss:95.3287353515625\u001b[0m\n",
      "\u001b[34mlr_value:0.011841166706949615           loss:95.2308120727539\u001b[0m\n",
      "\u001b[34mlr_value:0.012093967782463078           loss:95.12651824951172\u001b[0m\n",
      "\u001b[34mlr_value:0.012352165993694868           loss:95.04059600830078\u001b[0m\n",
      "\u001b[34mlr_value:0.012615876565922014           loss:94.95530700683594\u001b[0m\n",
      "\u001b[34mlr_value:0.012885217184405016           loss:94.88043212890625\u001b[0m\n",
      "\u001b[34mlr_value:0.013160308046906783           loss:94.8056640625\u001b[0m\n",
      "\u001b[34mlr_value:0.013441271917332989           loss:94.73726654052734\u001b[0m\n",
      "\u001b[34mlr_value:0.013728234180517442           loss:94.68095397949219\u001b[0m\n",
      "\u001b[34mlr_value:0.0140213228981772           loss:94.62569427490234\u001b[0m\n",
      "\u001b[34mlr_value:0.014320668866062307           loss:94.580322265625\u001b[0m\n",
      "\u001b[34mlr_value:0.014626405672325487           loss:94.53960418701172\u001b[0m\n",
      "\u001b[34mlr_value:0.01493866975713816           loss:94.50540161132812\u001b[0m\n",
      "\u001b[34mlr_value:0.015257600473579176           loss:94.47699737548828\u001b[0m\n",
      "\u001b[34mlr_value:0.015583340149823387           loss:94.458251953125\u001b[0m\n",
      "\u001b[34mlr_value:0.01591603415265802           loss:94.44104766845703\u001b[0m\n",
      "\u001b[34mlr_value:0.016255830952355086           loss:94.4327621459961\u001b[0m\n",
      "\u001b[34mlr_value:0.01660288218892862           loss:94.4282455444336\u001b[0m\n",
      "\u001b[34mlr_value:0.01695734273980669           loss:94.4341049194336\u001b[0m\n",
      "\u001b[34mlr_value:0.01731937078894796           loss:94.44310760498047\u001b[0m\n",
      "\u001b[34mlr_value:0.01768912789743395           loss:94.45964050292969\u001b[0m\n",
      "\u001b[34mlr_value:0.018066779075568442           loss:94.48532104492188\u001b[0m\n",
      "\u001b[34mlr_value:0.018452492856515974           loss:94.51789093017578\u001b[0m\n",
      "\u001b[34mlr_value:0.01884644137151272           loss:94.57403564453125\u001b[0m\n",
      "\u001b[34mlr_value:0.019248800426682814           loss:94.63109588623047\u001b[0m\n",
      "\u001b[34mlr_value:0.01965974958149483           loss:94.70504760742188\u001b[0m\n",
      "\u001b[34mlr_value:0.020079472228893273           loss:94.77550506591797\u001b[0m\n",
      "\u001b[34mlr_value:0.020508155677140625           loss:94.85365295410156\u001b[0m\n",
      "\u001b[34mlr_value:0.020945991233406853           loss:94.92950439453125\u001b[0m\n",
      "\u001b[34mlr_value:0.021393174289143498           loss:94.99327087402344\u001b[0m\n",
      "\u001b[34mlr_value:0.02184990440728028           loss:95.05960845947266\u001b[0m\n",
      "\u001b[34mlr_value:0.02231638541128343           loss:95.12492370605469\u001b[0m\n",
      "\u001b[34mlr_value:0.022792825476115407           loss:95.18141174316406\u001b[0m\n",
      "\u001b[34mlr_value:0.02327943722113632           loss:95.23603057861328\u001b[0m\n",
      "\u001b[34mlr_value:0.023776437804989045           loss:95.28863525390625\u001b[0m\n",
      "\u001b[34mlr_value:0.024284049022509736           loss:95.34259796142578\u001b[0m\n",
      "\u001b[34mlr_value:0.024802497403707574           loss:95.41350555419922\u001b[0m\n",
      "\u001b[34mlr_value:0.02533201431485765           loss:95.49761962890625\u001b[0m\n",
      "\u001b[34mlr_value:0.025872836061751867           loss:95.60929870605469\u001b[0m\n",
      "\u001b[34mlr_value:0.026425203995154543           loss:95.74836730957031\u001b[0m\n",
      "\u001b[34mlr_value:0.02698936461850908           loss:95.9123306274414\u001b[0m\n",
      "\u001b[34mlr_value:0.02756556969794431           loss:96.0660629272461\u001b[0m\n",
      "\u001b[34mlr_value:0.02815407637462945           loss:96.22084045410156\u001b[0m\n",
      "\u001b[34mlr_value:0.028755147279527462           loss:96.37152862548828\u001b[0m\n",
      "\u001b[34mlr_value:0.02936905065059864           loss:96.51861572265625\u001b[0m\n",
      "\u001b[34mlr_value:0.02999606045250635           loss:96.66531372070312\u001b[0m\n",
      "\u001b[34mlr_value:0.03063645649887819           loss:96.80635070800781\u001b[0m\n",
      "\u001b[34mlr_value:0.0312905245771776           loss:96.93824768066406\u001b[0m\n",
      "\u001b[34mlr_value:0.031958556576241366           loss:97.06336975097656\u001b[0m\n",
      "\u001b[34mlr_value:0.032640850616539735           loss:97.17780303955078\u001b[0m\n",
      "\u001b[34mlr_value:0.0333377111832179           loss:97.27901458740234\u001b[0m\n",
      "\u001b[34mlr_value:0.03404944926197734           loss:97.37849426269531\u001b[0m\n",
      "\u001b[34mlr_value:0.03477638247785856           loss:97.47589874267578\u001b[0m\n",
      "\u001b[34mlr_value:0.03551883523698662           loss:97.57933044433594\u001b[0m\n",
      "\u001b[34mlr_value:0.03627713887134263           loss:97.71588134765625\u001b[0m\n",
      "\u001b[34mlr_value:0.037051631786626404           loss:97.86907958984375\u001b[0m\n",
      "\u001b[34mlr_value:0.037842659613275494           loss:98.03031921386719\u001b[0m\n",
      "\u001b[34mlr_value:0.038650575360708615           loss:98.21370697021484\u001b[0m\n",
      "\u001b[34mlr_value:0.03947573957486216           loss:98.3735122680664\u001b[0m\n",
      "\u001b[34mlr_value:0.04031852049908963           loss:98.52238464355469\u001b[0m\n",
      "\u001b[34mlr_value:0.04117929423849647           loss:98.6614990234375\u001b[0m\n",
      "\u001b[34mlr_value:0.04205844492778349           loss:98.81195831298828\u001b[0m\n",
      "\u001b[34mlr_value:0.04295636490267305           loss:98.95806121826172\u001b[0m\n",
      "\u001b[34mlr_value:0.04387345487499567           loss:99.10693359375\u001b[0m\n",
      "\u001b[34mlr_value:0.04481012411151446           loss:99.25888061523438\u001b[0m\n",
      "\u001b[34mlr_value:0.045766790616567           loss:99.41154479980469\u001b[0m\n",
      "\u001b[34mlr_value:0.04674388131860712           loss:99.55998992919922\u001b[0m\n",
      "\u001b[34mlr_value:0.04774183226072857           loss:99.71009826660156\u001b[0m\n",
      "\u001b[34mlr_value:0.04876108879525666           loss:99.8613052368164\u001b[0m\n",
      "\u001b[34mlr_value:0.049802105782494374           loss:100.04740905761719\u001b[0m\n",
      "\u001b[34mlr_value:0.05086534779371106           loss:100.23429107666016\u001b[0m\n",
      "\u001b[34mlr_value:0.0519512893184655           loss:100.43463134765625\u001b[0m\n",
      "\u001b[34mlr_value:0.053060414976354525           loss:100.66220092773438\u001b[0m\n",
      "\u001b[34mlr_value:0.05419321973328273           loss:100.89595794677734\u001b[0m\n",
      "\u001b[34mlr_value:0.055350209122349475           loss:101.14270782470703\u001b[0m\n",
      "\u001b[34mlr_value:0.056531899469451224           loss:101.41424560546875\u001b[0m\n",
      "\u001b[34mlr_value:0.05773881812370071           loss:101.69029235839844\u001b[0m\n",
      "\u001b[34mlr_value:0.058971503692765534           loss:101.96139526367188\u001b[0m\n",
      "\u001b[34mlr_value:0.06023050628323051           loss:102.22797393798828\u001b[0m\n",
      "\u001b[34mlr_value:0.06151638774609209           loss:102.49612426757812\u001b[0m\n",
      "\u001b[34mlr_value:0.062829721927494           loss:102.77346801757812\u001b[0m\n",
      "\u001b[34mlr_value:0.06417109492481524           loss:103.06206512451172\u001b[0m\n",
      "\u001b[34mlr_value:0.06554110534822635           loss:103.38148498535156\u001b[0m\n",
      "\u001b[34mlr_value:0.06694036458782884           loss:103.70427703857422\u001b[0m\n",
      "\u001b[34mlr_value:0.0683694970864984           loss:104.02252197265625\u001b[0m\n",
      "\u001b[34mlr_value:0.06982914061855316           loss:104.32151794433594\u001b[0m\n",
      "\u001b[34mlr_value:0.07131994657437081           loss:104.60285949707031\u001b[0m\n",
      "\u001b[34mlr_value:0.0728425802510829           loss:104.88560485839844\u001b[0m\n",
      "\u001b[34mlr_value:0.07439772114947442           loss:105.16326141357422\u001b[0m\n",
      "\u001b[34mlr_value:0.07598606327722256           loss:105.49714660644531\u001b[0m\n",
      "\u001b[34mlr_value:0.07760831545860954           loss:105.93292236328125\u001b[0m\n",
      "\u001b[34mlr_value:0.0792652016508468           loss:106.42491149902344\u001b[0m\n",
      "\u001b[34mlr_value:0.08095746126715335           loss:106.99444580078125\u001b[0m\n",
      "\u001b[34mlr_value:0.08268584950673148           loss:107.66635131835938\u001b[0m\n",
      "\u001b[34mlr_value:0.08445113769178658           loss:108.35667419433594\u001b[0m\n",
      "\u001b[34mlr_value:0.08625411361174284           loss:109.11080932617188\u001b[0m\n",
      "\u001b[34mlr_value:0.08809558187480777           loss:109.86935424804688\u001b[0m\n",
      "\u001b[34mlr_value:0.08997636426704146           loss:110.68457794189453\u001b[0m\n",
      "\u001b[34mlr_value:0.09189730011909304           loss:111.4945068359375\u001b[0m\n",
      "\u001b[34mlr_value:0.09385924668076549           loss:112.30107879638672\u001b[0m\n",
      "\u001b[34mlr_value:0.09586307950357793           loss:113.08321380615234\u001b[0m\n",
      "\u001b[34mlr_value:0.0979096928314955           loss:113.84848022460938\u001b[0m\n",
      "\u001b[34mlr_value:0.1           loss:114.59397888183594\u001b[0m\n",
      "\u001b[34mlr_value:0.10213493384368201           loss:115.35530853271484\u001b[0m\n",
      "\u001b[34mlr_value:0.1043154471125328           loss:116.09502410888672\u001b[0m\n",
      "\u001b[34mlr_value:0.10654251289712624           loss:116.91232299804688\u001b[0m\n",
      "\u001b[34mlr_value:0.10881712506287626           loss:117.7711410522461\u001b[0m\n",
      "\u001b[34mlr_value:0.11114029869356515           loss:118.66081237792969\u001b[0m\n",
      "\u001b[34mlr_value:0.11351307054434312           loss:119.58284759521484\u001b[0m\n",
      "\u001b[34mlr_value:0.11593649950439669           loss:120.54022979736328\u001b[0m\n",
      "\u001b[34mlr_value:0.11841166706949628           loss:121.4979476928711\u001b[0m\n",
      "\u001b[34mlr_value:0.12093967782463078           loss:122.45240020751953\u001b[0m\n",
      "\u001b[34mlr_value:0.12352165993694855           loss:123.37693786621094\u001b[0m\n",
      "\u001b[34mlr_value:0.12615876565922027           loss:124.27771759033203\u001b[0m\n",
      "\u001b[34mlr_value:0.12885217184405018           loss:125.15699768066406\u001b[0m\n",
      "\u001b[34mlr_value:0.13160308046906782           loss:126.03341674804688\u001b[0m\n",
      "\u001b[34mlr_value:0.13441271917333003           loss:126.9253158569336\u001b[0m\n",
      "\u001b[34mlr_value:0.1372823418051744           loss:127.93956756591797\u001b[0m\n",
      "\u001b[34mlr_value:0.14021322898177202           loss:129.14292907714844\u001b[0m\n",
      "\u001b[34mlr_value:0.14320668866062322           loss:130.53663635253906\u001b[0m\n",
      "\u001b[34mlr_value:0.14626405672325488           loss:132.14938354492188\u001b[0m\n",
      "\u001b[34mlr_value:0.1493866975713816           loss:133.96778869628906\u001b[0m\n",
      "\u001b[34mlr_value:0.15257600473579158           loss:135.9881134033203\u001b[0m\n",
      "\u001b[34mlr_value:0.15583340149823388           loss:138.06552124023438\u001b[0m\n",
      "\u001b[34mlr_value:0.1591603415265802           loss:140.30702209472656\u001b[0m\n",
      "\u001b[34mlr_value:0.16255830952355071           loss:142.61181640625\u001b[0m\n",
      "\u001b[34mlr_value:0.16602882188928633           loss:145.08106994628906\u001b[0m\n",
      "\u001b[34mlr_value:0.16957342739806688           loss:147.63906860351562\u001b[0m\n",
      "\u001b[34mlr_value:0.1731937078894794           loss:150.26332092285156\u001b[0m\n",
      "\u001b[34mlr_value:0.17689127897433965           loss:153.12008666992188\u001b[0m\n",
      "\u001b[34mlr_value:0.18066779075568443           loss:156.29225158691406\u001b[0m\n",
      "\u001b[34mlr_value:0.18452492856515973           loss:159.88368225097656\u001b[0m\n",
      "\u001b[34mlr_value:0.1884644137151274           loss:164.0833282470703\u001b[0m\n",
      "\u001b[34mlr_value:0.19248800426682813           loss:168.94747924804688\u001b[0m\n",
      "\u001b[34mlr_value:0.19659749581494831           loss:174.28976440429688\u001b[0m\n",
      "\u001b[34mlr_value:0.20079472228893294           loss:180.07017517089844\u001b[0m\n",
      "\u001b[34mlr_value:0.20508155677140627           loss:186.41265869140625\u001b[0m\n",
      "\u001b[34mlr_value:0.20945991233406852           loss:193.03639221191406\u001b[0m\n",
      "\u001b[34mlr_value:0.2139317428914352           loss:199.64845275878906\u001b[0m\n",
      "\u001b[34mlr_value:0.2184990440728028           loss:207.4537353515625\u001b[0m\n",
      "\u001b[34mlr_value:0.22316385411283426           loss:214.107177734375\u001b[0m\n",
      "\u001b[34mlr_value:0.22792825476115386           loss:221.3199462890625\u001b[0m\n",
      "\u001b[34mlr_value:0.23279437221136345           loss:228.6946258544922\u001b[0m\n",
      "\u001b[34mlr_value:0.23776437804989045           loss:236.5940704345703\u001b[0m\n",
      "\u001b[34mlr_value:0.2428404902250971           loss:244.33078002929688\u001b[0m\n",
      "\u001b[34mlr_value:0.248024974037076           loss:252.33621215820312\u001b[0m\n",
      "\u001b[34mlr_value:0.25332014314857654           loss:260.6128234863281\u001b[0m\n",
      "\u001b[34mlr_value:0.25872836061751864           loss:269.0351867675781\u001b[0m\n",
      "\u001b[34mlr_value:0.26425203995154567           loss:278.3443908691406\u001b[0m\n",
      "\u001b[34mlr_value:0.2698936461850908           loss:287.75799560546875\u001b[0m\n",
      "\u001b[34mlr_value:0.2756556969794431           loss:297.78228759765625\u001b[0m\n",
      "\u001b[34mlr_value:0.2815407637462948           loss:309.0138244628906\u001b[0m\n",
      "\u001b[34mlr_value:0.2875514727952746           loss:321.655029296875\u001b[0m\n",
      "\u001b[34mlr_value:0.2936905065059864           loss:334.9607849121094\u001b[0m\n",
      "\u001b[34mlr_value:0.2999606045250632           loss:349.952880859375\u001b[0m\n",
      "\u001b[34mlr_value:0.3063645649887819           loss:364.93548583984375\u001b[0m\n",
      "\u001b[34mlr_value:0.312905245771776           loss:380.7013244628906\u001b[0m\n",
      "\u001b[34mlr_value:0.3195855657624133           loss:397.10595703125\u001b[0m\n",
      "\u001b[34mlr_value:0.3264085061653977           loss:413.8675842285156\u001b[0m\n",
      "\u001b[34mlr_value:0.33337711183217894           loss:430.385498046875\u001b[0m\n",
      "\u001b[34mlr_value:0.34049449261977305           loss:446.844970703125\u001b[0m\n",
      "\u001b[34mlr_value:0.3477638247785859           loss:462.896484375\u001b[0m\n",
      "\u001b[34mlr_value:0.35518835236986623           loss:478.3930358886719\u001b[0m\n",
      "\u001b[34mlr_value:0.3627713887134263           loss:493.2241516113281\u001b[0m\n",
      "\u001b[34mlr_value:0.37051631786626443           loss:507.27386474609375\u001b[0m\n",
      "\u001b[34mlr_value:0.3784265961327549           loss:522.4116821289062\u001b[0m\n",
      "\u001b[34mlr_value:0.38650575360708617           loss:537.8585205078125\u001b[0m\n",
      "\u001b[34mlr_value:0.394757395748622           loss:554.5851440429688\u001b[0m\n",
      "\u001b[34mlr_value:0.4031852049908963           loss:571.8240356445312\u001b[0m\n",
      "\u001b[34mlr_value:0.4117929423849647           loss:589.9078369140625\u001b[0m\n",
      "\u001b[34mlr_value:0.4205844492778353           loss:608.6324462890625\u001b[0m\n",
      "\u001b[34mlr_value:0.4295636490267305           loss:627.2083740234375\u001b[0m\n",
      "\u001b[34mlr_value:0.4387345487499567           loss:645.1452026367188\u001b[0m\n",
      "\u001b[34mlr_value:0.44810124111514416           loss:663.5235595703125\u001b[0m\n",
      "\u001b[34mlr_value:0.4576679061656705           loss:680.3792114257812\u001b[0m\n",
      "\u001b[34mlr_value:0.4674388131860712           loss:699.0682373046875\u001b[0m\n",
      "\u001b[34mlr_value:0.4774183226072852           loss:717.98828125\u001b[0m\n",
      "\u001b[34mlr_value:0.4876108879525671           loss:737.8370361328125\u001b[0m\n",
      "\u001b[34mlr_value:0.49802105782494377           loss:759.5355834960938\u001b[0m\n",
      "\u001b[34mlr_value:0.5086534779371106           loss:783.80859375\u001b[0m\n",
      "\u001b[34mlr_value:0.5195128931846555           loss:810.4957275390625\u001b[0m\n",
      "\u001b[34mlr_value:0.5306041497635453           loss:838.3026733398438\u001b[0m\n",
      "\u001b[34mlr_value:0.5419321973328273           loss:869.1116333007812\u001b[0m\n",
      "\u001b[34mlr_value:0.5535020912234954           loss:904.4312744140625\u001b[0m\n",
      "\u001b[34mlr_value:0.5653189946945122           loss:940.7434692382812\u001b[0m\n",
      "\u001b[34mlr_value:0.5773881812370071           loss:980.8900146484375\u001b[0m\n",
      "\u001b[34mlr_value:0.5897150369276548           loss:1019.6990356445312\u001b[0m\n",
      "\u001b[34mlr_value:0.6023050628323051           loss:1063.3271484375\u001b[0m\n",
      "\u001b[34mlr_value:0.6151638774609209           loss:1102.150146484375\u001b[0m\n",
      "\u001b[34mlr_value:0.6282972192749393           loss:1143.3516845703125\u001b[0m\n",
      "\u001b[34mlr_value:0.641710949248153           loss:1186.208740234375\u001b[0m\n",
      "\u001b[34mlr_value:0.6554110534822636           loss:1228.270263671875\u001b[0m\n",
      "\u001b[34mlr_value:0.6694036458782878           loss:1269.0662841796875\u001b[0m\n",
      "\u001b[34mlr_value:0.6836949708649847           loss:1313.5169677734375\u001b[0m\n",
      "\u001b[34mlr_value:0.6982914061855316           loss:1359.7413330078125\u001b[0m\n",
      "\u001b[34mlr_value:0.7131994657437081           loss:1411.326416015625\u001b[0m\n",
      "\u001b[34mlr_value:0.7284258025108298           loss:1476.5609130859375\u001b[0m\n",
      "\u001b[34mlr_value:0.7439772114947442           loss:1542.2352294921875\u001b[0m\n",
      "\u001b[34mlr_value:0.7598606327722256           loss:1616.9659423828125\u001b[0m\n",
      "\u001b[34mlr_value:0.7760831545860961           loss:1698.79248046875\u001b[0m\n",
      "\u001b[34mlr_value:0.7926520165084681           loss:1792.3780517578125\u001b[0m\n",
      "\u001b[34mlr_value:0.8095746126715335           loss:1895.664306640625\u001b[0m\n",
      "\u001b[34mlr_value:0.8268584950673157           loss:1998.5341796875\u001b[0m\n",
      "\u001b[34mlr_value:0.8445113769178657           loss:2105.566650390625\u001b[0m\n",
      "\u001b[34mlr_value:0.8625411361174284           loss:2220.244384765625\u001b[0m\n",
      "\u001b[34mlr_value:0.8809558187480769           loss:2339.216552734375\u001b[0m\n",
      "\u001b[34mlr_value:0.8997636426704155           loss:2472.48388671875\u001b[0m\n",
      "\u001b[34mlr_value:0.9189730011909304           loss:2606.85205078125\u001b[0m\n",
      "\u001b[34mlr_value:0.938592466807654           loss:2754.620361328125\u001b[0m\n",
      "\u001b[34mlr_value:0.9586307950357803           loss:2911.302001953125\u001b[0m\n",
      "\u001b[34mlr_value:0.9790969283149551           loss:3096.479736328125\u001b[0m\n",
      "\u001b[34mlr_value:1.0           loss:3279.33642578125\u001b[0m\n",
      "\u001b[34mlr_value:1.0213493384368202           loss:3474.91162109375\u001b[0m\n",
      "\u001b[34mlr_value:1.043154471125328           loss:3683.548828125\u001b[0m\n",
      "\u001b[34mlr_value:1.0654251289712624           loss:3898.355712890625\u001b[0m\n",
      "\u001b[34mlr_value:1.0881712506287626           loss:4114.7392578125\u001b[0m\n",
      "\u001b[34mlr_value:1.1114029869356514           loss:4331.75732421875\u001b[0m\n",
      "\u001b[34mlr_value:1.1351307054434312           loss:4541.4033203125\u001b[0m\n",
      "\u001b[34mlr_value:1.1593649950439668           loss:4758.48046875\u001b[0m\n",
      "\u001b[34mlr_value:1.1841166706949628           loss:4981.095703125\u001b[0m\n",
      "\u001b[34mlr_value:1.2093967782463078           loss:5209.3916015625\u001b[0m\n",
      "\u001b[34mlr_value:1.2352165993694855           loss:5449.79638671875\u001b[0m\n",
      "\u001b[34mlr_value:1.2615876565922026           loss:5714.19189453125\u001b[0m\n",
      "\u001b[34mlr_value:1.2885217184405016           loss:5993.98876953125\u001b[0m\n",
      "\u001b[34mlr_value:1.3160308046906781           loss:6276.15576171875\u001b[0m\n",
      "\u001b[34mlr_value:1.3441271917333002           loss:6592.5390625\u001b[0m\n",
      "\u001b[34mlr_value:1.3728234180517442           loss:6928.82421875\u001b[0m\n",
      "\u001b[34mlr_value:1.4021322898177202           loss:7224.29248046875\u001b[0m\n",
      "\u001b[34mlr_value:1.432066886606232           loss:7528.1884765625\u001b[0m\n",
      "\u001b[34mlr_value:1.4626405672325489           loss:7828.912109375\u001b[0m\n",
      "\u001b[34mlr_value:1.4938669757138159           loss:8125.06005859375\u001b[0m\n",
      "\u001b[34mlr_value:1.5257600473579191           loss:8431.73828125\u001b[0m\n",
      "\u001b[34mlr_value:1.5583340149823388           loss:8726.630859375\u001b[0m\n",
      "\u001b[34mlr_value:1.591603415265802           loss:9011.04296875\u001b[0m\n",
      "\u001b[34mlr_value:1.6255830952355104           loss:9318.9814453125\u001b[0m\n",
      "\u001b[34mlr_value:1.6602882188928634           loss:9639.119140625\u001b[0m\n",
      "\u001b[34mlr_value:1.695734273980669           loss:9998.826171875\u001b[0m\n",
      "\u001b[34mlr_value:1.731937078894794           loss:10419.0009765625\u001b[0m\n",
      "\u001b[34mlr_value:1.7689127897433965           loss:10893.904296875\u001b[0m\n",
      "\u001b[34mlr_value:1.8066779075568442           loss:11430.013671875\u001b[0m\n",
      "\u001b[34mlr_value:1.8452492856515974           loss:11981.333984375\u001b[0m\n",
      "\u001b[34mlr_value:1.8846441371512739           loss:12506.7548828125\u001b[0m\n",
      "\u001b[34mlr_value:1.9248800426682813           loss:13090.513671875\u001b[0m\n",
      "\u001b[34mlr_value:1.965974958149483           loss:13670.109375\u001b[0m\n",
      "\u001b[34mlr_value:2.0079472228893294           loss:14245.802734375\u001b[0m\n",
      "\u001b[34mlr_value:2.0508155677140625           loss:14842.794921875\u001b[0m\n",
      "\u001b[34mlr_value:2.0945991233406853           loss:15388.7109375\u001b[0m\n",
      "\u001b[34mlr_value:2.139317428914352           loss:15962.2373046875\u001b[0m\n",
      "\u001b[34mlr_value:2.184990440728028           loss:16498.396484375\u001b[0m\n",
      "\u001b[34mlr_value:2.231638541128343           loss:17060.951171875\u001b[0m\n",
      "\u001b[34mlr_value:2.2792825476115386           loss:17619.72265625\u001b[0m\n",
      "\u001b[34mlr_value:2.3279437221136345           loss:18185.607421875\u001b[0m\n",
      "\u001b[34mlr_value:2.3776437804989046           loss:18780.66796875\u001b[0m\n",
      "\u001b[34mlr_value:2.428404902250971           loss:19466.6640625\u001b[0m\n",
      "\u001b[34mlr_value:2.48024974037076           loss:20245.865234375\u001b[0m\n",
      "\u001b[34mlr_value:2.5332014314857654           loss:20978.6796875\u001b[0m\n",
      "\u001b[34mlr_value:2.5872836061751867           loss:21746.951171875\u001b[0m\n",
      "\u001b[34mlr_value:2.642520399515457           loss:22597.263671875\u001b[0m\n",
      "\u001b[34mlr_value:2.698936461850908           loss:23510.19921875\u001b[0m\n",
      "\u001b[34mlr_value:2.756556969794431           loss:24469.830078125\u001b[0m\n",
      "\u001b[34mlr_value:2.8154076374629478           loss:25402.583984375\u001b[0m\n",
      "\u001b[34mlr_value:2.8755147279527464           loss:26416.54296875\u001b[0m\n",
      "\u001b[34mlr_value:2.936905065059864           loss:27439.75390625\u001b[0m\n",
      "\u001b[34mlr_value:2.9996060452506383           loss:28539.3984375\u001b[0m\n",
      "\u001b[34mlr_value:3.0636456498878193           loss:29721.916015625\u001b[0m\n",
      "\u001b[34mlr_value:3.1290524577177594           loss:30990.4296875\u001b[0m\n",
      "\u001b[34mlr_value:3.1958556576241395           loss:32251.98046875\u001b[0m\n",
      "\u001b[34mlr_value:3.2640850616539767           loss:33674.796875\u001b[0m\n",
      "\u001b[34mlr_value:3.3337711183217897           loss:35133.19140625\u001b[0m\n",
      "\u001b[34mlr_value:3.4049449261977305           loss:36708.99609375\u001b[0m\n",
      "\u001b[34mlr_value:3.477638247785859           loss:38184.3203125\u001b[0m\n",
      "\u001b[34mlr_value:3.5518835236986623           loss:39735.24609375\u001b[0m\n",
      "\u001b[34mlr_value:3.627713887134263           loss:41281.14453125\u001b[0m\n",
      "\u001b[34mlr_value:3.705163178662644           loss:43181.328125\u001b[0m\n",
      "\u001b[34mlr_value:3.784265961327549           loss:44866.23046875\u001b[0m\n",
      "\u001b[34mlr_value:3.8650575360708617           loss:46964.35546875\u001b[0m\n",
      "\u001b[34mlr_value:3.9475739574862203           loss:49157.8203125\u001b[0m\n",
      "\u001b[34mlr_value:4.031852049908963           loss:51664.3671875\u001b[0m\n",
      "\u001b[34mlr_value:4.117929423849647           loss:54294.40625\u001b[0m\n",
      "\u001b[34mlr_value:4.205844492778353           loss:56991.2578125\u001b[0m\n",
      "\u001b[34mlr_value:4.295636490267305           loss:59824.22265625\u001b[0m\n",
      "\u001b[34mlr_value:4.387345487499567           loss:62708.875\u001b[0m\n",
      "\u001b[34mlr_value:4.4810124111514416           loss:65572.5390625\u001b[0m\n",
      "\u001b[34mlr_value:4.576679061656705           loss:68500.0234375\u001b[0m\n",
      "\u001b[34mlr_value:4.674388131860712           loss:71503.609375\u001b[0m\n",
      "\u001b[34mlr_value:4.774183226072852           loss:74604.578125\u001b[0m\n",
      "\u001b[34mlr_value:4.87610887952567           loss:77866.2421875\u001b[0m\n",
      "\u001b[34mlr_value:4.980210578249438           loss:81053.4140625\u001b[0m\n",
      "\u001b[34mlr_value:5.086534779371106           loss:84497.7421875\u001b[0m\n",
      "\u001b[34mlr_value:5.195128931846556           loss:87726.515625\u001b[0m\n",
      "\u001b[34mlr_value:5.306041497635452           loss:91427.59375\u001b[0m\n",
      "\u001b[34mlr_value:5.419321973328272           loss:94929.0078125\u001b[0m\n",
      "\u001b[34mlr_value:5.535020912234954           loss:98857.6015625\u001b[0m\n",
      "\u001b[34mlr_value:5.653189946945123           loss:103254.5078125\u001b[0m\n",
      "\u001b[34mlr_value:5.773881812370071           loss:108199.234375\u001b[0m\n",
      "\u001b[34mlr_value:5.8971503692765594           loss:113037.90625\u001b[0m\n",
      "\u001b[34mlr_value:6.023050628323051           loss:118402.7734375\u001b[0m\n",
      "\u001b[34mlr_value:6.151638774609209           loss:123767.4140625\u001b[0m\n",
      "\u001b[34mlr_value:6.282972192749407           loss:129288.6171875\u001b[0m\n",
      "\u001b[34mlr_value:6.41710949248153           loss:134692.640625\u001b[0m\n",
      "\u001b[34mlr_value:6.554110534822636           loss:140382.0\u001b[0m\n",
      "\u001b[34mlr_value:6.694036458782878           loss:146067.515625\u001b[0m\n",
      "\u001b[34mlr_value:6.836949708649846           loss:151777.9375\u001b[0m\n",
      "\u001b[34mlr_value:6.982914061855316           loss:157700.796875\u001b[0m\n",
      "\u001b[34mlr_value:7.1319946574370805           loss:164245.296875\u001b[0m\n",
      "\u001b[34mlr_value:7.284258025108297           loss:170733.328125\u001b[0m\n",
      "\u001b[34mlr_value:7.439772114947442           loss:177597.109375\u001b[0m\n",
      "\u001b[34mlr_value:7.598606327722256           loss:183969.21875\u001b[0m\n",
      "\u001b[34mlr_value:7.760831545860961           loss:190997.265625\u001b[0m\n",
      "\u001b[34mlr_value:7.92652016508468           loss:198968.9375\u001b[0m\n",
      "\u001b[34mlr_value:8.095746126715335           loss:207846.109375\u001b[0m\n",
      "\u001b[34mlr_value:8.268584950673157           loss:217460.453125\u001b[0m\n",
      "\u001b[34mlr_value:8.445113769178658           loss:227369.28125\u001b[0m\n",
      "\u001b[34mlr_value:8.625411361174285           loss:237673.234375\u001b[0m\n",
      "\u001b[34mlr_value:8.80955818748077           loss:249433.484375\u001b[0m\n",
      "\u001b[34mlr_value:8.997636426704155           loss:261956.203125\u001b[0m\n",
      "\u001b[34mlr_value:9.189730011909305           loss:275367.15625\u001b[0m\n",
      "\u001b[34mlr_value:9.38592466807654           loss:288663.8125\u001b[0m\n",
      "\u001b[34mlr_value:9.586307950357803           loss:305558.78125\u001b[0m\n",
      "\u001b[34mlr_value:9.79096928314955           loss:322812.5625\u001b[0m\n",
      "\u001b[34mlr_value:10.0           loss:327108.625\u001b[0m\n",
      "\u001b[34m2022-01-11 13:16:22.404899: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-01-11 13:16:22.405023: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2022-01-11 13:16:22.437961: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2022-01-11 13:21:31,911 sagemaker_tensorflow_container.training WARNING  No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[34mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[34mhttps://sagemaker.readthedocs.io/en/stable/using_tf.html#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\u001b[34m2022-01-11 13:21:31,911 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-01-11 13:21:37 Uploading - Uploading generated training model\n",
      "2022-01-11 13:21:37 Completed - Training job completed\n",
      "Training seconds: 396\n",
      "Billable seconds: 396\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "dataframe_dir = f's3://obstacles-classification/{train_dataset_name}'\n",
    "\n",
    "hyperparams={'batch-size'   : 16,\n",
    "             'optimizer'    : 'adam',\n",
    "             'dataframe_dir': dataframe_dir}\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "output_path = f's3://{bucket_name}/obstacles_classification/jobs/{train_dataset_name}'\n",
    "\n",
    "metric_definitions = [\n",
    "    {'Name': 'auc', 'Regex': 'auc: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'recall', 'Regex': 'recall: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'specifity', 'Regex': 'specifity: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'accuracy', 'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'validation auc', 'Regex': 'val_auc: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'validation recall', 'Regex': 'val_recall: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'validation specifity', 'Regex': 'val_specifity: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'validation accuracy', 'Regex': 'val_categorical_accuracy: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'validation loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'test auc', 'Regex': 'test_auc: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'test recall', 'Regex': 'test_recall: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'test specifity', 'Regex': 'test_specifity: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'test accuracy', 'Regex': 'test_accuracy: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'test loss', 'Regex': 'test_loss: ([0-9\\\\.]+)'},\n",
    "    {'Name': 'epoch', 'Regex': 'Epoch ([0-9]+)'},\n",
    "]\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point          = '7_channels_weights_lrrt.py', \n",
    "                          output_path          = f'{output_path}/',\n",
    "                          code_location        = output_path,\n",
    "                          role                 = role,\n",
    "                          train_instance_count = 1, \n",
    "                          train_instance_type  = 'ml.c5.xlarge',\n",
    "                          framework_version    = '2.3', \n",
    "                          py_version           = 'py37',\n",
    "                          script_mode          = True,\n",
    "                          metric_definitions   = metric_definitions,\n",
    "                          debugger_hook_config = False,\n",
    "                          sagemaker_session    = sagemaker_session,\n",
    "                          hyperparameters      = hyperparams)\n",
    "\n",
    "job_name=f'obstacles-classification-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())}'\n",
    "training_dataset = f's3://obstacles-classification/{train_dataset_name}/train'\n",
    "tf_estimator.fit({'training'  : training_dataset},\n",
    "                  job_name = job_name,\n",
    "                  experiment_config=experiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
