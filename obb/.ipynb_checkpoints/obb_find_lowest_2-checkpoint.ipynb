{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import heapq\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lowest = 60\n",
    "fp_threshold = 0.86\n",
    "fn_threshold = 0.83\n",
    "scores_file_path = './overlap_scores.txt'\n",
    "labels_dir = './labels'\n",
    "src_dir = './images'\n",
    "dst_dir = './lowest'\n",
    "score_param_names = ['class', 'iou', 'confidence']\n",
    "vertices = [f'v{i}' for i in range(1, 9)]\n",
    "score_param_names.extend(vertices)\n",
    "label_param_names = [v for v in vertices]\n",
    "label_param_names.extend(['class'])\n",
    "blacks = defaultdict(int) # 'blacks' are negative scores\n",
    "gap = defaultdict(int)\n",
    "clserr = defaultdict(int)\n",
    "fp = defaultdict(int)\n",
    "fn = defaultdict(int)\n",
    "image_scores = defaultdict(list)\n",
    "image_labels = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function to display an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img, title):\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function to calculate the IOU of 2 oriented bounding boxes (courtesy ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou(box1, box2):\n",
    "    im = np.zeros((1500, 1500), dtype=np.uint8)\n",
    "    im1 = np.zeros((1500, 1500), dtype=np.uint8)\n",
    "    im2 = np.zeros((1500, 1500), dtype=np.uint8)\n",
    "\n",
    "    cv2.fillPoly(im, [box1], 255)\n",
    "    cv2.fillPoly(im, [box2], 255)\n",
    "    uarea = cv2.countNonZero(im)\n",
    "\n",
    "    cv2.fillPoly(im1, [box1], 255)\n",
    "    cv2.fillPoly(im2, [box2], 255)\n",
    "    intersection = cv2.bitwise_and(im1, im2)\n",
    "    iarea = cv2.countNonZero(intersection)\n",
    "\n",
    "    return iarea/uarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dict with scores of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(scores_file_path, 'r') as scores_file:\n",
    "    for scores in scores_file:\n",
    "        score_params = {}\n",
    "        vals = scores.strip().split(' ')\n",
    "        for i, p in enumerate(vals[1:]):\n",
    "            score_params[score_param_names[i]] = p\n",
    "        image_scores[vals[0]].append(score_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dict with labels of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_fnames = os.listdir(labels_dir) \n",
    "for im_fname in im_fnames:\n",
    "    imname = im_fname.split('.')[0]\n",
    "    label_file_name = os.path.join(labels_dir, im_fname)\n",
    "    with open(label_file_name, 'r') as labels_file:\n",
    "        for labels in labels_file:\n",
    "            label_params = {}\n",
    "            vals = labels.strip().split(' ')\n",
    "            for i, p in enumerate(vals[:9]):\n",
    "                label_params[label_param_names[i]] = p\n",
    "            image_labels[imname].append(label_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate black-points of every image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 604/604 [00:45<00:00, 13.32it/s]\n"
     ]
    }
   ],
   "source": [
    "imnames = list(image_scores.keys())\n",
    "\n",
    "for imname in tqdm(imnames):\n",
    "    # Assign a black_points for the difference in no. of found objects\n",
    "    score_objects = len(image_scores[imname])\n",
    "    label_objects = len(image_labels[imname])\n",
    "    blacks[imname] += abs(score_objects - label_objects)\n",
    "    gap[imname] += abs(score_objects - label_objects)\n",
    "\n",
    "    # Find most ovelapping obb's, to add black-points if their \n",
    "    # iou and confidence are'nt aligned\n",
    "    match_heap = []\n",
    "    for i, score_object in enumerate(image_scores[imname]):\n",
    "        max_iou = 0.\n",
    "        max_j = -1\n",
    "        for j, label_object in enumerate(image_labels[imname]):\n",
    "            score_vertices = [int(float(image_scores[imname][i][f'v{j}'])) for j in range(1, 9)]\n",
    "            label_vertices = [int(image_labels[imname][j][f'v{k}']) for k in range(1, 9)]\n",
    "            box1 = [[score_vertices[k], score_vertices[k+1]] for k in range(0, 8, 2)]\n",
    "            box2 = [[label_vertices[k], label_vertices[k+1]] for k in range(0, 8, 2)]\n",
    "            box1 = np.array(box1)\n",
    "            box2 = np.array(box2)\n",
    "            box1 = box1.reshape(-1, 1, 2)\n",
    "            box2 = box2.reshape(-1, 1, 2)\n",
    "            iou = calc_iou(box1, box2) \n",
    "            if iou > max_iou:\n",
    "                max_iou = iou\n",
    "                max_j = j\n",
    "        heapq.heappush(match_heap, [max_iou, i, max_j])\n",
    "    matching = heapq.nlargest(label_objects, match_heap)\n",
    "    \n",
    "    # Add black-points for matching objects with mis-aligned classes or iou/confidence\n",
    "    for m in matching:\n",
    "        i = m[1]\n",
    "        j = m[2]\n",
    "        \n",
    "        # Add a black point if the class of the scored object is different than\n",
    "        # the class of the matching labeled object\n",
    "        if image_scores[imname][i]['class'] != image_labels[imname][j]['class']:\n",
    "            blacks[imname] += 1\n",
    "            clserr[imname] += 1\n",
    "\n",
    "        # Add a black point for a matching object in case confidence < fp_threshold and iou > 0.5\n",
    "        if float(image_scores[imname][i]['confidence']) < fp_threshold and float(image_scores[imname][i]['iou']) > 0.5:\n",
    "            blacks[imname] += 1\n",
    "            fp[imname] += 1\n",
    "\n",
    "        # Add a black point for a matching object in case confidence > fn_threshold and iou < 0.5\n",
    "        if float(image_scores[imname][i]['confidence']) > fn_threshold and float(image_scores[imname][i]['iou']) < 0.5:\n",
    "            blacks[imname] += 1\n",
    "            fn[imname] += 1            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a list of lowest-performing (= highest black-points scoring) images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_score = list(blacks.items())\n",
    "sorted_by_score.sort(key=lambda x:x[1], reverse=True)\n",
    "lowest = sorted_by_score[:num_lowest]\n",
    "lowest = [l for l in lowest if l[1] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw label & score bboxes/classes on image and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/52 [00:00<00:09,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_objects: 6\n",
      "i: 0, object_info: person 1.0\n",
      "score_objects: 6\n",
      "i: 1, object_info: person 0.9\n",
      "score_objects: 6\n",
      "i: 2, object_info: pallet 1.0\n",
      "score_objects: 6\n",
      "i: 3, object_info: forklift 1.0\n",
      "score_objects: 6\n",
      "i: 4, object_info: forklift 1.0\n",
      "score_objects: 6\n",
      "i: 5, object_info: forklift 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:03<00:00, 14.86it/s]\n"
     ]
    }
   ],
   "source": [
    "debug_image = 'v4_frame_000669'\n",
    "imnames = [l[0] for l in lowest]\n",
    "\n",
    "for imname in tqdm(imnames):\n",
    "    label_objects = len(image_labels[imname])\n",
    "    score_objects = len(image_scores[imname])\n",
    "    fname = f'{imname}.png'\n",
    "    img = cv2.imread(os.path.join(src_dir, fname))\n",
    "\n",
    "    for i in range(label_objects):\n",
    "        x1 = int(image_labels[imname][i]['v1'])\n",
    "        y1 = int(image_labels[imname][i]['v2'])\n",
    "        x2 = int(image_labels[imname][i]['v3'])\n",
    "        y2 = int(image_labels[imname][i]['v4'])\n",
    "        x3 = int(image_labels[imname][i]['v5'])\n",
    "        y3 = int(image_labels[imname][i]['v6'])\n",
    "        x4 = int(image_labels[imname][i]['v7'])\n",
    "        y4 = int(image_labels[imname][i]['v8'])\n",
    "\n",
    "        pts = [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]\n",
    "        pts = np.array(pts, dtype=np.int32)\n",
    "        _ = cv2.polylines(img, [pts], True, (0, 255, 0), 2)\n",
    "        object_name = image_labels[imname][i]['class']\n",
    "        x = int((x1 + x2 + x3 + x4) / 4)\n",
    "        y = int((y1 + y2 + y3 + y4) / 4) + 30\n",
    "        _ = cv2.putText(img, object_name, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "\n",
    "    for i in range(score_objects):\n",
    "        if imname == debug_image:\n",
    "            print(f'score_objects: {score_objects}')\n",
    "        x1 = float(image_scores[imname][i]['v1'])\n",
    "        y1 = float(image_scores[imname][i]['v2'])\n",
    "        x2 = float(image_scores[imname][i]['v3'])\n",
    "        y2 = float(image_scores[imname][i]['v4'])\n",
    "        x3 = float(image_scores[imname][i]['v5'])\n",
    "        y3 = float(image_scores[imname][i]['v6'])\n",
    "        x4 = float(image_scores[imname][i]['v7'])\n",
    "        y4 = float(image_scores[imname][i]['v8'])\n",
    "\n",
    "        pts = [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]\n",
    "        pts = np.array(pts, dtype=np.int32)\n",
    "        _ = cv2.polylines(img, [pts], True, (0, 0, 255), 2)\n",
    "        confidence = float(image_scores[imname][i][\"confidence\"])\n",
    "        object_info = f'{image_scores[imname][i][\"class\"]} {confidence:.1f}'\n",
    "        if imname == debug_image:\n",
    "            print(f'i: {i}, object_info: {object_info}')\n",
    "        x = int((x1 + x2 + x3 + x4) / 4)\n",
    "        y = int((y1 + y2 + y3 + y4) / 4)\n",
    "        _ = cv2.putText(img, object_info, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        \n",
    "    dst_name = f'{imname}_{blacks[imname]}_gap_{gap[imname]}_clserr_{clserr[imname]}_fp_{fp[imname]}_fn_{fn[imname]}.png'\n",
    "    dst = os.path.join(dst_dir, dst_name)\n",
    "    cv2.imwrite(dst, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('v4_frame_000669', 2),\n",
       " ('v2_frame_005710', 2),\n",
       " ('v2_frame_004890', 2),\n",
       " ('v2_frame_004510', 2),\n",
       " ('v4_frame_000170', 1),\n",
       " ('v4_frame_000096', 1),\n",
       " ('v2_frame_003590', 1),\n",
       " ('v5_frame_000125', 1),\n",
       " ('v4_frame_000667', 1),\n",
       " ('v2_frame_000260', 1),\n",
       " ('v2_frame_003220', 1),\n",
       " ('v5_frame_000127', 1),\n",
       " ('v5_frame_000138', 1),\n",
       " ('v2_frame_003200', 1),\n",
       " ('v2_frame_003880', 1),\n",
       " ('v4_frame_000188', 1),\n",
       " ('v2_frame_002300', 1),\n",
       " ('v2_frame_003920', 1),\n",
       " ('v2_frame_004210', 1),\n",
       " ('v2_frame_000480', 1),\n",
       " ('v2_frame_004500', 1),\n",
       " ('v2_frame_004880', 1),\n",
       " ('v2_frame_004260', 1),\n",
       " ('v2_frame_004090', 1),\n",
       " ('v2_frame_004340', 1),\n",
       " ('v2_frame_001970', 1),\n",
       " ('v2_frame_005120', 1),\n",
       " ('v1_frame_000243', 1),\n",
       " ('v2_frame_000000', 1),\n",
       " ('v2_frame_000130', 1),\n",
       " ('v2_frame_004740', 1),\n",
       " ('v2_frame_004820', 1),\n",
       " ('v2_frame_004750', 1),\n",
       " ('v2_frame_005660', 1),\n",
       " ('v2_frame_002710', 1),\n",
       " ('v2_frame_004240', 1),\n",
       " ('v2_frame_004560', 1),\n",
       " ('v2_frame_004520', 1),\n",
       " ('v2_frame_005020', 1),\n",
       " ('v2_frame_004720', 1),\n",
       " ('v1_frame_000447', 1),\n",
       " ('v1_frame_000426', 1),\n",
       " ('v1_frame_000448', 1),\n",
       " ('v1_frame_000235', 1),\n",
       " ('v1_frame_000441', 1),\n",
       " ('v1_frame_000363', 1),\n",
       " ('v2_frame_006540', 1),\n",
       " ('v1_frame_000431', 1),\n",
       " ('v1_frame_000444', 1),\n",
       " ('v1_frame_000437', 1),\n",
       " ('v1_frame_000369', 1),\n",
       " ('v1_frame_001395', 1)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine all iou's, sort in ascending order, map to corresponding confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious_dict = {}\n",
    "\n",
    "for image_score in image_scores:\n",
    "    for score in image_scores[image_score]:\n",
    "        ious_dict[float(score['iou'])] = float(score['confidence'])\n",
    "        \n",
    "sorted_ious_dict = sorted(ious_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = [f for f in fn.keys() if fn[f] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v2_frame_003220',\n",
       " 'v2_frame_002300',\n",
       " 'v2_frame_001970',\n",
       " 'v1_frame_000243',\n",
       " 'v2_frame_004890']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = [f for f in fp.keys() if fp[f] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v5_frame_000125', 'v5_frame_000127', 'v2_frame_005710']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': 'person',\n",
       "  'iou': '0.9604',\n",
       "  'confidence': '1.0000',\n",
       "  'v1': '692.65',\n",
       "  'v2': '379.95',\n",
       "  'v3': '723.50',\n",
       "  'v4': '441.59',\n",
       "  'v5': '652.57',\n",
       "  'v6': '477.0',\n",
       "  'v7': '621.72',\n",
       "  'v8': '415.44'},\n",
       " {'class': 'pallet',\n",
       "  'iou': '0.9359',\n",
       "  'confidence': '0.9995',\n",
       "  'v1': '1198.6',\n",
       "  'v2': '185.11',\n",
       "  'v3': '1182.3',\n",
       "  'v4': '337.18',\n",
       "  'v5': '958.47',\n",
       "  'v6': '313.25',\n",
       "  'v7': '974.72',\n",
       "  'v8': '161.18'},\n",
       " {'class': 'forklift',\n",
       "  'iou': '0.9167',\n",
       "  'confidence': '1.0000',\n",
       "  'v1': '578.40',\n",
       "  'v2': '258.36',\n",
       "  'v3': '650.72',\n",
       "  'v4': '428.32',\n",
       "  'v5': '548.15',\n",
       "  'v6': '471.96',\n",
       "  'v7': '475.8',\n",
       "  'v8': '302.00'},\n",
       " {'class': 'forklift',\n",
       "  'iou': '0.8200',\n",
       "  'confidence': '0.8202',\n",
       "  'v1': '1238.32',\n",
       "  'v2': '250.94',\n",
       "  'v3': '1231.26',\n",
       "  'v4': '319.08',\n",
       "  'v5': '984.22',\n",
       "  'v6': '293.48',\n",
       "  'v7': '991.2',\n",
       "  'v8': '225.34'}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_scores['v5_frame_000125']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
