{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\r\n",
      "Version: 2.5.1\r\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\r\n",
      "Home-page: https://www.tensorflow.org/\r\n",
      "Author: Google Inc.\r\n",
      "Author-email: packages@tensorflow.org\r\n",
      "License: Apache 2.0\r\n",
      "Location: /home/drevital/anaconda3/lib/python3.7/site-packages\r\n",
      "Requires: tensorflow-estimator, protobuf, opt-einsum, wheel, termcolor, google-pasta, flatbuffers, keras-nightly, absl-py, astunparse, wrapt, tensorboard, h5py, keras-preprocessing, six, numpy, gast, grpcio, typing-extensions\r\n",
      "Required-by: tensorflow-serving-api\r\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: numpy\r\n",
      "Version: 1.19.5\r\n",
      "Summary: NumPy is the fundamental package for array computing with Python.\r\n",
      "Home-page: https://www.numpy.org\r\n",
      "Author: Travis E. Oliphant et al.\r\n",
      "Author-email: None\r\n",
      "License: BSD\r\n",
      "Location: /home/drevital/anaconda3/lib/python3.7/site-packages\r\n",
      "Requires: \r\n",
      "Required-by: keras-retinanet, tensorflow, tensorflow-hub, tensorflow-gpu, tensorboard, tables, statsmodels, seaborn, scipy, scikit-learn, sagemaker, PyWavelets, pytest-arraydiff, patsy, pandas, opt-einsum, opencv-python, opencv-contrib-python, numexpr, numba, mkl-random, mkl-fft, matplotlib, Keras-Preprocessing, Keras-Applications, imgaug, imageio, ImageHash, imageai, h5py, gym, cupy, cupy-cuda111, chainer, Bottleneck, bokeh, bkcharts, astropy\r\n"
     ]
    }
   ],
   "source": [
    "!pip show numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "import os\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=600,\n",
    "                 img_height=200,\n",
    "                 batch_size=32,\n",
    "                 thresh_csv_fname=None,\n",
    "                 metrics_csv_fname=None):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.obstacle_images = []\n",
    "        self.no_obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_obstacles = 0\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen()\n",
    "        \n",
    "        self.model_score = ModelScore()\n",
    "\n",
    "        if thresh_csv_fname:\n",
    "            thresh_csv_path = os.path.join(model_path, thresh_csv_fname)\n",
    "            self.f_thresh_csv = open(thresh_csv_path, 'w')\n",
    "            self.thresh_csv_writer = csv.writer(self.f_thresh_csv)\n",
    "            \n",
    "            self.thresh_csv_header = ['model',\n",
    "                                      'dataset',\n",
    "                                      'Max Lost Ratio',\n",
    "                                      'Lower Threshold',\n",
    "                                      'Upper Threshold',\n",
    "                                      'Total Predictions',\n",
    "                                      'TP',\n",
    "                                      '% TP',\n",
    "                                      'TN',\n",
    "                                      '% TN',\n",
    "                                      'FP',\n",
    "                                      '% FP',\n",
    "                                      'FN',\n",
    "                                      '% FN',\n",
    "                                      'Not Decided',\n",
    "                                      '% Not Decided',\n",
    "                                      'True Not Decided',\n",
    "                                      '% True Not Decided']\n",
    "            \n",
    "            self.thresh_csv_writer.writerow(self.thresh_csv_header)\n",
    "            \n",
    "        if metrics_csv_fname:\n",
    "            metrics_csv_path = os.path.join(model_path, metrics_csv_fname)\n",
    "            self.f_metrics_csv = open(metrics_csv_path, 'w')\n",
    "            self.metrics_csv_writer = csv.writer(self.f_metrics_csv)\n",
    "\n",
    "            metrics_prefixes = ['test', 'validation', '']\n",
    "            metrics_separators = [' ', ' ', '']\n",
    "            metrics_functions = ['auc', 'recall', 'specifity']\n",
    "            \n",
    "            self.metrics_csv_header = ['Trial Name']\n",
    "            self.metrics_csv_header.append('Model Score')\n",
    "            self.metrics_csv_header.append('Lost True Values %')\n",
    "            self.metrics_csv_header.append('Lower Threshold')\n",
    "            self.metrics_csv_header.append('Upper Threshold')\n",
    "            self.metrics_csv_header.append('% FP')\n",
    "            self.metrics_csv_header.append('% FN')\n",
    "            \n",
    "            for i, metrics_prefix in enumerate(metrics_prefixes):\n",
    "                for metrics_function in metrics_functions:\n",
    "                    metric_name = metrics_separators[i].join([metrics_prefix, metrics_function])\n",
    "                    self.metrics_csv_header.append('max ' + metric_name)\n",
    "            \n",
    "            self.metrics_csv_writer.writerow(self.metrics_csv_header)        \n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self):\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    "\n",
    "    # Special generator to generate the 3 parts of the input image as 3 separate input images\n",
    "    def three_im_generator(self, gen, dataset, target_size, batch_size, class_mode):\n",
    "\n",
    "        im_gen = gen.flow_from_directory(dataset, \n",
    "                                         target_size=target_size, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         color_mode='grayscale',\n",
    "                                         class_mode=class_mode)\n",
    "        self.filenames = im_gen.filenames\n",
    "\n",
    "        while True:\n",
    "            im1_s, im2_s, im3_s = [], [], []\n",
    "            images, labels = im_gen.next()\n",
    "\n",
    "            for im in images:\n",
    "                w = im.shape[1]\n",
    "                im1 = im[:, :w//3]\n",
    "                im2 = im[:, w//3:(w*2)//3] \n",
    "                im3 = im[:, (w*2)//3:] \n",
    "                im1_s.append(im1)\n",
    "                im2_s.append(im2)\n",
    "                im3_s.append(im3)\n",
    "\n",
    "            im1_s = np.array(im1_s)\n",
    "            im2_s = np.array(im2_s)\n",
    "            im3_s = np.array(im3_s)\n",
    "            yield [im1_s, im2_s, im3_s], labels\n",
    "            \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = self.three_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        \n",
    "    # Compute and plot multi-class confusion-matrix, with given threshold values\n",
    "    def plot_cm_with_thresh(self,\n",
    "                            model_path,\n",
    "                            labels,\n",
    "                            predictions,\n",
    "                            predicted_classes,\n",
    "                            lower_thresh,\n",
    "                            upper_thresh):\n",
    "        \n",
    "        # Calculate number of values for each <class vs. class> considering the thresholds\n",
    "        \n",
    "        noobs_as_noobs = len([p for p in predicted_classes[:self.num_no_obstacles] if p==0])        \n",
    "        noobs_as_obs = len([p for p in predicted_classes[:self.num_no_obstacles] if p==1])\n",
    "        obs_as_noobs = len([p for p in predicted_classes[self.num_no_obstacles:] if p==0])\n",
    "        obs_as_obs = len([p for p in predicted_classes[self.num_no_obstacles:] if p==1])\n",
    "        noobs_as_undecided = len([p for p in predicted_classes[:self.num_no_obstacles] if p==2])        \n",
    "        obs_as_undecided = len([p for p in predicted_classes[self.num_no_obstacles:] if p==2])\n",
    "        \n",
    "        cm = [[noobs_as_noobs, noobs_as_obs, noobs_as_undecided],\n",
    "             [obs_as_noobs, obs_as_obs, obs_as_undecided]]\n",
    "        \n",
    "        print(f'cm: {cm}')\n",
    "        \n",
    "        # Creating a dataframe for a array-formatted Confusion matrix\n",
    "        cm_df = pd.DataFrame(cm,\n",
    "                             index = ['NO_OBSTACLE', 'OBSTACLE'], \n",
    "                             columns = ['NO_OBSTACLE', 'OBSTACLE', 'NOT_DECIDED'])\n",
    "        \n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.heatmap(cm_df, annot=True, fmt='d')\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label')        \n",
    "        \n",
    "    # Compute and plot confusion-matrix (TP, FP, TN, FN)\n",
    "    def calc_cm(self,\n",
    "                model_path,\n",
    "                labels,\n",
    "                predictions,\n",
    "                p=0.5,\n",
    "                max_lost_ratio=0,\n",
    "                not_decided=0,\n",
    "                trues=0,\n",
    "                true_not_decided=0,\n",
    "                lower_threshold=None,\n",
    "                upper_threshold=None,\n",
    "                print_params=True,\n",
    "                print_to_csv=False):\n",
    "\n",
    "        cm = confusion_matrix(labels, predictions > p)        \n",
    "\n",
    "        predicts = sum(sum(x) for x in cm)\n",
    "        tot_predicts = predicts + not_decided\n",
    "        \n",
    "        TN = cm[0][0]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "        TP = cm[1][1]\n",
    "        \n",
    "        TN_percent = (TN/tot_predicts)*100\n",
    "        FP_percent = (FP/tot_predicts)*100\n",
    "        FN_percent = (FN/tot_predicts)*100\n",
    "        TP_percent = (TP/tot_predicts)*100\n",
    "        not_decided_percent = (not_decided/tot_predicts)*100\n",
    "        true_not_decided_percent = (true_not_decided/trues)*100\n",
    "\n",
    "        if print_params:\n",
    "            print()\n",
    "            if max_lost_ratio:\n",
    "                print(f'Max Lost Ratio: {max_lost_ratio}')\n",
    "            print(f'No Obstacles Detected (True Negatives): {TN} ({TN_percent:.2f}%)')\n",
    "            print(f'No Obstacles Incorrectly Detected (False Positives): {FP} ({FP_percent:.2f}%)')\n",
    "            print(f'Obstacles Missed (False Negatives): {FN} ({FN_percent:.2f}%)')\n",
    "            print(f'Obstacles Detected (True Positives): {TP} ({TP_percent:.2f}%)')\n",
    "            if not_decided:\n",
    "                print(f'Not Decided: {not_decided} ({not_decided_percent:.2f}%)')\n",
    "            if true_not_decided:\n",
    "                print(f'True Not Decided: {true_not_decided} ({true_not_decided_percent:.2f}%)')\n",
    "            print(f'Total Obstacles: {tot_predicts}')\n",
    "        \n",
    "        self.model_score.add_model_option(true_not_decided,\n",
    "                                          true_not_decided_percent/100.0,\n",
    "                                          FP,\n",
    "                                          FP_percent/100.0,\n",
    "                                          FN,\n",
    "                                          FN_percent/100.0,\n",
    "                                          lower_threshold,\n",
    "                                          upper_threshold,\n",
    "                                          predictions=predictions)\n",
    "        \n",
    "        if print_to_csv:\n",
    "            # Prepare arguments for writing to csv\n",
    "            args = {'model': model_path,\n",
    "                    'Max Lost Ratio': max_lost_ratio,\n",
    "                    'Lower Threshold': lower_threshold,\n",
    "                    'Upper Threshold': upper_threshold,\n",
    "                    'Total Predictions': tot_predicts,\n",
    "                    'TP': TP,\n",
    "                    '% TP': TP_percent,\n",
    "                    'TN': TN,\n",
    "                    '% TN': TN_percent,\n",
    "                    'FP': FP,\n",
    "                    '% FP': FP_percent,\n",
    "                    'FN': FN,\n",
    "                    '% FN': FN_percent,\n",
    "                    'Not Decided': not_decided,\n",
    "                    '% Not Decided': not_decided_percent,\n",
    "                    'True Not Decided': true_not_decided,\n",
    "                    '% True Not Decided': true_not_decided_percent}\n",
    "            self.write_csv(**args)\n",
    "        \n",
    "        \n",
    "    # Same as above, with consideration of lower and upper threshold \n",
    "    # For values between those thresholds \"not decided\" is returned, \n",
    "    # so it lowers the no. of FP and FN\n",
    "    def calc_cm_considering_thresholds(self,\n",
    "                                       model_path,\n",
    "                                       labels,\n",
    "                                       predictions,\n",
    "                                       lower_threshold,\n",
    "                                       upper_threshold,\n",
    "                                       max_lost_ratio=0,\n",
    "                                       threshold=0.5,\n",
    "                                       print_params=True,\n",
    "                                       print_to_csv=False):\n",
    "        no_obs_preds = predictions[:self.num_no_obstacles]\n",
    "        no_obs_margin_preds = [p for p in no_obs_preds if p < lower_threshold or p > upper_threshold]\n",
    "        no_obs_margin_labels = [0]*len(no_obs_margin_preds)\n",
    "        true_no_obs_preds = [p for p in no_obs_preds if p <= 0.5]\n",
    "        true_no_obs_not_decided_preds = [p for p in no_obs_preds if lower_threshold < p <= 0.5]\n",
    "        obs_preds = predictions[self.num_no_obstacles:]\n",
    "        obs_margin_preds = [p for p in obs_preds if p < lower_threshold or p > upper_threshold]\n",
    "        obs_margin_labels = [1]*len(obs_margin_preds)\n",
    "        true_obs_preds = [p for p in obs_preds if p >= 0.5]\n",
    "        true_obs_not_decided_preds = [p for p in obs_preds if upper_threshold > p >= 0.5]\n",
    "        margin_preds = no_obs_margin_preds + obs_margin_preds\n",
    "        margin_preds = np.array(margin_preds, dtype=float)\n",
    "        true_preds = true_no_obs_preds + true_obs_preds\n",
    "        true_not_decided_preds = true_no_obs_not_decided_preds + true_obs_not_decided_preds\n",
    "        margin_labels = no_obs_margin_labels + obs_margin_labels\n",
    "        margin_labels = np.array(margin_labels, dtype=float)\n",
    "        not_decided = len(predictions) - len(margin_preds)\n",
    "        trues = len(true_preds)\n",
    "        true_not_decided = len(true_not_decided_preds)\n",
    "\n",
    "        self.calc_cm(model_path,\n",
    "                     margin_labels,\n",
    "                     margin_preds,\n",
    "                     max_lost_ratio=max_lost_ratio,\n",
    "                     not_decided=not_decided,\n",
    "                     trues=trues,\n",
    "                     true_not_decided=true_not_decided,\n",
    "                     lower_threshold=lower_threshold,\n",
    "                     upper_threshold=upper_threshold,\n",
    "                     print_params=print_params,\n",
    "                     print_to_csv=print_to_csv)\n",
    "            \n",
    "    def display_false_negatives(self, predictions, lower_threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] < lower_threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p < threshold]\n",
    "\n",
    "        if 500 > len(false_negatives) > 1:\n",
    "            num_images = len(false_negatives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_negatives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_negatives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show() \n",
    "            \n",
    "    def display_false_positives(self, predictions, upper_threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > upper_threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > upper_threshold]\n",
    "\n",
    "        if 500 > len(false_positives) > 1:\n",
    "            num_images = len(false_positives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_positives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                print(f'FP prediction: {preds[i]}, imname: {imname}')\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_positives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show()\n",
    "            \n",
    "    def display_not_decided(self, predcitions, filenames, lower_threshold, upper_threshold):\n",
    "        obstacle_image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        no_obstacle_image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        obs_title = ''\n",
    "        \n",
    "        not_decided = [fname for i, fname in enumerate(filenames)\\\n",
    "                       if ((lower_threshold < predictions[i] <= 0.5)\\\n",
    "                           and (fname.split('/')[-1] in no_obstacle_image_names))\\\n",
    "                           or ((0.5 <= predictions[i] < upper_threshold)\\\n",
    "                           and (fname.split('/')[-1] in obstacle_image_names))]\n",
    "        \n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                       if ((lower_threshold < p <= 0.5)\\\n",
    "                           and (filenames[i].split('/')[-1] in no_obstacle_image_names))\\\n",
    "                           or ((0.5 <= p < upper_threshold)\\\n",
    "                           and (filenames[i].split('/')[-1] in obstacle_image_names))]\n",
    "\n",
    "        if 500 > len(not_decided) > 1:\n",
    "            num_images = len(not_decided)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(1.5*num_images, 1.5*num_images))\n",
    "\n",
    "            for i, fname in enumerate(not_decided):\n",
    "                imname = fname.split('/')[-1]\n",
    "                if imname in obstacle_image_names:\n",
    "                    impath = os.path.join(self.obstacle_dataset, imname)\n",
    "                    obs_title = 'obs'\n",
    "                else:\n",
    "                    impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "                    obs_title = 'no_obs'\n",
    "                im = cv2.imread(impath)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(' '.join([imname, obs_title, str(preds[i]), (' '*30)]))\n",
    "            plt.show()\n",
    "        elif not_decided:\n",
    "            imname = not_decided[0].split('/')[-1]\n",
    "            if imname in obstacle_image_names:\n",
    "                impath = os.path.join(self.obstacle_dataset, imname)\n",
    "                obs_title = 'obs'\n",
    "            else:\n",
    "                impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "                obs_title = 'no_obs'\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(' '.join([imname, obs_title, str(preds[0])]))\n",
    "            plt.show()\n",
    "\n",
    "    # An algorithm for optimal threshold taken from \n",
    "    # https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
    "    # left here on case we consider re-using it.\n",
    "    # Currently we are using the 2nd algorithm below\n",
    "    def optimal_threshold_by_gmeans(self, num_no_obstacles, num_obstacles, predictions):\n",
    "        true_values = [0]*num_no_obstacles + [1]*num_obstacles \n",
    "        fpr, tpr, thresholds = roc_curve(true_values, predictions)\n",
    "        gmeans = sqrt(tpr * (1-fpr))\n",
    "        ix = argmax(gmeans)\n",
    "\n",
    "        return thresholds[ix]    \n",
    " \n",
    "    # 2nd algorithm for finding optimal threshold, own developed\n",
    "    # Currently used\n",
    "    # Params: \n",
    "    #    -- predictions - a list of predicted values for no_obstacle / obstacle\n",
    "    #    -- max_lost_ratio - a float [0.0-1.0], indicating the target maximum ratio (%/100)\n",
    "    #    of (\"not decided\" / all) true values, for TP and TN - this is to avoid putting extreme \n",
    "    #    low/high thresholds, which will lower FN/FP, but will leave too few True values returned.\n",
    "    #    This ratio (\"not_decided\" / all) is called here \"lost ratio\"\n",
    "    # Steps:\n",
    "    # 1. Set as (min_thresold / max_thresold) ==> (min(FN) / max(FP))\n",
    "    #       Using this will perform with 0 FN/FP, \n",
    "    #       as there are neither FN below lower_thresold, not FP above upper_threshold,\n",
    "    #       but --potentially-- with too many \"not decided\"\n",
    "    # 2. If the lost ratio is too high - start lowering it to the target, using binary search\n",
    "    #       to find the point where the ratio does not exceed the maximum lost-ration,\n",
    "    #       while keeping the lower/upper thresholds as close as possible to their \n",
    "    #       original values. \n",
    "    def find_thresholds(self, predictions, max_lost_ratio=0.1, base_threshold=0.5):\n",
    "        no_obs_preds = predictions[:handler.num_no_obstacles]\n",
    "        obs_preds = predictions[handler.num_no_obstacles:]\n",
    "        false_positives = np.array([p for p in no_obs_preds if p >= base_threshold])\n",
    "        false_negatives = np.array([p for p in obs_preds if p < base_threshold])\n",
    "        true_positives = np.array([p for p in obs_preds if p >= base_threshold])\n",
    "        true_negatives = np.array([p for p in no_obs_preds if p < base_threshold])\n",
    "        false_positives.sort(axis=0) \n",
    "        false_negatives.sort(axis=0)\n",
    "        true_positives.sort(axis=0)\n",
    "        true_negatives.sort(axis=0)\n",
    "\n",
    "        true_positives_above = np.array([p for p in true_positives if p > max(false_positives)])\n",
    "        true_negatives_below = np.array([p for p in true_negatives if p < min(false_negatives)])\n",
    "        lost_true_positives = np.array([p for p in true_positives if p <= max(false_positives)])\n",
    "        true_positives_lost_ratio = len(lost_true_positives) / len(true_positives)\n",
    "        lost_true_negatives = np.array([p for p in true_negatives if p >= min(false_negatives)])\n",
    "        true_negatives_lost_ratio = len(lost_true_negatives) / len(true_negatives)\n",
    "\n",
    "        lower_threshold = min(false_negatives)\n",
    "        lower_threshold_ind = np.where(true_negatives > lower_threshold)[0][0]\n",
    "        num_true_negatives = len(true_negatives)\n",
    "        gap = num_true_negatives - lower_threshold_ind\n",
    "        \n",
    "        # Binary search to find the point where no. of \"not decided\" satisfies the target\n",
    "\n",
    "        if true_negatives_lost_ratio > max_lost_ratio:\n",
    "            while gap:\n",
    "                lost_ratio_diff = true_negatives_lost_ratio - max_lost_ratio\n",
    "                if abs(lost_ratio_diff) < 0.01:\n",
    "                    break\n",
    "                gap //= 2\n",
    "                if lost_ratio_diff < 0.0:\n",
    "                    lower_threshold_ind -= gap\n",
    "                else:\n",
    "                    lower_threshold_ind += gap\n",
    "                lost_true_negatives = true_negatives[lower_threshold_ind:]\n",
    "                true_negatives_lost_ratio = len(lost_true_negatives) / num_true_negatives\n",
    "\n",
    "            lower_threshold = true_negatives[lower_threshold_ind] \n",
    "            \n",
    "        upper_threshold = max(false_positives)\n",
    "        upper_threshold_ind = np.where(true_positives > upper_threshold)[0][0]\n",
    "        num_true_positives = len(true_positives)\n",
    "        gap = upper_threshold_ind\n",
    "\n",
    "        # Binary search to find the point where no. of \"not decided\" satisfies the target\n",
    "        \n",
    "        if true_positives_lost_ratio > max_lost_ratio:\n",
    "            while gap:\n",
    "                lost_ratio_diff = true_positives_lost_ratio - max_lost_ratio\n",
    "                if abs(lost_ratio_diff) < 0.01:\n",
    "                    break\n",
    "                gap //= 2\n",
    "                if lost_ratio_diff < 0.0:\n",
    "                    upper_threshold_ind += gap\n",
    "                else:\n",
    "                    upper_threshold_ind -= gap\n",
    "                lost_true_positives = true_positives[:upper_threshold_ind]\n",
    "                true_positives_lost_ratio = len(lost_true_positives) / num_true_positives\n",
    "\n",
    "            upper_threshold = true_positives[upper_threshold_ind]\n",
    "            \n",
    "        return lower_threshold[0], upper_threshold[0]\n",
    "    \n",
    "    def write_metrics_to_csv(self, trial_component_display_name, print_params=True):\n",
    "        client = boto3.client('sagemaker', region_name='eu-west-1')\n",
    "        trials = client.list_trial_components()['TrialComponentSummaries']\n",
    "        trial = [t for t in trials if t['DisplayName'] == trial_component_display_name]\n",
    "        trial_description = None\n",
    "        \n",
    "        if trial:\n",
    "            trial_component_name = trial[0]['TrialComponentName']\n",
    "            trial_description = client.describe_trial_component(TrialComponentName=trial_component_name)\n",
    "\n",
    "        metrics_values = [trial_component_display_name]        \n",
    "\n",
    "        best_option = self.model_score.scored_models[self.model_score.best_option]\n",
    "        metrics_values.append(best_option['score'])\n",
    "        metrics_values.append(best_option['lost_true_values_percentage'])\n",
    "        metrics_values.append(best_option['lower_threshold'])\n",
    "        metrics_values.append(best_option['upper_threshold'])\n",
    "        metrics_values.append(best_option['false_positives_percentage'])\n",
    "        metrics_values.append(best_option['false_negatives_percentage'])\n",
    "        \n",
    "        if print_params:\n",
    "            print(f'best option: {best_option[\"lost_true_values_percentage\"]:.2f}')\n",
    "            print(f'score: {best_option[\"score\"]}')\n",
    "            print(f'lower_threshold: {best_option[\"lower_threshold\"]:.2f}')\n",
    "            print(f'upper_threshold: {best_option[\"upper_threshold\"]:.2f}')\n",
    "            print(f'%FP: {best_option[\"false_positives_percentage\"]*100:.2f}')\n",
    "            print(f'%FN: {best_option[\"false_negatives_percentage\"]*100:.2f}')\n",
    "\n",
    "        if trial_description:\n",
    "            metrics = trial_description['Metrics']\n",
    "\n",
    "            metrics_prefixes = ['test', 'validation', '']\n",
    "            metrics_separators = [' ', ' ', '']\n",
    "            metrics_functions = ['auc', 'recall', 'specifity']        \n",
    "\n",
    "            for i, metrics_prefix in enumerate(metrics_prefixes):\n",
    "                for metrics_function in metrics_functions:\n",
    "                    metric_name = metrics_separators[i].join([metrics_prefix, metrics_function])\n",
    "                    metric_value = [m for m in metrics if m['MetricName'] == metric_name]\n",
    "                    metrics_values.append(metric_value[0]['Max'])\n",
    "                                \n",
    "        self.metrics_csv_writer.writerow(metrics_values) \n",
    "\n",
    "    def write_csv(self, **args):        \n",
    "        row = []\n",
    "        keys = args.keys()\n",
    "        \n",
    "        if 'model' in keys:\n",
    "            row.append(args['model'])\n",
    "            \n",
    "        row.append(self.dataset)\n",
    "        \n",
    "        for col in self.thresh_csv_header[2:]:\n",
    "            if col in keys:\n",
    "                row.append(args[col])\n",
    "            else:\n",
    "                row.append(None)\n",
    "        \n",
    "        self.thresh_csv_writer.writerow(row)\n",
    "        \n",
    "    # Method to run when class is deleted\n",
    "    def __del__(self):\n",
    "        self.f_thresh_csv.close()\n",
    "        self.f_metrics_csv.close()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class to calculate model's score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelScore():\n",
    "    def __init__(self, alpha=0.7, beta=1.2, gamma=30):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.max_score = 0.0\n",
    "        self.scored_model_ind = 0\n",
    "        self.scored_models = []\n",
    "        \n",
    "    '''\n",
    "    Cliff shape function\n",
    "    \n",
    "    Based on the Sigmoid function:\n",
    "        1/(1 + np.exp(-x))\n",
    "\n",
    "    with:\n",
    "    1. Changing (x) to (1-x), so we flip the curve to be high near 0 and decline sharply at some point, till reaching zero\n",
    "    2. Adding alpha, beta and gamma modifiers to enable controlling the curve's attributes:\n",
    "        * alpha controls the point where the graph starts to decline sharply (= the % of lost true values which is berable and should get relatively high score for this aspect)\n",
    "        * beta controls the width of the sharply declining portion of the curve\n",
    "        * gamma controls the smoothness of the cliff-shape part of the graph. A high gamma will make the curvie less somooth, i.e. more 'cliffy'. \n",
    "\n",
    "    So our Sigmoid-modofied function is:\n",
    "\n",
    "        1/(1 + np.exp(-(1-(x+alpha)*beta)*gamma)) \n",
    "    '''\n",
    "    def cliff(self, x):\n",
    "        return 1/(1 + np.exp(-(1-(x+self.alpha)*self.beta)*self.gamma)) \n",
    "    \n",
    "    # A method to insert into overall model's scores an option, regarding \n",
    "    # the lost_true_value_percentage. \n",
    "    # The goal is that the class remembers the score attached to this option,\n",
    "    # then can compare all scores and find the best one\n",
    "    def add_model_option(self,\n",
    "                         lost_true_values,\n",
    "                         lost_true_values_percentage,\n",
    "                         false_positives,\n",
    "                         false_positives_percentage,\n",
    "                         false_negatives,\n",
    "                         false_negatives_percentage,\n",
    "                         lower_threshold,\n",
    "                         upper_threshold,\n",
    "                         predictions):\n",
    "        \n",
    "        s1 = self.cliff(lost_true_values_percentage)\n",
    "        s2 = 1.0 - (false_positives_percentage + false_negatives_percentage)\n",
    "        score = (s1 + s2) / 2\n",
    "        if score > self.max_score:\n",
    "            self.max_score = score\n",
    "            self.best_option = self.scored_model_ind\n",
    "        scored_model = {}\n",
    "        scored_model['score'] = score\n",
    "        scored_model['lost_true_values'] = lost_true_values\n",
    "        scored_model['lost_true_values_percentage'] = lost_true_values_percentage\n",
    "        scored_model['false_positives'] = false_positives\n",
    "        scored_model['false_positives_percentage'] = false_positives_percentage\n",
    "        scored_model['false_negatives'] = false_negatives\n",
    "        scored_model['false_negatives_percentage'] = false_negatives_percentage\n",
    "        scored_model['lower_threshold'] = lower_threshold\n",
    "        scored_model['upper_threshold'] = upper_threshold\n",
    "        scored_model['predictions'] = predictions\n",
    "        self.scored_models.append(scored_model)\n",
    "        self.scored_model_ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 1468 images belonging to 2 classes.\n",
      "Found 1468 images belonging to 2 classes.\n",
      "46/46 [==============================] - 14s 305ms/step\n",
      "Experimenting best max_ratio ...\n",
      "0.0050...0.0100...0.0150...0.0200...0.0250...0.0300...0.0350...0.0400...0.0450...0.0500...0.0550...0.0600...0.0650...0.0700...0.0750...0.0800...0.0850...0.0900...0.0950...0.1000...0.1050...0.1100...0.1150...0.1200...0.1250...0.1300...0.1350...0.1400...0.1450...0.1500...0.1550...0.1600...0.1650...0.1700...0.1750...0.1800...0.1850...0.1900...0.1950...0.2000...\n",
      "\n",
      "\n",
      "best option score: 0.9625938625447139\n",
      "best option lower threshold: 0.18370667099952698\n",
      "best option upper threshold: 0.6406828165054321\n",
      "best option lost true values: 85 (5.94%)\n",
      "best option false negatives: 4 (0.27%)\n",
      "best option false positives: 10 (0.68%)\n",
      "cm: [[538, 10, 93], [4, 808, 15]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Variables --\n",
    "trial_component_display_name = None\n",
    "model_path = '/home/drevital/cs_video_processor/models/humid_jan22_ggm'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/humid_jan22_ggm/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'grayscale'\n",
    "thresh_csv_fname = f'model_thresholds.{model_name}.csv'\n",
    "#metrics_csv_fname = f'model_metrics.{model_name}.csv'\n",
    "#thresh_csv_fname = None\n",
    "print_metrics = False\n",
    "metrics_csv_fname = None\n",
    "print_cm_params=False\n",
    "display_cm_figure = False\n",
    "display_false_negatives = False\n",
    "display_false_positives = False\n",
    "display_not_decided = False\n",
    "print_best_option_params=True\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, \n",
    "                         dataset, \n",
    "                         thresh_csv_fname=thresh_csv_fname,\n",
    "                         metrics_csv_fname=metrics_csv_fname)\n",
    "\n",
    "# -- Print metrics\n",
    "if print_metrics:\n",
    "    metrics = handler.print_model_metrics(model, color_mode)\n",
    "    \n",
    "# Build labels array for prediction\n",
    "labels = np.array([0]*handler.num_no_obstacles\\\n",
    "                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "# Find optimal lower, upper thresholds per given max limit of \"not decided\" (\"lost\") predictions\n",
    "max_lost_ratios = np.arange(start=0.005, stop=0.205, step=0.005)\n",
    "\n",
    "print('Experimenting best max_ratio ...')\n",
    "for max_lost_ratio in max_lost_ratios:\n",
    "    lower_threshold, upper_threshold = handler.find_thresholds(predictions,\n",
    "                                                               max_lost_ratio=max_lost_ratio,\n",
    "                                                               base_threshold=0.20)\n",
    "    print(f'{max_lost_ratio:.4f}', end='...')\n",
    "    # Print confusion-matrix after using recommended thresholds\n",
    "    handler.calc_cm_considering_thresholds(model_path,\n",
    "                                           labels,\n",
    "                                           predictions,\n",
    "                                           lower_threshold,\n",
    "                                           upper_threshold,\n",
    "                                           max_lost_ratio=max_lost_ratio,\n",
    "                                           threshold=0.5,\n",
    "                                           print_params=print_cm_params,\n",
    "                                           print_to_csv=False)\n",
    "    \n",
    "best_option = handler.model_score.scored_models[handler.model_score.best_option]\n",
    "\n",
    "print('\\n\\n')\n",
    "print(f'best option score: {best_option[\"score\"]}')\n",
    "print(f'best option lower threshold: {best_option[\"lower_threshold\"]}')\n",
    "print(f'best option upper threshold: {best_option[\"upper_threshold\"]}')\n",
    "print(f'best option lost true values: {best_option[\"lost_true_values\"]}', end = ' ')\n",
    "print(f'({best_option[\"lost_true_values_percentage\"]*100:.2f}%)')\n",
    "print(f'best option false negatives: {best_option[\"false_negatives\"]}', end=' ')\n",
    "print(f'({best_option[\"false_negatives_percentage\"]*100:.2f}%)')\n",
    "print(f'best option false positives: {best_option[\"false_positives\"]}', end=' ')\n",
    "print(f'({best_option[\"false_positives_percentage\"]*100:.2f}%)')\n",
    "\n",
    "lower_threshold = best_option['lower_threshold']\n",
    "upper_threshold = best_option['upper_threshold']\n",
    "\n",
    "# -- Generate predictions array in the for [0,1,2] for [no_obstacle, obstacle, not_decided]\n",
    "predicted_classes= []\n",
    "for prediction in predictions:\n",
    "    classification_states = [prediction <= lower_threshold,\n",
    "                             prediction >= upper_threshold,\n",
    "                             lower_threshold < prediction < upper_threshold]\n",
    "    predicted_classes.append(np.where(classification_states)[0][0])\n",
    "    \n",
    "# -- Print confusion-matrix considering the older \"no decision\" thresholds\n",
    "handler.plot_cm_with_thresh(model_path,\n",
    "                            labels,\n",
    "                            predictions,\n",
    "                            predicted_classes,\n",
    "                            lower_threshold,\n",
    "                            upper_threshold)\n",
    "\n",
    "if display_false_negatives:\n",
    "    print('\\nFALSE NEGATIVES\\n')\n",
    "    handler.display_false_negatives(predictions, filenames, lower_threshold)\n",
    "\n",
    "if display_false_positives:\n",
    "    print('\\nFALSE POSITIVES\\n')\n",
    "    handler.display_false_positives(predictions, filenames, upper_threshold)\n",
    "\n",
    "if display_not_decided:\n",
    "    print('\\nNOT DECIDED\\n')\n",
    "    handler.display_not_decided(predictions, filenames, lower_threshold, upper_threshold)\n",
    "\n",
    "print()\n",
    "    \n",
    "# Retrieve model's metrics from SageMaker and write them to the handler's .csv file\n",
    "if trial_component_display_name:\n",
    "    handler.write_metrics_to_csv(trial_component_display_name,\n",
    "                             print_params=print_best_option_params)\n",
    "del handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.005, 0.01 , 0.015, 0.02 , 0.025, 0.03 , 0.035, 0.04 , 0.045,\n",
       "       0.05 , 0.055, 0.06 , 0.065, 0.07 , 0.075, 0.08 , 0.085, 0.09 ,\n",
       "       0.095, 0.1  , 0.105, 0.11 , 0.115, 0.12 , 0.125, 0.13 , 0.135,\n",
       "       0.14 , 0.145, 0.15 , 0.155, 0.16 , 0.165, 0.17 , 0.175, 0.18 ,\n",
       "       0.185, 0.19 , 0.195, 0.2  ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_lost_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
