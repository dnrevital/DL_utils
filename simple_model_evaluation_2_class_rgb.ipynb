{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T09:05:42.307352Z",
     "iopub.status.busy": "2021-07-05T09:05:42.306996Z",
     "iopub.status.idle": "2021-07-05T09:05:42.315414Z",
     "shell.execute_reply": "2021-07-05T09:05:42.314278Z",
     "shell.execute_reply.started": "2021-07-05T09:05:42.307324Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import DirectoryIterator\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "import os\n",
    "from pathlib import Path\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes to handle dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler:\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 dataset,\n",
    "                 img_width=400,\n",
    "                 img_height=200,\n",
    "                 batch_size=32):\n",
    "        \n",
    "        self.model_path = model_path\n",
    "        self.dataset = dataset\n",
    "        self.obstacle_dataset = os.path.join(dataset, 'obstacle')\n",
    "        self.no_obstacle_dataset = os.path.join(dataset, 'no_obstacle')\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.obstacle_images = []\n",
    "        self.no_obstacle_images = []\n",
    "        self.sdv_images = []\n",
    "        self._update_image_lists = False\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "        # Will be determined while reading all images from dataset\n",
    "        self.num_obstacles = 0\n",
    "        self.num_no_obstacles = 0\n",
    "        self.num_sdvs = 0\n",
    "        self.num_images = 0\n",
    "            \n",
    "        (self.obstacle_image_names,\n",
    "        self.num_obstacles) = self._get_all_dataset_image_names(self.dataset, 'obstacle')\n",
    "        (self.no_obstacle_image_names,\n",
    "        self.num_no_obstacles) = self._get_all_dataset_image_names(self.dataset, 'no_obstacle')\n",
    "        self.datagen, self.steps = self.get_datagen(self.batch_size)\n",
    "                            \n",
    "    def _get_all_dataset_image_names(self, dataset, class_name):\n",
    "        class_dataset = os.path.join(dataset, class_name)\n",
    "        image_names = os.listdir(class_dataset)\n",
    "        image_paths = [os.path.join(class_dataset, image_name) for image_name in image_names]\n",
    "        \n",
    "        return image_paths, len(image_paths)\n",
    "            \n",
    "    def _get_image(self, imname):\n",
    "        imrgb = cv2.imread(imname)\n",
    "        im = cv2.cvtColor(imrgb, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        return im\n",
    "    \n",
    "    def get_datagen(self, batch_size):\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "        it = DirectoryIterator(self.dataset, image_data_generator=datagen, batch_size=batch_size)\n",
    "        steps= it.__len__()\n",
    "        \n",
    "        return datagen, steps\n",
    "\n",
    "    # Special generator to generate the 2 halves of the input image as 2 separate input images\n",
    "    def two_im_generator(self, gen, dataset, target_size, batch_size, class_mode):\n",
    "        im_gen = gen.flow_from_directory(dataset, \n",
    "                                         target_size=target_size, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         class_mode=class_mode)\n",
    "        self.filenames = im_gen.filenames\n",
    "\n",
    "        while True:\n",
    "            im1_s, im2_s = [], []\n",
    "            images, labels = im_gen.next()\n",
    "\n",
    "            for im in images:\n",
    "                w = im.shape[1]\n",
    "                im1 = im[:,:w//2]\n",
    "                im2 = im[:,w//2:] \n",
    "                im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)\n",
    "                im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)\n",
    "                im1_s.append(im1)\n",
    "                im2_s.append(im2)\n",
    "\n",
    "            im1_s = np.array(im1_s)\n",
    "            im2_s = np.array(im2_s)\n",
    "            yield [im1_s, im2_s], labels\n",
    "            \n",
    "    def get_metrics(self, model, color_mode='rgb'):\n",
    "        eval_generator = self.two_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.evaluate(eval_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def get_predictions(self, model, color_mode='rgb'):\n",
    "        predict_generator = self.two_im_generator(\n",
    "            self.datagen,\n",
    "            self.dataset,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='binary'\n",
    "        )\n",
    "        \n",
    "        return model.predict(predict_generator, steps=self.steps, verbose=1)\n",
    "        \n",
    "    def print_model_metrics(self, model, color_mode):\n",
    "        metrics = self.get_metrics(model, color_mode)\n",
    "\n",
    "        for name, value in zip(model.metrics_names, metrics):\n",
    "            print(name, ': ', value)\n",
    "            \n",
    "    # Compute and plot multi-class confusion-matrix\n",
    "    def plot_cm(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold) \n",
    "        print(f'cm: {cm}')\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('Actual label')\n",
    "        plt.xlabel('Predicted label') \n",
    "        \n",
    "    # Compute and plot multi-class confusion-matrix with normalization\n",
    "    def plot_cm_normalized(self, model_path, labels, predictions, threshold):\n",
    "        cm = confusion_matrix(labels, predictions > threshold)\n",
    "        # Normalise\n",
    "        cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        sns.heatmap(cmn, annot=True, fmt='.3f')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show(block=False)  \n",
    "                \n",
    "    def display_false_positives(self, predictions, threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        if 500 > len(false_positives) > 1:\n",
    "            num_images = len(false_positives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_positives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                print(f'FP prediction: {preds[i]}, imname: {imname}')\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_positives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show()\n",
    "            \n",
    "    def display_false_negatives(self, predictions, threshold):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "\n",
    "        if 500 > len(false_negatives) > 1:\n",
    "            num_images = len(false_negatives)\n",
    "            _, axarr = plt.subplots(num_images, 1, figsize=(num_images, num_images))\n",
    "\n",
    "            for i, fname in enumerate(false_negatives):\n",
    "                imname = fname.split('/')[-1]\n",
    "                impath = os.path.join(self.obstacle_dataset, imname)\n",
    "                im = cv2.imread(impath)\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                axarr[i].imshow(im)\n",
    "                axarr[i].set_title(str(preds[i]) + ' ' + imname + (' '*30))\n",
    "            plt.show()\n",
    "        elif false_negatives:\n",
    "            fname = false_positives[0]\n",
    "            imname = fname.split('/')[-1]\n",
    "            impath = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(impath)\n",
    "            plt.imshow(im)\n",
    "            plt.title(str(preds[0]) + ' ' + imname)\n",
    "            plt.show()\n",
    "\n",
    "    def save_false_positives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        false_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'false_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "    def save_true_positives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        true_positives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] > threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p > threshold]\n",
    "\n",
    "        fp_path = os.path.join(save_path, 'true_positives')\n",
    "        Path(fp_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_positives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fp_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "\n",
    "    def save_false_negatives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.obstacle_image_names]\n",
    "        false_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'false_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(false_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)\n",
    "            \n",
    "    def save_true_negatives(self, predictions, threshold, save_path):\n",
    "        image_names = [s.split('/')[-1] for s in self.no_obstacle_image_names]\n",
    "        true_negatives = [fname for i, fname in enumerate(self.filenames)\\\n",
    "                           if fname.split('/')[-1] in image_names\\\n",
    "                           and predictions[i] <= threshold]\n",
    "        preds = [p for i, p in enumerate(predictions)\\\n",
    "                 if self.filenames[i].split('/')[-1] in image_names\\\n",
    "                 and p <= threshold]\n",
    "        \n",
    "        fn_path = os.path.join(save_path, 'true_negatives')\n",
    "        Path(fn_path).mkdir(parents=True, exist_ok=True)\n",
    "        for i, fname in enumerate(true_negatives):\n",
    "            imname = fname.split('/')[-1]\n",
    "            in_path = os.path.join(self.no_obstacle_dataset, imname)\n",
    "            im = cv2.imread(in_path)\n",
    "            out_path = os.path.join(fn_path, imname)\n",
    "            cv2.imwrite(out_path, im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Found 1432 images belonging to 2 classes.\n",
      "Found 1432 images belonging to 2 classes.\n",
      "45/45 [==============================] - 7s 159ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- Variables --\n",
    "model_path = '/home/drevital/cs_video_processor/models/rgb_6'\n",
    "dataset = '/home/drevital/obstacles_classification_datasets/rgb_6/eval'\n",
    "model_name = model_path.split('/')[-1]\n",
    "color_mode = 'rgb'\n",
    "threshold = 0.70\n",
    "batch_size = 32\n",
    "save_base_path = '/home/drevital/obstacles_classification_datasets/model_eval'\n",
    "save_name = dataset.split('/')[-2] + '_' + str(threshold)\n",
    "save_path = os.path.join(save_base_path, save_name)\n",
    "\n",
    "# -- Run the Evaluation --\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "handler = DatasetHandler(model_path, dataset, batch_size=batch_size)\n",
    "\n",
    "# -- Define Labels\n",
    "labels = np.array([0]*handler.num_no_obstacles\\\n",
    "                + [1]*handler.num_obstacles)\n",
    "\n",
    "# -- Predict with the model\n",
    "predictions = handler.get_predictions(model, color_mode=color_mode)\n",
    "\n",
    "# -- Print confision-matrix\n",
    "handler.plot_cm_normalized(model_path, labels, predictions, threshold=threshold)\n",
    "\n",
    "# -- Save Images\n",
    "handler.save_false_negatives(predictions, threshold=threshold, save_path=save_path)\n",
    "handler.save_false_positives(predictions, threshold=threshold, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
